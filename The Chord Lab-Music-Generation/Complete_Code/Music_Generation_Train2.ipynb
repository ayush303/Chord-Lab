{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, TimeDistributed, Dense, Activation, Embedding, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"../Data2/\"\n",
    "data_file = \"Data_Tunes.txt\"\n",
    "charIndex_json = \"char_to_index.json\"\n",
    "model_weights_directory = '../Data2/Model_Weights/'\n",
    "BATCH_SIZE = 16\n",
    "SEQ_LENGTH = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_batches(all_chars, unique_chars):\n",
    "    length = all_chars.shape[0]\n",
    "    batch_chars = int(length / BATCH_SIZE) #155222/16 = 9701\n",
    "    \n",
    "    for start in range(0, batch_chars - SEQ_LENGTH, 64):  #(0, 9637, 64)  #it denotes number of batches. It runs everytime when\n",
    "        #new batch is created. We have a total of 151 batches.\n",
    "        X = np.zeros((BATCH_SIZE, SEQ_LENGTH))    #(16, 64)\n",
    "        Y = np.zeros((BATCH_SIZE, SEQ_LENGTH, unique_chars))   #(16, 64, 87)\n",
    "        for batch_index in range(0, 16):  #it denotes each row in a batch.  \n",
    "            for i in range(0, 64):  #it denotes each column in a batch. Each column represents each character means \n",
    "                #each time-step character in a sequence.\n",
    "                X[batch_index, i] = all_chars[batch_index * batch_chars + start + i]\n",
    "                Y[batch_index, i, all_chars[batch_index * batch_chars + start + i + 1]] = 1 #here we have added '1' because the\n",
    "                #correct label will be the next character in the sequence. So, the next character will be denoted by\n",
    "                #all_chars[batch_index * batch_chars + start + i] + 1. \n",
    "        yield X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def built_model(batch_size, seq_length, unique_chars):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Embedding(input_dim = unique_chars, output_dim = 512, batch_input_shape = (batch_size, seq_length), name = \"embd_1\")) \n",
    "    \n",
    "    model.add(Bidirectional(LSTM(256, return_sequences = True, stateful = True, name = \"lstm_first\")))\n",
    "    model.add(Dropout(0.2, name = \"drp_1\"))\n",
    "    \n",
    "    model.add(Bidirectional(LSTM(256, return_sequences = True, stateful = True)))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Bidirectional(LSTM(256, return_sequences = True, stateful = True)))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(TimeDistributed(Dense(unique_chars)))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    \n",
    "    model.load_weights(\"../Data/Model_Weights/Weights_80.h5\", by_name = True)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model(data, epochs = 90):\n",
    "    #mapping character to index\n",
    "    char_to_index = {ch: i for (i, ch) in enumerate(sorted(list(set(data))))}\n",
    "    print(\"Number of unique characters in our whole tunes database = {}\".format(len(char_to_index))) #87\n",
    "    \n",
    "    with open(os.path.join(data_directory, charIndex_json), mode = \"w\") as f:\n",
    "        json.dump(char_to_index, f)\n",
    "        \n",
    "    index_to_char = {i: ch for (ch, i) in char_to_index.items()}\n",
    "    unique_chars = len(char_to_index)\n",
    "    \n",
    "    model = built_model(BATCH_SIZE, SEQ_LENGTH, unique_chars)\n",
    "    model.summary()\n",
    "    model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "    \n",
    "    all_characters = np.asarray([char_to_index[c] for c in data], dtype = np.int32)\n",
    "    print(\"Total number of characters = \"+str(all_characters.shape[0])) #155222\n",
    "    \n",
    "    epoch_number, loss, accuracy = [], [], []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch+1, epochs))\n",
    "        final_epoch_loss, final_epoch_accuracy = 0, 0\n",
    "        epoch_number.append(epoch+1)\n",
    "        \n",
    "        for i, (x, y) in enumerate(read_batches(all_characters, unique_chars)):\n",
    "            final_epoch_loss, final_epoch_accuracy = model.train_on_batch(x, y) #check documentation of train_on_batch here: https://keras.io/models/sequential/\n",
    "            print(\"Batch: {}, Loss: {}, Accuracy: {}\".format(i+1, final_epoch_loss, final_epoch_accuracy))\n",
    "            #here, above we are reading the batches one-by-one and train our model on each batch one-by-one.\n",
    "        loss.append(final_epoch_loss)\n",
    "        accuracy.append(final_epoch_accuracy)\n",
    "        \n",
    "        #saving weights after every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            if not os.path.exists(model_weights_directory):\n",
    "                os.makedirs(model_weights_directory)\n",
    "            model.save_weights(os.path.join(model_weights_directory, \"Weights_{}.h5\".format(epoch+1)))\n",
    "            print('Saved Weights at epoch {} to file Weights_{}.h5'.format(epoch+1, epoch+1))\n",
    "    \n",
    "    #creating dataframe and record all the losses and accuracies at each epoch\n",
    "    log_frame = pd.DataFrame(columns = [\"Epoch\", \"Loss\", \"Accuracy\"])\n",
    "    log_frame[\"Epoch\"] = epoch_number\n",
    "    log_frame[\"Loss\"] = loss\n",
    "    log_frame[\"Accuracy\"] = accuracy\n",
    "    log_frame.to_csv(\"../Data2/log.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "86328125\n",
      "Batch: 4, Loss: 0.08656841516494751, Accuracy: 0.986328125\n",
      "Batch: 5, Loss: 0.07311617583036423, Accuracy: 0.9853515625\n",
      "Batch: 6, Loss: 0.10036357492208481, Accuracy: 0.984375\n",
      "Batch: 7, Loss: 0.05554836243391037, Accuracy: 0.9912109375\n",
      "Batch: 8, Loss: 0.07076491415500641, Accuracy: 0.984375\n",
      "Batch: 9, Loss: 0.08158539235591888, Accuracy: 0.98828125\n",
      "Batch: 10, Loss: 0.06608546525239944, Accuracy: 0.990234375\n",
      "Batch: 11, Loss: 0.08764923363924026, Accuracy: 0.986328125\n",
      "Batch: 12, Loss: 0.08465596288442612, Accuracy: 0.984375\n",
      "Batch: 13, Loss: 0.06741703301668167, Accuracy: 0.9853515625\n",
      "Batch: 14, Loss: 0.06771326065063477, Accuracy: 0.9873046875\n",
      "Batch: 15, Loss: 0.09181388467550278, Accuracy: 0.9833984375\n",
      "Batch: 16, Loss: 0.07797346264123917, Accuracy: 0.9873046875\n",
      "Batch: 17, Loss: 0.09713363647460938, Accuracy: 0.984375\n",
      "Batch: 18, Loss: 0.07974893599748611, Accuracy: 0.9853515625\n",
      "Batch: 19, Loss: 0.09672115743160248, Accuracy: 0.98828125\n",
      "Batch: 20, Loss: 0.11017001420259476, Accuracy: 0.984375\n",
      "Batch: 21, Loss: 0.06087106466293335, Accuracy: 0.9892578125\n",
      "Batch: 22, Loss: 0.0811341181397438, Accuracy: 0.9853515625\n",
      "Batch: 23, Loss: 0.08094222098588943, Accuracy: 0.9873046875\n",
      "Batch: 24, Loss: 0.0753822773694992, Accuracy: 0.9892578125\n",
      "Batch: 25, Loss: 0.07025212049484253, Accuracy: 0.9873046875\n",
      "Batch: 26, Loss: 0.08225876092910767, Accuracy: 0.9853515625\n",
      "Batch: 27, Loss: 0.08854164183139801, Accuracy: 0.98828125\n",
      "Batch: 28, Loss: 0.08442968130111694, Accuracy: 0.9853515625\n",
      "Batch: 29, Loss: 0.07596983015537262, Accuracy: 0.98828125\n",
      "Batch: 30, Loss: 0.08552069962024689, Accuracy: 0.986328125\n",
      "Batch: 31, Loss: 0.08658484369516373, Accuracy: 0.984375\n",
      "Batch: 32, Loss: 0.07939904928207397, Accuracy: 0.986328125\n",
      "Batch: 33, Loss: 0.07424022257328033, Accuracy: 0.986328125\n",
      "Batch: 34, Loss: 0.11464213579893112, Accuracy: 0.9833984375\n",
      "Batch: 35, Loss: 0.1005285382270813, Accuracy: 0.9853515625\n",
      "Batch: 36, Loss: 0.08125106245279312, Accuracy: 0.9873046875\n",
      "Batch: 37, Loss: 0.09115079045295715, Accuracy: 0.9853515625\n",
      "Batch: 38, Loss: 0.08329235762357712, Accuracy: 0.9873046875\n",
      "Batch: 39, Loss: 0.08695809543132782, Accuracy: 0.984375\n",
      "Batch: 40, Loss: 0.08380618691444397, Accuracy: 0.9833984375\n",
      "Batch: 41, Loss: 0.0978289470076561, Accuracy: 0.9873046875\n",
      "Batch: 42, Loss: 0.0651235356926918, Accuracy: 0.9873046875\n",
      "Batch: 43, Loss: 0.07331299781799316, Accuracy: 0.986328125\n",
      "Batch: 44, Loss: 0.08052012324333191, Accuracy: 0.98828125\n",
      "Batch: 45, Loss: 0.06672630459070206, Accuracy: 0.98828125\n",
      "Batch: 46, Loss: 0.07755164802074432, Accuracy: 0.9873046875\n",
      "Batch: 47, Loss: 0.09862591326236725, Accuracy: 0.9833984375\n",
      "Batch: 48, Loss: 0.08972711861133575, Accuracy: 0.986328125\n",
      "Batch: 49, Loss: 0.0593617707490921, Accuracy: 0.9892578125\n",
      "Batch: 50, Loss: 0.10092275589704514, Accuracy: 0.9814453125\n",
      "Batch: 51, Loss: 0.08674211800098419, Accuracy: 0.986328125\n",
      "Batch: 52, Loss: 0.10804202407598495, Accuracy: 0.984375\n",
      "Batch: 53, Loss: 0.08429396897554398, Accuracy: 0.986328125\n",
      "Batch: 54, Loss: 0.06354612112045288, Accuracy: 0.9892578125\n",
      "Batch: 55, Loss: 0.07307516783475876, Accuracy: 0.986328125\n",
      "Batch: 56, Loss: 0.08893401175737381, Accuracy: 0.9873046875\n",
      "Batch: 57, Loss: 0.07374602556228638, Accuracy: 0.98828125\n",
      "Batch: 58, Loss: 0.060907743871212006, Accuracy: 0.986328125\n",
      "Batch: 59, Loss: 0.09394802898168564, Accuracy: 0.9853515625\n",
      "Batch: 60, Loss: 0.08019275218248367, Accuracy: 0.9853515625\n",
      "Batch: 61, Loss: 0.08081912994384766, Accuracy: 0.9853515625\n",
      "Batch: 62, Loss: 0.07958619296550751, Accuracy: 0.9873046875\n",
      "Batch: 63, Loss: 0.069997139275074, Accuracy: 0.9873046875\n",
      "Batch: 64, Loss: 0.08926337957382202, Accuracy: 0.9853515625\n",
      "Batch: 65, Loss: 0.08990725874900818, Accuracy: 0.982421875\n",
      "Batch: 66, Loss: 0.10823985189199448, Accuracy: 0.9833984375\n",
      "Batch: 67, Loss: 0.0906141996383667, Accuracy: 0.984375\n",
      "Batch: 68, Loss: 0.09096875041723251, Accuracy: 0.986328125\n",
      "Batch: 69, Loss: 0.09101611375808716, Accuracy: 0.9853515625\n",
      "Batch: 70, Loss: 0.06927579641342163, Accuracy: 0.9853515625\n",
      "Batch: 71, Loss: 0.0881975069642067, Accuracy: 0.986328125\n",
      "Batch: 72, Loss: 0.08252875506877899, Accuracy: 0.984375\n",
      "Batch: 73, Loss: 0.0766557827591896, Accuracy: 0.986328125\n",
      "Batch: 74, Loss: 0.06987971812486649, Accuracy: 0.986328125\n",
      "Batch: 75, Loss: 0.09321807324886322, Accuracy: 0.9853515625\n",
      "Batch: 76, Loss: 0.07311683148145676, Accuracy: 0.98828125\n",
      "Batch: 77, Loss: 0.08568934351205826, Accuracy: 0.9873046875\n",
      "Batch: 78, Loss: 0.06639349460601807, Accuracy: 0.9853515625\n",
      "Batch: 79, Loss: 0.08444512635469437, Accuracy: 0.9873046875\n",
      "Batch: 80, Loss: 0.06837154924869537, Accuracy: 0.986328125\n",
      "Batch: 81, Loss: 0.06338711082935333, Accuracy: 0.9873046875\n",
      "Batch: 82, Loss: 0.08223329484462738, Accuracy: 0.9873046875\n",
      "Batch: 83, Loss: 0.06343720853328705, Accuracy: 0.9892578125\n",
      "Batch: 84, Loss: 0.06703311949968338, Accuracy: 0.990234375\n",
      "Batch: 85, Loss: 0.06079984828829765, Accuracy: 0.990234375\n",
      "Batch: 86, Loss: 0.053076766431331635, Accuracy: 0.98828125\n",
      "Batch: 87, Loss: 0.06261780858039856, Accuracy: 0.9892578125\n",
      "Batch: 88, Loss: 0.08605754375457764, Accuracy: 0.986328125\n",
      "Batch: 89, Loss: 0.06916702538728714, Accuracy: 0.9873046875\n",
      "Batch: 90, Loss: 0.0773782730102539, Accuracy: 0.9892578125\n",
      "Batch: 91, Loss: 0.06901951879262924, Accuracy: 0.9892578125\n",
      "Batch: 92, Loss: 0.08863846212625504, Accuracy: 0.9873046875\n",
      "Batch: 93, Loss: 0.06849337369203568, Accuracy: 0.9873046875\n",
      "Batch: 94, Loss: 0.09242786467075348, Accuracy: 0.986328125\n",
      "Batch: 95, Loss: 0.07077544182538986, Accuracy: 0.98828125\n",
      "Batch: 96, Loss: 0.07369142025709152, Accuracy: 0.986328125\n",
      "Batch: 97, Loss: 0.06956032663583755, Accuracy: 0.9873046875\n",
      "Batch: 98, Loss: 0.08813450485467911, Accuracy: 0.984375\n",
      "Batch: 99, Loss: 0.06683973968029022, Accuracy: 0.9873046875\n",
      "Batch: 100, Loss: 0.0735817402601242, Accuracy: 0.986328125\n",
      "Batch: 101, Loss: 0.07167714834213257, Accuracy: 0.9853515625\n",
      "Batch: 102, Loss: 0.06027700752019882, Accuracy: 0.98828125\n",
      "Batch: 103, Loss: 0.09392914175987244, Accuracy: 0.986328125\n",
      "Batch: 104, Loss: 0.04828786104917526, Accuracy: 0.990234375\n",
      "Batch: 105, Loss: 0.08344925940036774, Accuracy: 0.9873046875\n",
      "Batch: 106, Loss: 0.09045993536710739, Accuracy: 0.9853515625\n",
      "Batch: 107, Loss: 0.07901206612586975, Accuracy: 0.986328125\n",
      "Batch: 108, Loss: 0.08513316512107849, Accuracy: 0.9892578125\n",
      "Batch: 109, Loss: 0.07047712802886963, Accuracy: 0.9873046875\n",
      "Batch: 110, Loss: 0.08378266543149948, Accuracy: 0.9873046875\n",
      "Batch: 111, Loss: 0.06747870147228241, Accuracy: 0.9892578125\n",
      "Batch: 112, Loss: 0.07221505045890808, Accuracy: 0.9892578125\n",
      "Batch: 113, Loss: 0.0680360347032547, Accuracy: 0.9853515625\n",
      "Batch: 114, Loss: 0.08610972762107849, Accuracy: 0.986328125\n",
      "Batch: 115, Loss: 0.08578100055456161, Accuracy: 0.9853515625\n",
      "Batch: 116, Loss: 0.06889642030000687, Accuracy: 0.98828125\n",
      "Batch: 117, Loss: 0.08052024990320206, Accuracy: 0.98828125\n",
      "Batch: 118, Loss: 0.06953905522823334, Accuracy: 0.9873046875\n",
      "Batch: 119, Loss: 0.061782628297805786, Accuracy: 0.990234375\n",
      "Batch: 120, Loss: 0.07234857231378555, Accuracy: 0.9853515625\n",
      "Batch: 121, Loss: 0.07934620976448059, Accuracy: 0.9873046875\n",
      "Batch: 122, Loss: 0.05191735923290253, Accuracy: 0.9892578125\n",
      "Batch: 123, Loss: 0.07982169091701508, Accuracy: 0.98828125\n",
      "Batch: 124, Loss: 0.06970210373401642, Accuracy: 0.98828125\n",
      "Batch: 125, Loss: 0.0965314581990242, Accuracy: 0.986328125\n",
      "Batch: 126, Loss: 0.06664936244487762, Accuracy: 0.98828125\n",
      "Batch: 127, Loss: 0.07969388365745544, Accuracy: 0.984375\n",
      "Batch: 128, Loss: 0.08616961538791656, Accuracy: 0.98828125\n",
      "Batch: 129, Loss: 0.06556198745965958, Accuracy: 0.9892578125\n",
      "Batch: 130, Loss: 0.060233235359191895, Accuracy: 0.990234375\n",
      "Batch: 131, Loss: 0.07291565835475922, Accuracy: 0.9853515625\n",
      "Batch: 132, Loss: 0.08280870318412781, Accuracy: 0.986328125\n",
      "Batch: 133, Loss: 0.08484959602355957, Accuracy: 0.9853515625\n",
      "Batch: 134, Loss: 0.07561491429805756, Accuracy: 0.9873046875\n",
      "Batch: 135, Loss: 0.06840794533491135, Accuracy: 0.9853515625\n",
      "Batch: 136, Loss: 0.05264577269554138, Accuracy: 0.9892578125\n",
      "Batch: 137, Loss: 0.07674352079629898, Accuracy: 0.9873046875\n",
      "Batch: 138, Loss: 0.05729920417070389, Accuracy: 0.9921875\n",
      "Batch: 139, Loss: 0.07646670937538147, Accuracy: 0.9873046875\n",
      "Batch: 140, Loss: 0.0702671930193901, Accuracy: 0.98828125\n",
      "Batch: 141, Loss: 0.06751789152622223, Accuracy: 0.98828125\n",
      "Batch: 142, Loss: 0.09019019454717636, Accuracy: 0.9853515625\n",
      "Batch: 143, Loss: 0.0714116021990776, Accuracy: 0.9873046875\n",
      "Batch: 144, Loss: 0.07196198403835297, Accuracy: 0.986328125\n",
      "Batch: 145, Loss: 0.05432571843266487, Accuracy: 0.9912109375\n",
      "Batch: 146, Loss: 0.09581077098846436, Accuracy: 0.984375\n",
      "Batch: 147, Loss: 0.07991933077573776, Accuracy: 0.9873046875\n",
      "Batch: 148, Loss: 0.0619308277964592, Accuracy: 0.9873046875\n",
      "Batch: 149, Loss: 0.06620649993419647, Accuracy: 0.98828125\n",
      "Batch: 150, Loss: 0.04950706288218498, Accuracy: 0.9921875\n",
      "Batch: 151, Loss: 0.05578375235199928, Accuracy: 0.9892578125\n",
      "Epoch 5/90\n",
      "Batch: 1, Loss: 0.0658499002456665, Accuracy: 0.990234375\n",
      "Batch: 2, Loss: 0.06672640144824982, Accuracy: 0.9873046875\n",
      "Batch: 3, Loss: 0.06323498487472534, Accuracy: 0.986328125\n",
      "Batch: 4, Loss: 0.06304122507572174, Accuracy: 0.986328125\n",
      "Batch: 5, Loss: 0.054442934691905975, Accuracy: 0.9912109375\n",
      "Batch: 6, Loss: 0.08319713920354843, Accuracy: 0.986328125\n",
      "Batch: 7, Loss: 0.04003126174211502, Accuracy: 0.9912109375\n",
      "Batch: 8, Loss: 0.04894484579563141, Accuracy: 0.98828125\n",
      "Batch: 9, Loss: 0.06898993253707886, Accuracy: 0.98828125\n",
      "Batch: 10, Loss: 0.0581418015062809, Accuracy: 0.9912109375\n",
      "Batch: 11, Loss: 0.06827784329652786, Accuracy: 0.9873046875\n",
      "Batch: 12, Loss: 0.07028697431087494, Accuracy: 0.9873046875\n",
      "Batch: 13, Loss: 0.05867301672697067, Accuracy: 0.9873046875\n",
      "Batch: 14, Loss: 0.05193696171045303, Accuracy: 0.990234375\n",
      "Batch: 15, Loss: 0.07624845206737518, Accuracy: 0.9873046875\n",
      "Batch: 16, Loss: 0.058402590453624725, Accuracy: 0.990234375\n",
      "Batch: 17, Loss: 0.07630939036607742, Accuracy: 0.98828125\n",
      "Batch: 18, Loss: 0.07154902070760727, Accuracy: 0.98828125\n",
      "Batch: 19, Loss: 0.07957273721694946, Accuracy: 0.9873046875\n",
      "Batch: 20, Loss: 0.08532141149044037, Accuracy: 0.9873046875\n",
      "Batch: 21, Loss: 0.05033890902996063, Accuracy: 0.990234375\n",
      "Batch: 22, Loss: 0.07869552075862885, Accuracy: 0.986328125\n",
      "Batch: 23, Loss: 0.06381920725107193, Accuracy: 0.9892578125\n",
      "Batch: 24, Loss: 0.05980757251381874, Accuracy: 0.9892578125\n",
      "Batch: 25, Loss: 0.054681308567523956, Accuracy: 0.990234375\n",
      "Batch: 26, Loss: 0.06567710638046265, Accuracy: 0.98828125\n",
      "Batch: 27, Loss: 0.07873357832431793, Accuracy: 0.9873046875\n",
      "Batch: 28, Loss: 0.07249589264392853, Accuracy: 0.9873046875\n",
      "Batch: 29, Loss: 0.06113782525062561, Accuracy: 0.9873046875\n",
      "Batch: 30, Loss: 0.06948524713516235, Accuracy: 0.986328125\n",
      "Batch: 31, Loss: 0.07520494610071182, Accuracy: 0.986328125\n",
      "Batch: 32, Loss: 0.058311160653829575, Accuracy: 0.9892578125\n",
      "Batch: 33, Loss: 0.06304331123828888, Accuracy: 0.98828125\n",
      "Batch: 34, Loss: 0.10021215677261353, Accuracy: 0.9853515625\n",
      "Batch: 35, Loss: 0.0784742534160614, Accuracy: 0.9873046875\n",
      "Batch: 36, Loss: 0.06536266952753067, Accuracy: 0.98828125\n",
      "Batch: 37, Loss: 0.07143308967351913, Accuracy: 0.98828125\n",
      "Batch: 38, Loss: 0.06073170527815819, Accuracy: 0.9892578125\n",
      "Batch: 39, Loss: 0.07672806084156036, Accuracy: 0.9853515625\n",
      "Batch: 40, Loss: 0.06020442023873329, Accuracy: 0.98828125\n",
      "Batch: 41, Loss: 0.0726160928606987, Accuracy: 0.98828125\n",
      "Batch: 42, Loss: 0.053845036774873734, Accuracy: 0.9873046875\n",
      "Batch: 43, Loss: 0.06056372448801994, Accuracy: 0.98828125\n",
      "Batch: 44, Loss: 0.0625525489449501, Accuracy: 0.98828125\n",
      "Batch: 45, Loss: 0.05529818311333656, Accuracy: 0.990234375\n",
      "Batch: 46, Loss: 0.06320756673812866, Accuracy: 0.9921875\n",
      "Batch: 47, Loss: 0.08215728402137756, Accuracy: 0.984375\n",
      "Batch: 48, Loss: 0.06933584064245224, Accuracy: 0.9892578125\n",
      "Batch: 49, Loss: 0.049840886145830154, Accuracy: 0.994140625\n",
      "Batch: 50, Loss: 0.07713241875171661, Accuracy: 0.984375\n",
      "Batch: 51, Loss: 0.06845137476921082, Accuracy: 0.98828125\n",
      "Batch: 52, Loss: 0.09058067202568054, Accuracy: 0.986328125\n",
      "Batch: 53, Loss: 0.06620147824287415, Accuracy: 0.986328125\n",
      "Batch: 54, Loss: 0.04871602728962898, Accuracy: 0.9912109375\n",
      "Batch: 55, Loss: 0.05621565505862236, Accuracy: 0.990234375\n",
      "Batch: 56, Loss: 0.07146182656288147, Accuracy: 0.98828125\n",
      "Batch: 57, Loss: 0.05897153913974762, Accuracy: 0.990234375\n",
      "Batch: 58, Loss: 0.050720032304525375, Accuracy: 0.9892578125\n",
      "Batch: 59, Loss: 0.07154323905706406, Accuracy: 0.9892578125\n",
      "Batch: 60, Loss: 0.057060226798057556, Accuracy: 0.98828125\n",
      "Batch: 61, Loss: 0.06383505463600159, Accuracy: 0.986328125\n",
      "Batch: 62, Loss: 0.06298790127038956, Accuracy: 0.98828125\n",
      "Batch: 63, Loss: 0.049926936626434326, Accuracy: 0.9892578125\n",
      "Batch: 64, Loss: 0.07055068761110306, Accuracy: 0.9873046875\n",
      "Batch: 65, Loss: 0.0710478350520134, Accuracy: 0.9873046875\n",
      "Batch: 66, Loss: 0.08090472221374512, Accuracy: 0.9833984375\n",
      "Batch: 67, Loss: 0.07867812365293503, Accuracy: 0.984375\n",
      "Batch: 68, Loss: 0.07409201562404633, Accuracy: 0.9873046875\n",
      "Batch: 69, Loss: 0.07371257990598679, Accuracy: 0.986328125\n",
      "Batch: 70, Loss: 0.0572221502661705, Accuracy: 0.990234375\n",
      "Batch: 71, Loss: 0.07337591797113419, Accuracy: 0.98828125\n",
      "Batch: 72, Loss: 0.06564764678478241, Accuracy: 0.986328125\n",
      "Batch: 73, Loss: 0.06759410351514816, Accuracy: 0.9873046875\n",
      "Batch: 74, Loss: 0.06448216736316681, Accuracy: 0.986328125\n",
      "Batch: 75, Loss: 0.07097648829221725, Accuracy: 0.9873046875\n",
      "Batch: 76, Loss: 0.05789957195520401, Accuracy: 0.98828125\n",
      "Batch: 77, Loss: 0.07180426269769669, Accuracy: 0.98828125\n",
      "Batch: 78, Loss: 0.042294941842556, Accuracy: 0.9931640625\n",
      "Batch: 79, Loss: 0.07012607902288437, Accuracy: 0.98828125\n",
      "Batch: 80, Loss: 0.05394084006547928, Accuracy: 0.986328125\n",
      "Batch: 81, Loss: 0.04991495609283447, Accuracy: 0.98828125\n",
      "Batch: 82, Loss: 0.06665711849927902, Accuracy: 0.9873046875\n",
      "Batch: 83, Loss: 0.048788897693157196, Accuracy: 0.9892578125\n",
      "Batch: 84, Loss: 0.06167542189359665, Accuracy: 0.9921875\n",
      "Batch: 85, Loss: 0.04659690707921982, Accuracy: 0.9921875\n",
      "Batch: 86, Loss: 0.0439455471932888, Accuracy: 0.990234375\n",
      "Batch: 87, Loss: 0.05532688647508621, Accuracy: 0.9892578125\n",
      "Batch: 88, Loss: 0.07174481451511383, Accuracy: 0.9892578125\n",
      "Batch: 89, Loss: 0.053056515753269196, Accuracy: 0.990234375\n",
      "Batch: 90, Loss: 0.056998349726200104, Accuracy: 0.98828125\n",
      "Batch: 91, Loss: 0.06077033281326294, Accuracy: 0.98828125\n",
      "Batch: 92, Loss: 0.06608710438013077, Accuracy: 0.98828125\n",
      "Batch: 93, Loss: 0.062041014432907104, Accuracy: 0.98828125\n",
      "Batch: 94, Loss: 0.07958366721868515, Accuracy: 0.9892578125\n",
      "Batch: 95, Loss: 0.05267322063446045, Accuracy: 0.9921875\n",
      "Batch: 96, Loss: 0.06647558510303497, Accuracy: 0.9873046875\n",
      "Batch: 97, Loss: 0.058826375752687454, Accuracy: 0.98828125\n",
      "Batch: 98, Loss: 0.07147954404354095, Accuracy: 0.9873046875\n",
      "Batch: 99, Loss: 0.052500054240226746, Accuracy: 0.9892578125\n",
      "Batch: 100, Loss: 0.05559147894382477, Accuracy: 0.990234375\n",
      "Batch: 101, Loss: 0.059039127081632614, Accuracy: 0.98828125\n",
      "Batch: 102, Loss: 0.05181237310171127, Accuracy: 0.990234375\n",
      "Batch: 103, Loss: 0.07672318816184998, Accuracy: 0.9892578125\n",
      "Batch: 104, Loss: 0.04418504610657692, Accuracy: 0.990234375\n",
      "Batch: 105, Loss: 0.0648091658949852, Accuracy: 0.9892578125\n",
      "Batch: 106, Loss: 0.07483770698308945, Accuracy: 0.9873046875\n",
      "Batch: 107, Loss: 0.06197807192802429, Accuracy: 0.986328125\n",
      "Batch: 108, Loss: 0.06916236132383347, Accuracy: 0.986328125\n",
      "Batch: 109, Loss: 0.05651475489139557, Accuracy: 0.990234375\n",
      "Batch: 110, Loss: 0.0713861808180809, Accuracy: 0.9873046875\n",
      "Batch: 111, Loss: 0.052574560046195984, Accuracy: 0.9912109375\n",
      "Batch: 112, Loss: 0.061292123049497604, Accuracy: 0.990234375\n",
      "Batch: 113, Loss: 0.052316807210445404, Accuracy: 0.9873046875\n",
      "Batch: 114, Loss: 0.07273351401090622, Accuracy: 0.98828125\n",
      "Batch: 115, Loss: 0.06804651021957397, Accuracy: 0.98828125\n",
      "Batch: 116, Loss: 0.050381436944007874, Accuracy: 0.9912109375\n",
      "Batch: 117, Loss: 0.06286384165287018, Accuracy: 0.98828125\n",
      "Batch: 118, Loss: 0.053626444190740585, Accuracy: 0.9892578125\n",
      "Batch: 119, Loss: 0.0449981763958931, Accuracy: 0.9931640625\n",
      "Batch: 120, Loss: 0.06513851881027222, Accuracy: 0.9873046875\n",
      "Batch: 121, Loss: 0.0645872950553894, Accuracy: 0.986328125\n",
      "Batch: 122, Loss: 0.04424457252025604, Accuracy: 0.9892578125\n",
      "Batch: 123, Loss: 0.06246642395853996, Accuracy: 0.9892578125\n",
      "Batch: 124, Loss: 0.06559095531702042, Accuracy: 0.9892578125\n",
      "Batch: 125, Loss: 0.08165843039751053, Accuracy: 0.98828125\n",
      "Batch: 126, Loss: 0.0562579520046711, Accuracy: 0.9892578125\n",
      "Batch: 127, Loss: 0.06276319921016693, Accuracy: 0.990234375\n",
      "Batch: 128, Loss: 0.07580055296421051, Accuracy: 0.9853515625\n",
      "Batch: 129, Loss: 0.042855385690927505, Accuracy: 0.9921875\n",
      "Batch: 130, Loss: 0.04819931462407112, Accuracy: 0.990234375\n",
      "Batch: 131, Loss: 0.05939934775233269, Accuracy: 0.9892578125\n",
      "Batch: 132, Loss: 0.06522482633590698, Accuracy: 0.98828125\n",
      "Batch: 133, Loss: 0.06773341447114944, Accuracy: 0.986328125\n",
      "Batch: 134, Loss: 0.056033387780189514, Accuracy: 0.9912109375\n",
      "Batch: 135, Loss: 0.045263051986694336, Accuracy: 0.98828125\n",
      "Batch: 136, Loss: 0.038292597979307175, Accuracy: 0.9921875\n",
      "Batch: 137, Loss: 0.06844302266836166, Accuracy: 0.986328125\n",
      "Batch: 138, Loss: 0.04582490772008896, Accuracy: 0.9912109375\n",
      "Batch: 139, Loss: 0.06444457173347473, Accuracy: 0.9873046875\n",
      "Batch: 140, Loss: 0.06178589165210724, Accuracy: 0.986328125\n",
      "Batch: 141, Loss: 0.057270996272563934, Accuracy: 0.98828125\n",
      "Batch: 142, Loss: 0.07927031815052032, Accuracy: 0.9833984375\n",
      "Batch: 143, Loss: 0.06073906272649765, Accuracy: 0.986328125\n",
      "Batch: 144, Loss: 0.05736559256911278, Accuracy: 0.9873046875\n",
      "Batch: 145, Loss: 0.04795447736978531, Accuracy: 0.98828125\n",
      "Batch: 146, Loss: 0.08053958415985107, Accuracy: 0.9873046875\n",
      "Batch: 147, Loss: 0.06610486656427383, Accuracy: 0.9892578125\n",
      "Batch: 148, Loss: 0.05351359769701958, Accuracy: 0.9892578125\n",
      "Batch: 149, Loss: 0.04590597003698349, Accuracy: 0.990234375\n",
      "Batch: 150, Loss: 0.04618946835398674, Accuracy: 0.9912109375\n",
      "Batch: 151, Loss: 0.04809405654668808, Accuracy: 0.990234375\n",
      "Epoch 6/90\n",
      "Batch: 1, Loss: 0.05098826438188553, Accuracy: 0.9892578125\n",
      "Batch: 2, Loss: 0.057059697806835175, Accuracy: 0.9873046875\n",
      "Batch: 3, Loss: 0.056736964732408524, Accuracy: 0.990234375\n",
      "Batch: 4, Loss: 0.048478495329618454, Accuracy: 0.986328125\n",
      "Batch: 5, Loss: 0.05236127972602844, Accuracy: 0.9892578125\n",
      "Batch: 6, Loss: 0.06934955716133118, Accuracy: 0.98828125\n",
      "Batch: 7, Loss: 0.0294218547642231, Accuracy: 0.994140625\n",
      "Batch: 8, Loss: 0.03880204260349274, Accuracy: 0.990234375\n",
      "Batch: 9, Loss: 0.06153388321399689, Accuracy: 0.990234375\n",
      "Batch: 10, Loss: 0.04455793648958206, Accuracy: 0.990234375\n",
      "Batch: 11, Loss: 0.05420045927166939, Accuracy: 0.9873046875\n",
      "Batch: 12, Loss: 0.05751536786556244, Accuracy: 0.9873046875\n",
      "Batch: 13, Loss: 0.04217267036437988, Accuracy: 0.9912109375\n",
      "Batch: 14, Loss: 0.04177055507898331, Accuracy: 0.9912109375\n",
      "Batch: 15, Loss: 0.0628829225897789, Accuracy: 0.98828125\n",
      "Batch: 16, Loss: 0.04797638952732086, Accuracy: 0.990234375\n",
      "Batch: 17, Loss: 0.0633305013179779, Accuracy: 0.9892578125\n",
      "Batch: 18, Loss: 0.06613989174365997, Accuracy: 0.98828125\n",
      "Batch: 19, Loss: 0.06461170315742493, Accuracy: 0.9892578125\n",
      "Batch: 20, Loss: 0.06857626140117645, Accuracy: 0.98828125\n",
      "Batch: 21, Loss: 0.04124678671360016, Accuracy: 0.9921875\n",
      "Batch: 22, Loss: 0.06533217430114746, Accuracy: 0.9873046875\n",
      "Batch: 23, Loss: 0.05465206503868103, Accuracy: 0.990234375\n",
      "Batch: 24, Loss: 0.04272042214870453, Accuracy: 0.9921875\n",
      "Batch: 25, Loss: 0.04687418043613434, Accuracy: 0.990234375\n",
      "Batch: 26, Loss: 0.06055675819516182, Accuracy: 0.990234375\n",
      "Batch: 27, Loss: 0.06414139270782471, Accuracy: 0.986328125\n",
      "Batch: 28, Loss: 0.058421820402145386, Accuracy: 0.9892578125\n",
      "Batch: 29, Loss: 0.04722586274147034, Accuracy: 0.9931640625\n",
      "Batch: 30, Loss: 0.05390671640634537, Accuracy: 0.98828125\n",
      "Batch: 31, Loss: 0.058069296181201935, Accuracy: 0.98828125\n",
      "Batch: 32, Loss: 0.043299607932567596, Accuracy: 0.990234375\n",
      "Batch: 33, Loss: 0.053505636751651764, Accuracy: 0.990234375\n",
      "Batch: 34, Loss: 0.06981823593378067, Accuracy: 0.984375\n",
      "Batch: 35, Loss: 0.0665852278470993, Accuracy: 0.9892578125\n",
      "Batch: 36, Loss: 0.06172800436615944, Accuracy: 0.9892578125\n",
      "Batch: 37, Loss: 0.06014719977974892, Accuracy: 0.9912109375\n",
      "Batch: 38, Loss: 0.049123845994472504, Accuracy: 0.9892578125\n",
      "Batch: 39, Loss: 0.05832712724804878, Accuracy: 0.98828125\n",
      "Batch: 40, Loss: 0.04250280559062958, Accuracy: 0.9912109375\n",
      "Batch: 41, Loss: 0.05865545570850372, Accuracy: 0.9892578125\n",
      "Batch: 42, Loss: 0.04472643509507179, Accuracy: 0.9892578125\n",
      "Batch: 43, Loss: 0.05727479234337807, Accuracy: 0.9873046875\n",
      "Batch: 44, Loss: 0.06114117428660393, Accuracy: 0.98828125\n",
      "Batch: 45, Loss: 0.04812239855527878, Accuracy: 0.9892578125\n",
      "Batch: 46, Loss: 0.05062659829854965, Accuracy: 0.9912109375\n",
      "Batch: 47, Loss: 0.06566088646650314, Accuracy: 0.9873046875\n",
      "Batch: 48, Loss: 0.0522138774394989, Accuracy: 0.990234375\n",
      "Batch: 49, Loss: 0.04220257326960564, Accuracy: 0.9931640625\n",
      "Batch: 50, Loss: 0.06925219297409058, Accuracy: 0.9853515625\n",
      "Batch: 51, Loss: 0.05728710815310478, Accuracy: 0.98828125\n",
      "Batch: 52, Loss: 0.0635889396071434, Accuracy: 0.9873046875\n",
      "Batch: 53, Loss: 0.05186409130692482, Accuracy: 0.990234375\n",
      "Batch: 54, Loss: 0.038031935691833496, Accuracy: 0.9931640625\n",
      "Batch: 55, Loss: 0.04362545162439346, Accuracy: 0.9892578125\n",
      "Batch: 56, Loss: 0.05791344866156578, Accuracy: 0.990234375\n",
      "Batch: 57, Loss: 0.05030788108706474, Accuracy: 0.990234375\n",
      "Batch: 58, Loss: 0.039362769573926926, Accuracy: 0.9931640625\n",
      "Batch: 59, Loss: 0.05827738717198372, Accuracy: 0.9892578125\n",
      "Batch: 60, Loss: 0.05199094116687775, Accuracy: 0.9892578125\n",
      "Batch: 61, Loss: 0.049840472638607025, Accuracy: 0.990234375\n",
      "Batch: 62, Loss: 0.05269893631339073, Accuracy: 0.9892578125\n",
      "Batch: 63, Loss: 0.038196466863155365, Accuracy: 0.9912109375\n",
      "Batch: 64, Loss: 0.0596403032541275, Accuracy: 0.990234375\n",
      "Batch: 65, Loss: 0.05672406405210495, Accuracy: 0.986328125\n",
      "Batch: 66, Loss: 0.06524502485990524, Accuracy: 0.986328125\n",
      "Batch: 67, Loss: 0.06593000888824463, Accuracy: 0.9873046875\n",
      "Batch: 68, Loss: 0.05962982401251793, Accuracy: 0.990234375\n",
      "Batch: 69, Loss: 0.06678587198257446, Accuracy: 0.986328125\n",
      "Batch: 70, Loss: 0.03768083080649376, Accuracy: 0.9921875\n",
      "Batch: 71, Loss: 0.05680384114384651, Accuracy: 0.9892578125\n",
      "Batch: 72, Loss: 0.05098293349146843, Accuracy: 0.98828125\n",
      "Batch: 73, Loss: 0.05326281115412712, Accuracy: 0.9921875\n",
      "Batch: 74, Loss: 0.04568788781762123, Accuracy: 0.9892578125\n",
      "Batch: 75, Loss: 0.06081845983862877, Accuracy: 0.98828125\n",
      "Batch: 76, Loss: 0.05123298987746239, Accuracy: 0.98828125\n",
      "Batch: 77, Loss: 0.061425864696502686, Accuracy: 0.98828125\n",
      "Batch: 78, Loss: 0.03688123822212219, Accuracy: 0.994140625\n",
      "Batch: 79, Loss: 0.058205507695674896, Accuracy: 0.9892578125\n",
      "Batch: 80, Loss: 0.040343426167964935, Accuracy: 0.9892578125\n",
      "Batch: 81, Loss: 0.043856918811798096, Accuracy: 0.990234375\n",
      "Batch: 82, Loss: 0.05778079852461815, Accuracy: 0.98828125\n",
      "Batch: 83, Loss: 0.04321093112230301, Accuracy: 0.9892578125\n",
      "Batch: 84, Loss: 0.050191618502140045, Accuracy: 0.9912109375\n",
      "Batch: 85, Loss: 0.041302986443042755, Accuracy: 0.9931640625\n",
      "Batch: 86, Loss: 0.036921486258506775, Accuracy: 0.9921875\n",
      "Batch: 87, Loss: 0.04019824415445328, Accuracy: 0.9912109375\n",
      "Batch: 88, Loss: 0.06528550386428833, Accuracy: 0.9892578125\n",
      "Batch: 89, Loss: 0.05148325487971306, Accuracy: 0.9892578125\n",
      "Batch: 90, Loss: 0.04639606922864914, Accuracy: 0.990234375\n",
      "Batch: 91, Loss: 0.04595814272761345, Accuracy: 0.9892578125\n",
      "Batch: 92, Loss: 0.060235604643821716, Accuracy: 0.9892578125\n",
      "Batch: 93, Loss: 0.04686072841286659, Accuracy: 0.9931640625\n",
      "Batch: 94, Loss: 0.07368756085634232, Accuracy: 0.98828125\n",
      "Batch: 95, Loss: 0.04275510460138321, Accuracy: 0.9921875\n",
      "Batch: 96, Loss: 0.054555829614400864, Accuracy: 0.990234375\n",
      "Batch: 97, Loss: 0.04129752889275551, Accuracy: 0.990234375\n",
      "Batch: 98, Loss: 0.05413663387298584, Accuracy: 0.990234375\n",
      "Batch: 99, Loss: 0.03993051499128342, Accuracy: 0.98828125\n",
      "Batch: 100, Loss: 0.04113784059882164, Accuracy: 0.9921875\n",
      "Batch: 101, Loss: 0.04953482002019882, Accuracy: 0.9873046875\n",
      "Batch: 102, Loss: 0.04427028074860573, Accuracy: 0.9931640625\n",
      "Batch: 103, Loss: 0.06011076271533966, Accuracy: 0.9892578125\n",
      "Batch: 104, Loss: 0.030186371877789497, Accuracy: 0.994140625\n",
      "Batch: 105, Loss: 0.05976385250687599, Accuracy: 0.990234375\n",
      "Batch: 106, Loss: 0.05996070057153702, Accuracy: 0.9873046875\n",
      "Batch: 107, Loss: 0.04883342981338501, Accuracy: 0.9892578125\n",
      "Batch: 108, Loss: 0.057645734399557114, Accuracy: 0.990234375\n",
      "Batch: 109, Loss: 0.0466243252158165, Accuracy: 0.990234375\n",
      "Batch: 110, Loss: 0.059508081525564194, Accuracy: 0.9892578125\n",
      "Batch: 111, Loss: 0.04473445191979408, Accuracy: 0.9912109375\n",
      "Batch: 112, Loss: 0.041917834430933, Accuracy: 0.9921875\n",
      "Batch: 113, Loss: 0.04564795643091202, Accuracy: 0.9892578125\n",
      "Batch: 114, Loss: 0.0503317192196846, Accuracy: 0.990234375\n",
      "Batch: 115, Loss: 0.0657896101474762, Accuracy: 0.9892578125\n",
      "Batch: 116, Loss: 0.047834161669015884, Accuracy: 0.990234375\n",
      "Batch: 117, Loss: 0.04975425451993942, Accuracy: 0.9892578125\n",
      "Batch: 118, Loss: 0.04565461352467537, Accuracy: 0.9921875\n",
      "Batch: 119, Loss: 0.03768763691186905, Accuracy: 0.9931640625\n",
      "Batch: 120, Loss: 0.0531320683658123, Accuracy: 0.9892578125\n",
      "Batch: 121, Loss: 0.056682199239730835, Accuracy: 0.9892578125\n",
      "Batch: 122, Loss: 0.03549901023507118, Accuracy: 0.994140625\n",
      "Batch: 123, Loss: 0.05337552726268768, Accuracy: 0.9892578125\n",
      "Batch: 124, Loss: 0.05686037987470627, Accuracy: 0.9892578125\n",
      "Batch: 125, Loss: 0.07354670017957687, Accuracy: 0.98828125\n",
      "Batch: 126, Loss: 0.047857917845249176, Accuracy: 0.9892578125\n",
      "Batch: 127, Loss: 0.05531317740678787, Accuracy: 0.9873046875\n",
      "Batch: 128, Loss: 0.06680691987276077, Accuracy: 0.9912109375\n",
      "Batch: 129, Loss: 0.035101499408483505, Accuracy: 0.9931640625\n",
      "Batch: 130, Loss: 0.039606738835573196, Accuracy: 0.9912109375\n",
      "Batch: 131, Loss: 0.048913128674030304, Accuracy: 0.990234375\n",
      "Batch: 132, Loss: 0.05495450645685196, Accuracy: 0.98828125\n",
      "Batch: 133, Loss: 0.05480755865573883, Accuracy: 0.98828125\n",
      "Batch: 134, Loss: 0.048663683235645294, Accuracy: 0.990234375\n",
      "Batch: 135, Loss: 0.041410889476537704, Accuracy: 0.9892578125\n",
      "Batch: 136, Loss: 0.030279064550995827, Accuracy: 0.990234375\n",
      "Batch: 137, Loss: 0.045588936656713486, Accuracy: 0.98828125\n",
      "Batch: 138, Loss: 0.033942874521017075, Accuracy: 0.9931640625\n",
      "Batch: 139, Loss: 0.05083802342414856, Accuracy: 0.98828125\n",
      "Batch: 140, Loss: 0.05990046635270119, Accuracy: 0.9892578125\n",
      "Batch: 141, Loss: 0.0469282902777195, Accuracy: 0.9912109375\n",
      "Batch: 142, Loss: 0.06809636205434799, Accuracy: 0.9853515625\n",
      "Batch: 143, Loss: 0.04426748678088188, Accuracy: 0.990234375\n",
      "Batch: 144, Loss: 0.04908720403909683, Accuracy: 0.9892578125\n",
      "Batch: 145, Loss: 0.03828234225511551, Accuracy: 0.9921875\n",
      "Batch: 146, Loss: 0.0641547366976738, Accuracy: 0.98828125\n",
      "Batch: 147, Loss: 0.05244285985827446, Accuracy: 0.990234375\n",
      "Batch: 148, Loss: 0.038508910685777664, Accuracy: 0.9912109375\n",
      "Batch: 149, Loss: 0.04158002883195877, Accuracy: 0.9912109375\n",
      "Batch: 150, Loss: 0.029655087739229202, Accuracy: 0.9921875\n",
      "Batch: 151, Loss: 0.03391602635383606, Accuracy: 0.990234375\n",
      "Epoch 7/90\n",
      "Batch: 1, Loss: 0.044668495655059814, Accuracy: 0.9892578125\n",
      "Batch: 2, Loss: 0.053167108446359634, Accuracy: 0.9892578125\n",
      "Batch: 3, Loss: 0.04444634169340134, Accuracy: 0.9912109375\n",
      "Batch: 4, Loss: 0.03443143144249916, Accuracy: 0.990234375\n",
      "Batch: 5, Loss: 0.04192589968442917, Accuracy: 0.9931640625\n",
      "Batch: 6, Loss: 0.06298745423555374, Accuracy: 0.98828125\n",
      "Batch: 7, Loss: 0.022493921220302582, Accuracy: 0.9951171875\n",
      "Batch: 8, Loss: 0.03051288053393364, Accuracy: 0.9931640625\n",
      "Batch: 9, Loss: 0.04671836644411087, Accuracy: 0.9912109375\n",
      "Batch: 10, Loss: 0.03719281405210495, Accuracy: 0.9921875\n",
      "Batch: 11, Loss: 0.04185781255364418, Accuracy: 0.98828125\n",
      "Batch: 12, Loss: 0.0472622849047184, Accuracy: 0.9912109375\n",
      "Batch: 13, Loss: 0.03313712403178215, Accuracy: 0.9951171875\n",
      "Batch: 14, Loss: 0.042023759335279465, Accuracy: 0.990234375\n",
      "Batch: 15, Loss: 0.04847436025738716, Accuracy: 0.9912109375\n",
      "Batch: 16, Loss: 0.046499043703079224, Accuracy: 0.9921875\n",
      "Batch: 17, Loss: 0.05038963258266449, Accuracy: 0.990234375\n",
      "Batch: 18, Loss: 0.053502053022384644, Accuracy: 0.9912109375\n",
      "Batch: 19, Loss: 0.05358631908893585, Accuracy: 0.9912109375\n",
      "Batch: 20, Loss: 0.055080346763134, Accuracy: 0.990234375\n",
      "Batch: 21, Loss: 0.0368657186627388, Accuracy: 0.9921875\n",
      "Batch: 22, Loss: 0.05582871288061142, Accuracy: 0.9873046875\n",
      "Batch: 23, Loss: 0.04446369409561157, Accuracy: 0.990234375\n",
      "Batch: 24, Loss: 0.029397020116448402, Accuracy: 0.9912109375\n",
      "Batch: 25, Loss: 0.03972947224974632, Accuracy: 0.9931640625\n",
      "Batch: 26, Loss: 0.055214349180459976, Accuracy: 0.990234375\n",
      "Batch: 27, Loss: 0.046383339911699295, Accuracy: 0.990234375\n",
      "Batch: 28, Loss: 0.04975228011608124, Accuracy: 0.9912109375\n",
      "Batch: 29, Loss: 0.040943488478660583, Accuracy: 0.9921875\n",
      "Batch: 30, Loss: 0.04667157679796219, Accuracy: 0.9912109375\n",
      "Batch: 31, Loss: 0.04557691514492035, Accuracy: 0.98828125\n",
      "Batch: 32, Loss: 0.029682468622922897, Accuracy: 0.9921875\n",
      "Batch: 33, Loss: 0.04584586247801781, Accuracy: 0.990234375\n",
      "Batch: 34, Loss: 0.06386107951402664, Accuracy: 0.986328125\n",
      "Batch: 35, Loss: 0.04726288095116615, Accuracy: 0.9921875\n",
      "Batch: 36, Loss: 0.05212291702628136, Accuracy: 0.9892578125\n",
      "Batch: 37, Loss: 0.054656073451042175, Accuracy: 0.9912109375\n",
      "Batch: 38, Loss: 0.04164622351527214, Accuracy: 0.9912109375\n",
      "Batch: 39, Loss: 0.05054202675819397, Accuracy: 0.98828125\n",
      "Batch: 40, Loss: 0.03597329929471016, Accuracy: 0.9921875\n",
      "Batch: 41, Loss: 0.04288231208920479, Accuracy: 0.9931640625\n",
      "Batch: 42, Loss: 0.03316498175263405, Accuracy: 0.9931640625\n",
      "Batch: 43, Loss: 0.04135255143046379, Accuracy: 0.9931640625\n",
      "Batch: 44, Loss: 0.051166657358407974, Accuracy: 0.990234375\n",
      "Batch: 45, Loss: 0.03824897110462189, Accuracy: 0.990234375\n",
      "Batch: 46, Loss: 0.044111888855695724, Accuracy: 0.9921875\n",
      "Batch: 47, Loss: 0.052614107728004456, Accuracy: 0.9892578125\n",
      "Batch: 48, Loss: 0.05036671459674835, Accuracy: 0.990234375\n",
      "Batch: 49, Loss: 0.034748733043670654, Accuracy: 0.9921875\n",
      "Batch: 50, Loss: 0.053035371005535126, Accuracy: 0.9873046875\n",
      "Batch: 51, Loss: 0.04604753106832504, Accuracy: 0.990234375\n",
      "Batch: 52, Loss: 0.05228601023554802, Accuracy: 0.990234375\n",
      "Batch: 53, Loss: 0.04176397994160652, Accuracy: 0.9921875\n",
      "Batch: 54, Loss: 0.03417355567216873, Accuracy: 0.9951171875\n",
      "Batch: 55, Loss: 0.03490864858031273, Accuracy: 0.990234375\n",
      "Batch: 56, Loss: 0.04544166848063469, Accuracy: 0.9921875\n",
      "Batch: 57, Loss: 0.03658581152558327, Accuracy: 0.9912109375\n",
      "Batch: 58, Loss: 0.03257010132074356, Accuracy: 0.994140625\n",
      "Batch: 59, Loss: 0.047827813774347305, Accuracy: 0.9892578125\n",
      "Batch: 60, Loss: 0.03977040573954582, Accuracy: 0.9912109375\n",
      "Batch: 61, Loss: 0.040556907653808594, Accuracy: 0.9912109375\n",
      "Batch: 62, Loss: 0.046232663094997406, Accuracy: 0.9892578125\n",
      "Batch: 63, Loss: 0.02755596861243248, Accuracy: 0.994140625\n",
      "Batch: 64, Loss: 0.05185693874955177, Accuracy: 0.9892578125\n",
      "Batch: 65, Loss: 0.048272475600242615, Accuracy: 0.9912109375\n",
      "Batch: 66, Loss: 0.05198227986693382, Accuracy: 0.986328125\n",
      "Batch: 67, Loss: 0.059491027146577835, Accuracy: 0.9873046875\n",
      "Batch: 68, Loss: 0.04334374517202377, Accuracy: 0.9892578125\n",
      "Batch: 69, Loss: 0.0586552694439888, Accuracy: 0.9873046875\n",
      "Batch: 70, Loss: 0.03723910450935364, Accuracy: 0.9931640625\n",
      "Batch: 71, Loss: 0.052313972264528275, Accuracy: 0.990234375\n",
      "Batch: 72, Loss: 0.04006299749016762, Accuracy: 0.9921875\n",
      "Batch: 73, Loss: 0.04046790674328804, Accuracy: 0.994140625\n",
      "Batch: 74, Loss: 0.04203174635767937, Accuracy: 0.990234375\n",
      "Batch: 75, Loss: 0.04592984914779663, Accuracy: 0.9873046875\n",
      "Batch: 76, Loss: 0.04379120469093323, Accuracy: 0.990234375\n",
      "Batch: 77, Loss: 0.052722882479429245, Accuracy: 0.986328125\n",
      "Batch: 78, Loss: 0.03280072286725044, Accuracy: 0.9951171875\n",
      "Batch: 79, Loss: 0.04764317348599434, Accuracy: 0.990234375\n",
      "Batch: 80, Loss: 0.037749774754047394, Accuracy: 0.990234375\n",
      "Batch: 81, Loss: 0.030342858284711838, Accuracy: 0.994140625\n",
      "Batch: 82, Loss: 0.04737117141485214, Accuracy: 0.9912109375\n",
      "Batch: 83, Loss: 0.033276937901973724, Accuracy: 0.9921875\n",
      "Batch: 84, Loss: 0.04274696111679077, Accuracy: 0.9912109375\n",
      "Batch: 85, Loss: 0.037464018911123276, Accuracy: 0.9921875\n",
      "Batch: 86, Loss: 0.03377481922507286, Accuracy: 0.9912109375\n",
      "Batch: 87, Loss: 0.034207526594400406, Accuracy: 0.9931640625\n",
      "Batch: 88, Loss: 0.05475374683737755, Accuracy: 0.9912109375\n",
      "Batch: 89, Loss: 0.04095882549881935, Accuracy: 0.990234375\n",
      "Batch: 90, Loss: 0.03602170944213867, Accuracy: 0.9931640625\n",
      "Batch: 91, Loss: 0.0401487872004509, Accuracy: 0.9912109375\n",
      "Batch: 92, Loss: 0.05022308975458145, Accuracy: 0.98828125\n",
      "Batch: 93, Loss: 0.04449617490172386, Accuracy: 0.9931640625\n",
      "Batch: 94, Loss: 0.06009158119559288, Accuracy: 0.9892578125\n",
      "Batch: 95, Loss: 0.03398452699184418, Accuracy: 0.994140625\n",
      "Batch: 96, Loss: 0.04807818681001663, Accuracy: 0.990234375\n",
      "Batch: 97, Loss: 0.03843897953629494, Accuracy: 0.990234375\n",
      "Batch: 98, Loss: 0.04135103523731232, Accuracy: 0.990234375\n",
      "Batch: 99, Loss: 0.03697152063250542, Accuracy: 0.9892578125\n",
      "Batch: 100, Loss: 0.034914348274469376, Accuracy: 0.9912109375\n",
      "Batch: 101, Loss: 0.04163851961493492, Accuracy: 0.98828125\n",
      "Batch: 102, Loss: 0.034556854516267776, Accuracy: 0.9921875\n",
      "Batch: 103, Loss: 0.05229952186346054, Accuracy: 0.9912109375\n",
      "Batch: 104, Loss: 0.02782820351421833, Accuracy: 0.994140625\n",
      "Batch: 105, Loss: 0.04191203415393829, Accuracy: 0.9931640625\n",
      "Batch: 106, Loss: 0.053127650171518326, Accuracy: 0.990234375\n",
      "Batch: 107, Loss: 0.04271126911044121, Accuracy: 0.9921875\n",
      "Batch: 108, Loss: 0.054415687918663025, Accuracy: 0.9912109375\n",
      "Batch: 109, Loss: 0.040424905717372894, Accuracy: 0.9921875\n",
      "Batch: 110, Loss: 0.04342480003833771, Accuracy: 0.9912109375\n",
      "Batch: 111, Loss: 0.0358203761279583, Accuracy: 0.990234375\n",
      "Batch: 112, Loss: 0.032437682151794434, Accuracy: 0.9912109375\n",
      "Batch: 113, Loss: 0.04065566509962082, Accuracy: 0.9912109375\n",
      "Batch: 114, Loss: 0.05144605413079262, Accuracy: 0.98828125\n",
      "Batch: 115, Loss: 0.05253145471215248, Accuracy: 0.9873046875\n",
      "Batch: 116, Loss: 0.03629514202475548, Accuracy: 0.9921875\n",
      "Batch: 117, Loss: 0.04522518068552017, Accuracy: 0.9921875\n",
      "Batch: 118, Loss: 0.03920457884669304, Accuracy: 0.9912109375\n",
      "Batch: 119, Loss: 0.0338749885559082, Accuracy: 0.9921875\n",
      "Batch: 120, Loss: 0.045965034514665604, Accuracy: 0.9912109375\n",
      "Batch: 121, Loss: 0.04080747067928314, Accuracy: 0.9892578125\n",
      "Batch: 122, Loss: 0.021822279319167137, Accuracy: 0.99609375\n",
      "Batch: 123, Loss: 0.048024799674749374, Accuracy: 0.990234375\n",
      "Batch: 124, Loss: 0.05062369257211685, Accuracy: 0.9912109375\n",
      "Batch: 125, Loss: 0.06050088629126549, Accuracy: 0.98828125\n",
      "Batch: 126, Loss: 0.03621159866452217, Accuracy: 0.9912109375\n",
      "Batch: 127, Loss: 0.05248704180121422, Accuracy: 0.98828125\n",
      "Batch: 128, Loss: 0.0510922446846962, Accuracy: 0.9912109375\n",
      "Batch: 129, Loss: 0.031997643411159515, Accuracy: 0.994140625\n",
      "Batch: 130, Loss: 0.0412214919924736, Accuracy: 0.9912109375\n",
      "Batch: 131, Loss: 0.04470789432525635, Accuracy: 0.9912109375\n",
      "Batch: 132, Loss: 0.04291657730937004, Accuracy: 0.9912109375\n",
      "Batch: 133, Loss: 0.043200988322496414, Accuracy: 0.98828125\n",
      "Batch: 134, Loss: 0.0394212007522583, Accuracy: 0.9931640625\n",
      "Batch: 135, Loss: 0.029131675139069557, Accuracy: 0.9921875\n",
      "Batch: 136, Loss: 0.029591765254735947, Accuracy: 0.994140625\n",
      "Batch: 137, Loss: 0.040659938007593155, Accuracy: 0.9912109375\n",
      "Batch: 138, Loss: 0.03014548309147358, Accuracy: 0.9931640625\n",
      "Batch: 139, Loss: 0.05114717409014702, Accuracy: 0.9892578125\n",
      "Batch: 140, Loss: 0.045093052089214325, Accuracy: 0.9892578125\n",
      "Batch: 141, Loss: 0.03887927532196045, Accuracy: 0.990234375\n",
      "Batch: 142, Loss: 0.05552331358194351, Accuracy: 0.98828125\n",
      "Batch: 143, Loss: 0.040358711034059525, Accuracy: 0.9892578125\n",
      "Batch: 144, Loss: 0.038558658212423325, Accuracy: 0.9921875\n",
      "Batch: 145, Loss: 0.031834591180086136, Accuracy: 0.994140625\n",
      "Batch: 146, Loss: 0.05379124730825424, Accuracy: 0.986328125\n",
      "Batch: 147, Loss: 0.04362409561872482, Accuracy: 0.990234375\n",
      "Batch: 148, Loss: 0.03374195098876953, Accuracy: 0.9912109375\n",
      "Batch: 149, Loss: 0.03200663626194, Accuracy: 0.9931640625\n",
      "Batch: 150, Loss: 0.02348930388689041, Accuracy: 0.994140625\n",
      "Batch: 151, Loss: 0.028536494821310043, Accuracy: 0.9931640625\n",
      "Epoch 8/90\n",
      "Batch: 1, Loss: 0.03618890792131424, Accuracy: 0.9921875\n",
      "Batch: 2, Loss: 0.04182446748018265, Accuracy: 0.98828125\n",
      "Batch: 3, Loss: 0.039221350103616714, Accuracy: 0.9912109375\n",
      "Batch: 4, Loss: 0.02654912695288658, Accuracy: 0.9951171875\n",
      "Batch: 5, Loss: 0.036009229719638824, Accuracy: 0.9931640625\n",
      "Batch: 6, Loss: 0.050565022975206375, Accuracy: 0.9892578125\n",
      "Batch: 7, Loss: 0.019842609763145447, Accuracy: 0.9970703125\n",
      "Batch: 8, Loss: 0.023195862770080566, Accuracy: 0.994140625\n",
      "Batch: 9, Loss: 0.0444088950753212, Accuracy: 0.9912109375\n",
      "Batch: 10, Loss: 0.03686433658003807, Accuracy: 0.994140625\n",
      "Batch: 11, Loss: 0.04557854309678078, Accuracy: 0.9853515625\n",
      "Batch: 12, Loss: 0.04256422072649002, Accuracy: 0.990234375\n",
      "Batch: 13, Loss: 0.0345868319272995, Accuracy: 0.9912109375\n",
      "Batch: 14, Loss: 0.0295550674200058, Accuracy: 0.994140625\n",
      "Batch: 15, Loss: 0.04256778582930565, Accuracy: 0.990234375\n",
      "Batch: 16, Loss: 0.0410517156124115, Accuracy: 0.9921875\n",
      "Batch: 17, Loss: 0.04238252341747284, Accuracy: 0.9921875\n",
      "Batch: 18, Loss: 0.046306706964969635, Accuracy: 0.990234375\n",
      "Batch: 19, Loss: 0.044559165835380554, Accuracy: 0.9912109375\n",
      "Batch: 20, Loss: 0.05526179447770119, Accuracy: 0.990234375\n",
      "Batch: 21, Loss: 0.027603985741734505, Accuracy: 0.9931640625\n",
      "Batch: 22, Loss: 0.04393685609102249, Accuracy: 0.9873046875\n",
      "Batch: 23, Loss: 0.04164920747280121, Accuracy: 0.9912109375\n",
      "Batch: 24, Loss: 0.028398074209690094, Accuracy: 0.9931640625\n",
      "Batch: 25, Loss: 0.03067385032773018, Accuracy: 0.9912109375\n",
      "Batch: 26, Loss: 0.03721240535378456, Accuracy: 0.9912109375\n",
      "Batch: 27, Loss: 0.036742229014635086, Accuracy: 0.9892578125\n",
      "Batch: 28, Loss: 0.04301701486110687, Accuracy: 0.9912109375\n",
      "Batch: 29, Loss: 0.035699211061000824, Accuracy: 0.9931640625\n",
      "Batch: 30, Loss: 0.033932026475667953, Accuracy: 0.9912109375\n",
      "Batch: 31, Loss: 0.03729647025465965, Accuracy: 0.9912109375\n",
      "Batch: 32, Loss: 0.027156289666891098, Accuracy: 0.9931640625\n",
      "Batch: 33, Loss: 0.04590250179171562, Accuracy: 0.9892578125\n",
      "Batch: 34, Loss: 0.04938460886478424, Accuracy: 0.9892578125\n",
      "Batch: 35, Loss: 0.0437437929213047, Accuracy: 0.990234375\n",
      "Batch: 36, Loss: 0.03764635697007179, Accuracy: 0.9921875\n",
      "Batch: 37, Loss: 0.04787128418684006, Accuracy: 0.9931640625\n",
      "Batch: 38, Loss: 0.03554582595825195, Accuracy: 0.9921875\n",
      "Batch: 39, Loss: 0.03779026120901108, Accuracy: 0.9921875\n",
      "Batch: 40, Loss: 0.026884060353040695, Accuracy: 0.9921875\n",
      "Batch: 41, Loss: 0.03594563901424408, Accuracy: 0.9951171875\n",
      "Batch: 42, Loss: 0.030686892569065094, Accuracy: 0.9912109375\n",
      "Batch: 43, Loss: 0.036592572927474976, Accuracy: 0.9951171875\n",
      "Batch: 44, Loss: 0.04022977873682976, Accuracy: 0.9921875\n",
      "Batch: 45, Loss: 0.03277715668082237, Accuracy: 0.9921875\n",
      "Batch: 46, Loss: 0.03645975887775421, Accuracy: 0.9921875\n",
      "Batch: 47, Loss: 0.0489254929125309, Accuracy: 0.9892578125\n",
      "Batch: 48, Loss: 0.042402952909469604, Accuracy: 0.9912109375\n",
      "Batch: 49, Loss: 0.030062053352594376, Accuracy: 0.9951171875\n",
      "Batch: 50, Loss: 0.05342605337500572, Accuracy: 0.98828125\n",
      "Batch: 51, Loss: 0.03487387299537659, Accuracy: 0.9921875\n",
      "Batch: 52, Loss: 0.04135225713253021, Accuracy: 0.98828125\n",
      "Batch: 53, Loss: 0.036830395460128784, Accuracy: 0.994140625\n",
      "Batch: 54, Loss: 0.03281392529606819, Accuracy: 0.994140625\n",
      "Batch: 55, Loss: 0.03206875920295715, Accuracy: 0.9931640625\n",
      "Batch: 56, Loss: 0.041383348405361176, Accuracy: 0.9912109375\n",
      "Batch: 57, Loss: 0.03572052717208862, Accuracy: 0.9921875\n",
      "Batch: 58, Loss: 0.029441259801387787, Accuracy: 0.9951171875\n",
      "Batch: 59, Loss: 0.0394744873046875, Accuracy: 0.9921875\n",
      "Batch: 60, Loss: 0.0368935652077198, Accuracy: 0.9921875\n",
      "Batch: 61, Loss: 0.02603786252439022, Accuracy: 0.9931640625\n",
      "Batch: 62, Loss: 0.038128193467855453, Accuracy: 0.9912109375\n",
      "Batch: 63, Loss: 0.026652872562408447, Accuracy: 0.9931640625\n",
      "Batch: 64, Loss: 0.045104239135980606, Accuracy: 0.9912109375\n",
      "Batch: 65, Loss: 0.04340672120451927, Accuracy: 0.990234375\n",
      "Batch: 66, Loss: 0.04222413897514343, Accuracy: 0.9892578125\n",
      "Batch: 67, Loss: 0.04625092074275017, Accuracy: 0.9873046875\n",
      "Batch: 68, Loss: 0.04122147709131241, Accuracy: 0.990234375\n",
      "Batch: 69, Loss: 0.05425615981221199, Accuracy: 0.98828125\n",
      "Batch: 70, Loss: 0.02322334423661232, Accuracy: 0.9951171875\n",
      "Batch: 71, Loss: 0.03767792880535126, Accuracy: 0.990234375\n",
      "Batch: 72, Loss: 0.0308515727519989, Accuracy: 0.9912109375\n",
      "Batch: 73, Loss: 0.03971748426556587, Accuracy: 0.994140625\n",
      "Batch: 74, Loss: 0.026376798748970032, Accuracy: 0.9921875\n",
      "Batch: 75, Loss: 0.04405767470598221, Accuracy: 0.9892578125\n",
      "Batch: 76, Loss: 0.03896832838654518, Accuracy: 0.9912109375\n",
      "Batch: 77, Loss: 0.04307515174150467, Accuracy: 0.9892578125\n",
      "Batch: 78, Loss: 0.02566738985478878, Accuracy: 0.994140625\n",
      "Batch: 79, Loss: 0.03404820337891579, Accuracy: 0.9912109375\n",
      "Batch: 80, Loss: 0.03613683208823204, Accuracy: 0.9912109375\n",
      "Batch: 81, Loss: 0.024042658507823944, Accuracy: 0.9931640625\n",
      "Batch: 82, Loss: 0.03827247768640518, Accuracy: 0.9912109375\n",
      "Batch: 83, Loss: 0.03007452003657818, Accuracy: 0.9921875\n",
      "Batch: 84, Loss: 0.03354029729962349, Accuracy: 0.994140625\n",
      "Batch: 85, Loss: 0.027375169098377228, Accuracy: 0.9951171875\n",
      "Batch: 86, Loss: 0.0331084206700325, Accuracy: 0.9921875\n",
      "Batch: 87, Loss: 0.027906203642487526, Accuracy: 0.9931640625\n",
      "Batch: 88, Loss: 0.048358190804719925, Accuracy: 0.9921875\n",
      "Batch: 89, Loss: 0.03344769775867462, Accuracy: 0.9931640625\n",
      "Batch: 90, Loss: 0.025244908407330513, Accuracy: 0.9951171875\n",
      "Batch: 91, Loss: 0.032006993889808655, Accuracy: 0.9921875\n",
      "Batch: 92, Loss: 0.0354260578751564, Accuracy: 0.990234375\n",
      "Batch: 93, Loss: 0.033656977117061615, Accuracy: 0.994140625\n",
      "Batch: 94, Loss: 0.06117413565516472, Accuracy: 0.9892578125\n",
      "Batch: 95, Loss: 0.02906123176217079, Accuracy: 0.9931640625\n",
      "Batch: 96, Loss: 0.03667226433753967, Accuracy: 0.9921875\n",
      "Batch: 97, Loss: 0.031241096556186676, Accuracy: 0.990234375\n",
      "Batch: 98, Loss: 0.036475006490945816, Accuracy: 0.9921875\n",
      "Batch: 99, Loss: 0.025265105068683624, Accuracy: 0.994140625\n",
      "Batch: 100, Loss: 0.03133711591362953, Accuracy: 0.9912109375\n",
      "Batch: 101, Loss: 0.03246878832578659, Accuracy: 0.990234375\n",
      "Batch: 102, Loss: 0.026484716683626175, Accuracy: 0.9931640625\n",
      "Batch: 103, Loss: 0.04198286682367325, Accuracy: 0.9931640625\n",
      "Batch: 104, Loss: 0.024171795696020126, Accuracy: 0.9970703125\n",
      "Batch: 105, Loss: 0.04140860587358475, Accuracy: 0.9921875\n",
      "Batch: 106, Loss: 0.04007042571902275, Accuracy: 0.990234375\n",
      "Batch: 107, Loss: 0.028495753183960915, Accuracy: 0.9951171875\n",
      "Batch: 108, Loss: 0.04763296619057655, Accuracy: 0.9912109375\n",
      "Batch: 109, Loss: 0.03154079616069794, Accuracy: 0.9921875\n",
      "Batch: 110, Loss: 0.033417001366615295, Accuracy: 0.9892578125\n",
      "Batch: 111, Loss: 0.03241734579205513, Accuracy: 0.9921875\n",
      "Batch: 112, Loss: 0.03103996440768242, Accuracy: 0.9912109375\n",
      "Batch: 113, Loss: 0.026380764320492744, Accuracy: 0.994140625\n",
      "Batch: 114, Loss: 0.04109294340014458, Accuracy: 0.9892578125\n",
      "Batch: 115, Loss: 0.0463140569627285, Accuracy: 0.990234375\n",
      "Batch: 116, Loss: 0.034240156412124634, Accuracy: 0.990234375\n",
      "Batch: 117, Loss: 0.045416209846735, Accuracy: 0.9921875\n",
      "Batch: 118, Loss: 0.026445623487234116, Accuracy: 0.994140625\n",
      "Batch: 119, Loss: 0.02646821364760399, Accuracy: 0.994140625\n",
      "Batch: 120, Loss: 0.038841236382722855, Accuracy: 0.9892578125\n",
      "Batch: 121, Loss: 0.031940653920173645, Accuracy: 0.990234375\n",
      "Batch: 122, Loss: 0.02051902562379837, Accuracy: 0.9970703125\n",
      "Batch: 123, Loss: 0.03460533916950226, Accuracy: 0.9931640625\n",
      "Batch: 124, Loss: 0.04430089518427849, Accuracy: 0.9921875\n",
      "Batch: 125, Loss: 0.055116117000579834, Accuracy: 0.9912109375\n",
      "Batch: 126, Loss: 0.034536171704530716, Accuracy: 0.9912109375\n",
      "Batch: 127, Loss: 0.046307049691677094, Accuracy: 0.98828125\n",
      "Batch: 128, Loss: 0.05290069431066513, Accuracy: 0.98828125\n",
      "Batch: 129, Loss: 0.025445062667131424, Accuracy: 0.994140625\n",
      "Batch: 130, Loss: 0.032073769718408585, Accuracy: 0.994140625\n",
      "Batch: 131, Loss: 0.0354599803686142, Accuracy: 0.9931640625\n",
      "Batch: 132, Loss: 0.04366523399949074, Accuracy: 0.98828125\n",
      "Batch: 133, Loss: 0.035429324954748154, Accuracy: 0.9912109375\n",
      "Batch: 134, Loss: 0.03470822423696518, Accuracy: 0.9931640625\n",
      "Batch: 135, Loss: 0.026348639279603958, Accuracy: 0.994140625\n",
      "Batch: 136, Loss: 0.018414385616779327, Accuracy: 0.9951171875\n",
      "Batch: 137, Loss: 0.03499198704957962, Accuracy: 0.990234375\n",
      "Batch: 138, Loss: 0.024385036900639534, Accuracy: 0.9931640625\n",
      "Batch: 139, Loss: 0.039235133677721024, Accuracy: 0.9912109375\n",
      "Batch: 140, Loss: 0.03896201774477959, Accuracy: 0.990234375\n",
      "Batch: 141, Loss: 0.036853641271591187, Accuracy: 0.990234375\n",
      "Batch: 142, Loss: 0.0500582754611969, Accuracy: 0.9892578125\n",
      "Batch: 143, Loss: 0.025544583797454834, Accuracy: 0.9931640625\n",
      "Batch: 144, Loss: 0.03232577070593834, Accuracy: 0.9912109375\n",
      "Batch: 145, Loss: 0.02379467524588108, Accuracy: 0.9951171875\n",
      "Batch: 146, Loss: 0.04973411187529564, Accuracy: 0.9873046875\n",
      "Batch: 147, Loss: 0.03224828466773033, Accuracy: 0.994140625\n",
      "Batch: 148, Loss: 0.025158649310469627, Accuracy: 0.994140625\n",
      "Batch: 149, Loss: 0.023942727595567703, Accuracy: 0.9951171875\n",
      "Batch: 150, Loss: 0.023371972143650055, Accuracy: 0.9931640625\n",
      "Batch: 151, Loss: 0.02358235791325569, Accuracy: 0.9951171875\n",
      "Epoch 9/90\n",
      "Batch: 1, Loss: 0.03316831588745117, Accuracy: 0.9912109375\n",
      "Batch: 2, Loss: 0.033371664583683014, Accuracy: 0.9921875\n",
      "Batch: 3, Loss: 0.03181298077106476, Accuracy: 0.9921875\n",
      "Batch: 4, Loss: 0.02395438402891159, Accuracy: 0.990234375\n",
      "Batch: 5, Loss: 0.033605046570301056, Accuracy: 0.9921875\n",
      "Batch: 6, Loss: 0.048455704003572464, Accuracy: 0.98828125\n",
      "Batch: 7, Loss: 0.017613522708415985, Accuracy: 0.998046875\n",
      "Batch: 8, Loss: 0.017643816769123077, Accuracy: 0.9951171875\n",
      "Batch: 9, Loss: 0.03490569442510605, Accuracy: 0.9931640625\n",
      "Batch: 10, Loss: 0.03146195784211159, Accuracy: 0.9921875\n",
      "Batch: 11, Loss: 0.03364730253815651, Accuracy: 0.9912109375\n",
      "Batch: 12, Loss: 0.03912264481186867, Accuracy: 0.9912109375\n",
      "Batch: 13, Loss: 0.02783002331852913, Accuracy: 0.994140625\n",
      "Batch: 14, Loss: 0.02600179985165596, Accuracy: 0.9951171875\n",
      "Batch: 15, Loss: 0.03171774744987488, Accuracy: 0.9951171875\n",
      "Batch: 16, Loss: 0.03197448328137398, Accuracy: 0.9931640625\n",
      "Batch: 17, Loss: 0.0387202687561512, Accuracy: 0.9912109375\n",
      "Batch: 18, Loss: 0.04408472031354904, Accuracy: 0.9912109375\n",
      "Batch: 19, Loss: 0.03410733491182327, Accuracy: 0.9921875\n",
      "Batch: 20, Loss: 0.04412553459405899, Accuracy: 0.9921875\n",
      "Batch: 21, Loss: 0.02396492287516594, Accuracy: 0.9921875\n",
      "Batch: 22, Loss: 0.03577008470892906, Accuracy: 0.9892578125\n",
      "Batch: 23, Loss: 0.032664597034454346, Accuracy: 0.994140625\n",
      "Batch: 24, Loss: 0.02412811852991581, Accuracy: 0.9951171875\n",
      "Batch: 25, Loss: 0.018980275839567184, Accuracy: 0.99609375\n",
      "Batch: 26, Loss: 0.04146425798535347, Accuracy: 0.9912109375\n",
      "Batch: 27, Loss: 0.032888684421777725, Accuracy: 0.990234375\n",
      "Batch: 28, Loss: 0.03387515991926193, Accuracy: 0.9931640625\n",
      "Batch: 29, Loss: 0.021856220439076424, Accuracy: 0.99609375\n",
      "Batch: 30, Loss: 0.026398763060569763, Accuracy: 0.9951171875\n",
      "Batch: 31, Loss: 0.03177682310342789, Accuracy: 0.9951171875\n",
      "Batch: 32, Loss: 0.018094340339303017, Accuracy: 0.99609375\n",
      "Batch: 33, Loss: 0.03480380028486252, Accuracy: 0.9912109375\n",
      "Batch: 34, Loss: 0.039529286324977875, Accuracy: 0.9921875\n",
      "Batch: 35, Loss: 0.038745563477277756, Accuracy: 0.9931640625\n",
      "Batch: 36, Loss: 0.032865509390830994, Accuracy: 0.9921875\n",
      "Batch: 37, Loss: 0.04200354963541031, Accuracy: 0.9931640625\n",
      "Batch: 38, Loss: 0.032754696905612946, Accuracy: 0.9921875\n",
      "Batch: 39, Loss: 0.030694717541337013, Accuracy: 0.9892578125\n",
      "Batch: 40, Loss: 0.0201864056289196, Accuracy: 0.9951171875\n",
      "Batch: 41, Loss: 0.029144765809178352, Accuracy: 0.994140625\n",
      "Batch: 42, Loss: 0.02685256488621235, Accuracy: 0.9921875\n",
      "Batch: 43, Loss: 0.035241663455963135, Accuracy: 0.9931640625\n",
      "Batch: 44, Loss: 0.028047535568475723, Accuracy: 0.994140625\n",
      "Batch: 45, Loss: 0.02554275095462799, Accuracy: 0.9931640625\n",
      "Batch: 46, Loss: 0.03314186632633209, Accuracy: 0.9931640625\n",
      "Batch: 47, Loss: 0.0364508181810379, Accuracy: 0.9912109375\n",
      "Batch: 48, Loss: 0.03200290724635124, Accuracy: 0.9921875\n",
      "Batch: 49, Loss: 0.022882023826241493, Accuracy: 0.99609375\n",
      "Batch: 50, Loss: 0.035856425762176514, Accuracy: 0.9912109375\n",
      "Batch: 51, Loss: 0.02480534091591835, Accuracy: 0.994140625\n",
      "Batch: 52, Loss: 0.031960826367139816, Accuracy: 0.9931640625\n",
      "Batch: 53, Loss: 0.02918066643178463, Accuracy: 0.994140625\n",
      "Batch: 54, Loss: 0.025237467139959335, Accuracy: 0.9951171875\n",
      "Batch: 55, Loss: 0.022856852039694786, Accuracy: 0.9931640625\n",
      "Batch: 56, Loss: 0.035537511110305786, Accuracy: 0.9912109375\n",
      "Batch: 57, Loss: 0.03295140340924263, Accuracy: 0.9912109375\n",
      "Batch: 58, Loss: 0.023715242743492126, Accuracy: 0.994140625\n",
      "Batch: 59, Loss: 0.03209379315376282, Accuracy: 0.9912109375\n",
      "Batch: 60, Loss: 0.03008868731558323, Accuracy: 0.9921875\n",
      "Batch: 61, Loss: 0.023130886256694794, Accuracy: 0.9921875\n",
      "Batch: 62, Loss: 0.032758500427007675, Accuracy: 0.9951171875\n",
      "Batch: 63, Loss: 0.019562644883990288, Accuracy: 0.994140625\n",
      "Batch: 64, Loss: 0.037261221557855606, Accuracy: 0.9912109375\n",
      "Batch: 65, Loss: 0.03492336720228195, Accuracy: 0.9931640625\n",
      "Batch: 66, Loss: 0.03451550006866455, Accuracy: 0.9921875\n",
      "Batch: 67, Loss: 0.03795228898525238, Accuracy: 0.990234375\n",
      "Batch: 68, Loss: 0.035839326679706573, Accuracy: 0.9912109375\n",
      "Batch: 69, Loss: 0.041098590940237045, Accuracy: 0.9873046875\n",
      "Batch: 70, Loss: 0.021823840215802193, Accuracy: 0.99609375\n",
      "Batch: 71, Loss: 0.03229900822043419, Accuracy: 0.994140625\n",
      "Batch: 72, Loss: 0.03231922164559364, Accuracy: 0.9912109375\n",
      "Batch: 73, Loss: 0.03582553565502167, Accuracy: 0.9921875\n",
      "Batch: 74, Loss: 0.03098881244659424, Accuracy: 0.9912109375\n",
      "Batch: 75, Loss: 0.02846757508814335, Accuracy: 0.9921875\n",
      "Batch: 76, Loss: 0.03337534889578819, Accuracy: 0.9921875\n",
      "Batch: 77, Loss: 0.032545242458581924, Accuracy: 0.9921875\n",
      "Batch: 78, Loss: 0.018245719373226166, Accuracy: 0.9951171875\n",
      "Batch: 79, Loss: 0.03806736320257187, Accuracy: 0.990234375\n",
      "Batch: 80, Loss: 0.02622152864933014, Accuracy: 0.9951171875\n",
      "Batch: 81, Loss: 0.02745768427848816, Accuracy: 0.9912109375\n",
      "Batch: 82, Loss: 0.03707680478692055, Accuracy: 0.98828125\n",
      "Batch: 83, Loss: 0.024471573531627655, Accuracy: 0.9921875\n",
      "Batch: 84, Loss: 0.03289239853620529, Accuracy: 0.9931640625\n",
      "Batch: 85, Loss: 0.026454346254467964, Accuracy: 0.9951171875\n",
      "Batch: 86, Loss: 0.024433227255940437, Accuracy: 0.994140625\n",
      "Batch: 87, Loss: 0.02653772383928299, Accuracy: 0.994140625\n",
      "Batch: 88, Loss: 0.04462592676281929, Accuracy: 0.9892578125\n",
      "Batch: 89, Loss: 0.02926357463002205, Accuracy: 0.9931640625\n",
      "Batch: 90, Loss: 0.022963782772421837, Accuracy: 0.994140625\n",
      "Batch: 91, Loss: 0.025562601163983345, Accuracy: 0.9931640625\n",
      "Batch: 92, Loss: 0.03430527076125145, Accuracy: 0.9912109375\n",
      "Batch: 93, Loss: 0.02547970786690712, Accuracy: 0.9951171875\n",
      "Batch: 94, Loss: 0.053654689341783524, Accuracy: 0.990234375\n",
      "Batch: 95, Loss: 0.019817491993308067, Accuracy: 0.9951171875\n",
      "Batch: 96, Loss: 0.037446457892656326, Accuracy: 0.9912109375\n",
      "Batch: 97, Loss: 0.020612027496099472, Accuracy: 0.9951171875\n",
      "Batch: 98, Loss: 0.021686602383852005, Accuracy: 0.99609375\n",
      "Batch: 99, Loss: 0.024249156937003136, Accuracy: 0.9931640625\n",
      "Batch: 100, Loss: 0.022552113980054855, Accuracy: 0.994140625\n",
      "Batch: 101, Loss: 0.022885743528604507, Accuracy: 0.994140625\n",
      "Batch: 102, Loss: 0.025805670768022537, Accuracy: 0.994140625\n",
      "Batch: 103, Loss: 0.0411779060959816, Accuracy: 0.9912109375\n",
      "Batch: 104, Loss: 0.01988138258457184, Accuracy: 0.9951171875\n",
      "Batch: 105, Loss: 0.03430115431547165, Accuracy: 0.994140625\n",
      "Batch: 106, Loss: 0.03285139426589012, Accuracy: 0.9912109375\n",
      "Batch: 107, Loss: 0.024217655882239342, Accuracy: 0.9931640625\n",
      "Batch: 108, Loss: 0.040918171405792236, Accuracy: 0.9921875\n",
      "Batch: 109, Loss: 0.028463445603847504, Accuracy: 0.9951171875\n",
      "Batch: 110, Loss: 0.02702946960926056, Accuracy: 0.994140625\n",
      "Batch: 111, Loss: 0.021329881623387337, Accuracy: 0.994140625\n",
      "Batch: 112, Loss: 0.018930338323116302, Accuracy: 0.99609375\n",
      "Batch: 113, Loss: 0.024287397041916847, Accuracy: 0.994140625\n",
      "Batch: 114, Loss: 0.026460547000169754, Accuracy: 0.9921875\n",
      "Batch: 115, Loss: 0.03313298523426056, Accuracy: 0.9921875\n",
      "Batch: 116, Loss: 0.024678196758031845, Accuracy: 0.9951171875\n",
      "Batch: 117, Loss: 0.030885230749845505, Accuracy: 0.994140625\n",
      "Batch: 118, Loss: 0.02446660026907921, Accuracy: 0.99609375\n",
      "Batch: 119, Loss: 0.020325204357504845, Accuracy: 0.9951171875\n",
      "Batch: 120, Loss: 0.034628335386514664, Accuracy: 0.9931640625\n",
      "Batch: 121, Loss: 0.028069112449884415, Accuracy: 0.9912109375\n",
      "Batch: 122, Loss: 0.01581500470638275, Accuracy: 0.998046875\n",
      "Batch: 123, Loss: 0.03020322509109974, Accuracy: 0.994140625\n",
      "Batch: 124, Loss: 0.03725767508149147, Accuracy: 0.9921875\n",
      "Batch: 125, Loss: 0.04166840389370918, Accuracy: 0.9931640625\n",
      "Batch: 126, Loss: 0.023792920634150505, Accuracy: 0.994140625\n",
      "Batch: 127, Loss: 0.041196368634700775, Accuracy: 0.9912109375\n",
      "Batch: 128, Loss: 0.03984678164124489, Accuracy: 0.9912109375\n",
      "Batch: 129, Loss: 0.019000252708792686, Accuracy: 0.99609375\n",
      "Batch: 130, Loss: 0.02974095568060875, Accuracy: 0.9921875\n",
      "Batch: 131, Loss: 0.03033008612692356, Accuracy: 0.9921875\n",
      "Batch: 132, Loss: 0.03153887391090393, Accuracy: 0.9931640625\n",
      "Batch: 133, Loss: 0.03171196207404137, Accuracy: 0.9921875\n",
      "Batch: 134, Loss: 0.029560178518295288, Accuracy: 0.9931640625\n",
      "Batch: 135, Loss: 0.020666006952524185, Accuracy: 0.994140625\n",
      "Batch: 136, Loss: 0.015165683813393116, Accuracy: 0.998046875\n",
      "Batch: 137, Loss: 0.027486395090818405, Accuracy: 0.9931640625\n",
      "Batch: 138, Loss: 0.01928599365055561, Accuracy: 0.994140625\n",
      "Batch: 139, Loss: 0.03048616461455822, Accuracy: 0.990234375\n",
      "Batch: 140, Loss: 0.030051812529563904, Accuracy: 0.9912109375\n",
      "Batch: 141, Loss: 0.025341002270579338, Accuracy: 0.994140625\n",
      "Batch: 142, Loss: 0.04207921773195267, Accuracy: 0.98828125\n",
      "Batch: 143, Loss: 0.024590538814663887, Accuracy: 0.9931640625\n",
      "Batch: 144, Loss: 0.02617090754210949, Accuracy: 0.994140625\n",
      "Batch: 145, Loss: 0.02662418596446514, Accuracy: 0.9921875\n",
      "Batch: 146, Loss: 0.032846901565790176, Accuracy: 0.9892578125\n",
      "Batch: 147, Loss: 0.02883850410580635, Accuracy: 0.9921875\n",
      "Batch: 148, Loss: 0.02310492843389511, Accuracy: 0.9921875\n",
      "Batch: 149, Loss: 0.020984329283237457, Accuracy: 0.9951171875\n",
      "Batch: 150, Loss: 0.018999306485056877, Accuracy: 0.9951171875\n",
      "Batch: 151, Loss: 0.019686440005898476, Accuracy: 0.99609375\n",
      "Epoch 10/90\n",
      "Batch: 1, Loss: 0.030979251489043236, Accuracy: 0.9921875\n",
      "Batch: 2, Loss: 0.03291267529129982, Accuracy: 0.9892578125\n",
      "Batch: 3, Loss: 0.02161272242665291, Accuracy: 0.998046875\n",
      "Batch: 4, Loss: 0.018508022651076317, Accuracy: 0.9951171875\n",
      "Batch: 5, Loss: 0.02721397764980793, Accuracy: 0.9921875\n",
      "Batch: 6, Loss: 0.039700355380773544, Accuracy: 0.9912109375\n",
      "Batch: 7, Loss: 0.017008675262331963, Accuracy: 0.994140625\n",
      "Batch: 8, Loss: 0.017105232924222946, Accuracy: 0.99609375\n",
      "Batch: 9, Loss: 0.025630423799157143, Accuracy: 0.9951171875\n",
      "Batch: 10, Loss: 0.028714710846543312, Accuracy: 0.9951171875\n",
      "Batch: 11, Loss: 0.02266157791018486, Accuracy: 0.994140625\n",
      "Batch: 12, Loss: 0.02927834913134575, Accuracy: 0.9931640625\n",
      "Batch: 13, Loss: 0.025453446432948112, Accuracy: 0.994140625\n",
      "Batch: 14, Loss: 0.02889583259820938, Accuracy: 0.994140625\n",
      "Batch: 15, Loss: 0.02658095955848694, Accuracy: 0.9951171875\n",
      "Batch: 16, Loss: 0.029146749526262283, Accuracy: 0.9921875\n",
      "Batch: 17, Loss: 0.02745644934475422, Accuracy: 0.994140625\n",
      "Batch: 18, Loss: 0.03484570235013962, Accuracy: 0.9912109375\n",
      "Batch: 19, Loss: 0.02423788234591484, Accuracy: 0.99609375\n",
      "Batch: 20, Loss: 0.038832686841487885, Accuracy: 0.9951171875\n",
      "Batch: 21, Loss: 0.029505472630262375, Accuracy: 0.9921875\n",
      "Batch: 22, Loss: 0.03969176486134529, Accuracy: 0.9921875\n",
      "Batch: 23, Loss: 0.027294469997286797, Accuracy: 0.9951171875\n",
      "Batch: 24, Loss: 0.015133854933083057, Accuracy: 0.9970703125\n",
      "Batch: 25, Loss: 0.023308295756578445, Accuracy: 0.994140625\n",
      "Batch: 26, Loss: 0.036565810441970825, Accuracy: 0.9921875\n",
      "Batch: 27, Loss: 0.02865588665008545, Accuracy: 0.9912109375\n",
      "Batch: 28, Loss: 0.030665427446365356, Accuracy: 0.994140625\n",
      "Batch: 29, Loss: 0.023055650293827057, Accuracy: 0.994140625\n",
      "Batch: 30, Loss: 0.017822695896029472, Accuracy: 0.9951171875\n",
      "Batch: 31, Loss: 0.02103414386510849, Accuracy: 0.99609375\n",
      "Batch: 32, Loss: 0.015438323840498924, Accuracy: 0.99609375\n",
      "Batch: 33, Loss: 0.027857067063450813, Accuracy: 0.9931640625\n",
      "Batch: 34, Loss: 0.030445650219917297, Accuracy: 0.9912109375\n",
      "Batch: 35, Loss: 0.029013050720095634, Accuracy: 0.9921875\n",
      "Batch: 36, Loss: 0.026884900406003, Accuracy: 0.9951171875\n",
      "Batch: 37, Loss: 0.0364421084523201, Accuracy: 0.994140625\n",
      "Batch: 38, Loss: 0.021911615505814552, Accuracy: 0.9951171875\n",
      "Batch: 39, Loss: 0.019759226590394974, Accuracy: 0.9951171875\n",
      "Batch: 40, Loss: 0.016183635219931602, Accuracy: 0.99609375\n",
      "Batch: 41, Loss: 0.02654096484184265, Accuracy: 0.994140625\n",
      "Batch: 42, Loss: 0.020993664860725403, Accuracy: 0.994140625\n",
      "Batch: 43, Loss: 0.023533549159765244, Accuracy: 0.99609375\n",
      "Batch: 44, Loss: 0.03155085816979408, Accuracy: 0.9921875\n",
      "Batch: 45, Loss: 0.025882508605718613, Accuracy: 0.994140625\n",
      "Batch: 46, Loss: 0.03061278723180294, Accuracy: 0.9931640625\n",
      "Batch: 47, Loss: 0.03695623204112053, Accuracy: 0.9921875\n",
      "Batch: 48, Loss: 0.03132101148366928, Accuracy: 0.9921875\n",
      "Batch: 49, Loss: 0.014122514054179192, Accuracy: 0.9951171875\n",
      "Batch: 50, Loss: 0.030459284782409668, Accuracy: 0.9921875\n",
      "Batch: 51, Loss: 0.020892353728413582, Accuracy: 0.994140625\n",
      "Batch: 52, Loss: 0.02571060322225094, Accuracy: 0.9921875\n",
      "Batch: 53, Loss: 0.024484088644385338, Accuracy: 0.9970703125\n",
      "Batch: 54, Loss: 0.02018718048930168, Accuracy: 0.99609375\n",
      "Batch: 55, Loss: 0.021618323400616646, Accuracy: 0.99609375\n",
      "Batch: 56, Loss: 0.024907585233449936, Accuracy: 0.9951171875\n",
      "Batch: 57, Loss: 0.025793254375457764, Accuracy: 0.994140625\n",
      "Batch: 58, Loss: 0.018044091761112213, Accuracy: 0.99609375\n",
      "Batch: 59, Loss: 0.026986604556441307, Accuracy: 0.9931640625\n",
      "Batch: 60, Loss: 0.024152545258402824, Accuracy: 0.99609375\n",
      "Batch: 61, Loss: 0.017674770206212997, Accuracy: 0.99609375\n",
      "Batch: 62, Loss: 0.031179821118712425, Accuracy: 0.994140625\n",
      "Batch: 63, Loss: 0.017768772318959236, Accuracy: 0.9951171875\n",
      "Batch: 64, Loss: 0.0337684229016304, Accuracy: 0.9921875\n",
      "Batch: 65, Loss: 0.028215957805514336, Accuracy: 0.9921875\n",
      "Batch: 66, Loss: 0.023824138566851616, Accuracy: 0.9931640625\n",
      "Batch: 67, Loss: 0.033565703779459, Accuracy: 0.9921875\n",
      "Batch: 68, Loss: 0.031688280403614044, Accuracy: 0.9912109375\n",
      "Batch: 69, Loss: 0.03406057134270668, Accuracy: 0.990234375\n",
      "Batch: 70, Loss: 0.018991220742464066, Accuracy: 0.99609375\n",
      "Batch: 71, Loss: 0.026346493512392044, Accuracy: 0.9951171875\n",
      "Batch: 72, Loss: 0.025014974176883698, Accuracy: 0.9931640625\n",
      "Batch: 73, Loss: 0.02398104779422283, Accuracy: 0.994140625\n",
      "Batch: 74, Loss: 0.0188443660736084, Accuracy: 0.9951171875\n",
      "Batch: 75, Loss: 0.029859088361263275, Accuracy: 0.9912109375\n",
      "Batch: 76, Loss: 0.02491852268576622, Accuracy: 0.9912109375\n",
      "Batch: 77, Loss: 0.022832687944173813, Accuracy: 0.9921875\n",
      "Batch: 78, Loss: 0.019206929951906204, Accuracy: 0.9951171875\n",
      "Batch: 79, Loss: 0.0259564071893692, Accuracy: 0.9931640625\n",
      "Batch: 80, Loss: 0.024699900299310684, Accuracy: 0.9912109375\n",
      "Batch: 81, Loss: 0.014168590307235718, Accuracy: 0.99609375\n",
      "Batch: 82, Loss: 0.023200353607535362, Accuracy: 0.9921875\n",
      "Batch: 83, Loss: 0.015010648407042027, Accuracy: 0.9970703125\n",
      "Batch: 84, Loss: 0.02267194353044033, Accuracy: 0.99609375\n",
      "Batch: 85, Loss: 0.022918425500392914, Accuracy: 0.9970703125\n",
      "Batch: 86, Loss: 0.02046848088502884, Accuracy: 0.994140625\n",
      "Batch: 87, Loss: 0.018792683258652687, Accuracy: 0.9951171875\n",
      "Batch: 88, Loss: 0.0348125696182251, Accuracy: 0.9921875\n",
      "Batch: 89, Loss: 0.019503654912114143, Accuracy: 0.994140625\n",
      "Batch: 90, Loss: 0.021273288875818253, Accuracy: 0.9951171875\n",
      "Batch: 91, Loss: 0.025687869638204575, Accuracy: 0.9912109375\n",
      "Batch: 92, Loss: 0.026108400896191597, Accuracy: 0.9921875\n",
      "Batch: 93, Loss: 0.02145833522081375, Accuracy: 0.994140625\n",
      "Batch: 94, Loss: 0.04128536954522133, Accuracy: 0.9912109375\n",
      "Batch: 95, Loss: 0.016013920307159424, Accuracy: 0.994140625\n",
      "Batch: 96, Loss: 0.03151953965425491, Accuracy: 0.9921875\n",
      "Batch: 97, Loss: 0.02001812495291233, Accuracy: 0.99609375\n",
      "Batch: 98, Loss: 0.02868771180510521, Accuracy: 0.994140625\n",
      "Batch: 99, Loss: 0.016043709591031075, Accuracy: 0.99609375\n",
      "Batch: 100, Loss: 0.02081776224076748, Accuracy: 0.9931640625\n",
      "Batch: 101, Loss: 0.024364255368709564, Accuracy: 0.9921875\n",
      "Batch: 102, Loss: 0.02367263473570347, Accuracy: 0.9951171875\n",
      "Batch: 103, Loss: 0.027521003037691116, Accuracy: 0.9921875\n",
      "Batch: 104, Loss: 0.01811913773417473, Accuracy: 0.9970703125\n",
      "Batch: 105, Loss: 0.029816884547472, Accuracy: 0.99609375\n",
      "Batch: 106, Loss: 0.02658788487315178, Accuracy: 0.9921875\n",
      "Batch: 107, Loss: 0.017421986907720566, Accuracy: 0.99609375\n",
      "Batch: 108, Loss: 0.030610717833042145, Accuracy: 0.9951171875\n",
      "Batch: 109, Loss: 0.020576803013682365, Accuracy: 0.9970703125\n",
      "Batch: 110, Loss: 0.020688354969024658, Accuracy: 0.9951171875\n",
      "Batch: 111, Loss: 0.02549166977405548, Accuracy: 0.9921875\n",
      "Batch: 112, Loss: 0.01693771407008171, Accuracy: 0.99609375\n",
      "Batch: 113, Loss: 0.015558653511106968, Accuracy: 0.99609375\n",
      "Batch: 114, Loss: 0.027716055512428284, Accuracy: 0.9921875\n",
      "Batch: 115, Loss: 0.029917925596237183, Accuracy: 0.994140625\n",
      "Batch: 116, Loss: 0.018699822947382927, Accuracy: 0.9970703125\n",
      "Batch: 117, Loss: 0.026858488097786903, Accuracy: 0.9912109375\n",
      "Batch: 118, Loss: 0.020523877814412117, Accuracy: 0.99609375\n",
      "Batch: 119, Loss: 0.016696089878678322, Accuracy: 0.994140625\n",
      "Batch: 120, Loss: 0.024680985137820244, Accuracy: 0.9921875\n",
      "Batch: 121, Loss: 0.028101401403546333, Accuracy: 0.9921875\n",
      "Batch: 122, Loss: 0.01983245089650154, Accuracy: 0.99609375\n",
      "Batch: 123, Loss: 0.025363273918628693, Accuracy: 0.9951171875\n",
      "Batch: 124, Loss: 0.03817925229668617, Accuracy: 0.9921875\n",
      "Batch: 125, Loss: 0.040231164544820786, Accuracy: 0.9912109375\n",
      "Batch: 126, Loss: 0.024277377873659134, Accuracy: 0.994140625\n",
      "Batch: 127, Loss: 0.026917286217212677, Accuracy: 0.9931640625\n",
      "Batch: 128, Loss: 0.030978290364146233, Accuracy: 0.9931640625\n",
      "Batch: 129, Loss: 0.024358347058296204, Accuracy: 0.9951171875\n",
      "Batch: 130, Loss: 0.022620249539613724, Accuracy: 0.9951171875\n",
      "Batch: 131, Loss: 0.0265407245606184, Accuracy: 0.9951171875\n",
      "Batch: 132, Loss: 0.028424005955457687, Accuracy: 0.9921875\n",
      "Batch: 133, Loss: 0.02380571886897087, Accuracy: 0.9921875\n",
      "Batch: 134, Loss: 0.02383553609251976, Accuracy: 0.994140625\n",
      "Batch: 135, Loss: 0.01913122832775116, Accuracy: 0.9970703125\n",
      "Batch: 136, Loss: 0.0148302111774683, Accuracy: 0.998046875\n",
      "Batch: 137, Loss: 0.022671792656183243, Accuracy: 0.9921875\n",
      "Batch: 138, Loss: 0.01999736577272415, Accuracy: 0.9951171875\n",
      "Batch: 139, Loss: 0.03455979377031326, Accuracy: 0.9912109375\n",
      "Batch: 140, Loss: 0.024435965344309807, Accuracy: 0.994140625\n",
      "Batch: 141, Loss: 0.019767414778470993, Accuracy: 0.99609375\n",
      "Batch: 142, Loss: 0.04094010591506958, Accuracy: 0.9892578125\n",
      "Batch: 143, Loss: 0.017960233613848686, Accuracy: 0.99609375\n",
      "Batch: 144, Loss: 0.020549504086375237, Accuracy: 0.994140625\n",
      "Batch: 145, Loss: 0.017331546172499657, Accuracy: 0.99609375\n",
      "Batch: 146, Loss: 0.02595704235136509, Accuracy: 0.9912109375\n",
      "Batch: 147, Loss: 0.019572217017412186, Accuracy: 0.9951171875\n",
      "Batch: 148, Loss: 0.01699904352426529, Accuracy: 0.9951171875\n",
      "Batch: 149, Loss: 0.015801403671503067, Accuracy: 0.99609375\n",
      "Batch: 150, Loss: 0.015883363783359528, Accuracy: 0.9951171875\n",
      "Batch: 151, Loss: 0.016004519537091255, Accuracy: 0.9970703125\n",
      "Saved Weights at epoch 10 to file Weights_10.h5\n",
      "Epoch 11/90\n",
      "Batch: 1, Loss: 0.019353855401277542, Accuracy: 0.994140625\n",
      "Batch: 2, Loss: 0.02728516422212124, Accuracy: 0.9921875\n",
      "Batch: 3, Loss: 0.017984911799430847, Accuracy: 0.994140625\n",
      "Batch: 4, Loss: 0.019813355058431625, Accuracy: 0.9921875\n",
      "Batch: 5, Loss: 0.018355850130319595, Accuracy: 0.9970703125\n",
      "Batch: 6, Loss: 0.0323326475918293, Accuracy: 0.9921875\n",
      "Batch: 7, Loss: 0.012818136252462864, Accuracy: 0.9970703125\n",
      "Batch: 8, Loss: 0.015039083547890186, Accuracy: 0.9970703125\n",
      "Batch: 9, Loss: 0.023627711459994316, Accuracy: 0.9951171875\n",
      "Batch: 10, Loss: 0.02709580399096012, Accuracy: 0.9951171875\n",
      "Batch: 11, Loss: 0.027805089950561523, Accuracy: 0.990234375\n",
      "Batch: 12, Loss: 0.02665708400309086, Accuracy: 0.994140625\n",
      "Batch: 13, Loss: 0.015788985416293144, Accuracy: 0.9970703125\n",
      "Batch: 14, Loss: 0.01932983286678791, Accuracy: 0.99609375\n",
      "Batch: 15, Loss: 0.025549856945872307, Accuracy: 0.9931640625\n",
      "Batch: 16, Loss: 0.02135610021650791, Accuracy: 0.99609375\n",
      "Batch: 17, Loss: 0.023545101284980774, Accuracy: 0.9951171875\n",
      "Batch: 18, Loss: 0.029398305341601372, Accuracy: 0.994140625\n",
      "Batch: 19, Loss: 0.023119933903217316, Accuracy: 0.9931640625\n",
      "Batch: 20, Loss: 0.03351287543773651, Accuracy: 0.994140625\n",
      "Batch: 21, Loss: 0.019876334816217422, Accuracy: 0.994140625\n",
      "Batch: 22, Loss: 0.02847588248550892, Accuracy: 0.9921875\n",
      "Batch: 23, Loss: 0.01805378869175911, Accuracy: 0.99609375\n",
      "Batch: 24, Loss: 0.014523720368742943, Accuracy: 0.998046875\n",
      "Batch: 25, Loss: 0.011943144723773003, Accuracy: 0.9990234375\n",
      "Batch: 26, Loss: 0.0369354709982872, Accuracy: 0.990234375\n",
      "Batch: 27, Loss: 0.02160092256963253, Accuracy: 0.9921875\n",
      "Batch: 28, Loss: 0.02336537279188633, Accuracy: 0.9951171875\n",
      "Batch: 29, Loss: 0.017463283613324165, Accuracy: 0.9970703125\n",
      "Batch: 30, Loss: 0.015242919325828552, Accuracy: 0.99609375\n",
      "Batch: 31, Loss: 0.022510144859552383, Accuracy: 0.9951171875\n",
      "Batch: 32, Loss: 0.010534771718084812, Accuracy: 0.998046875\n",
      "Batch: 33, Loss: 0.021174713969230652, Accuracy: 0.9951171875\n",
      "Batch: 34, Loss: 0.02935699373483658, Accuracy: 0.9912109375\n",
      "Batch: 35, Loss: 0.01774384081363678, Accuracy: 0.99609375\n",
      "Batch: 36, Loss: 0.023457570001482964, Accuracy: 0.9931640625\n",
      "Batch: 37, Loss: 0.026692533865571022, Accuracy: 0.99609375\n",
      "Batch: 38, Loss: 0.021061887964606285, Accuracy: 0.994140625\n",
      "Batch: 39, Loss: 0.02062215656042099, Accuracy: 0.9951171875\n",
      "Batch: 40, Loss: 0.013718006201088428, Accuracy: 0.998046875\n",
      "Batch: 41, Loss: 0.018871840089559555, Accuracy: 0.99609375\n",
      "Batch: 42, Loss: 0.019915137439966202, Accuracy: 0.9931640625\n",
      "Batch: 43, Loss: 0.021798381581902504, Accuracy: 0.99609375\n",
      "Batch: 44, Loss: 0.022455796599388123, Accuracy: 0.9931640625\n",
      "Batch: 45, Loss: 0.019347168505191803, Accuracy: 0.994140625\n",
      "Batch: 46, Loss: 0.02266746759414673, Accuracy: 0.9951171875\n",
      "Batch: 47, Loss: 0.026270201429724693, Accuracy: 0.9931640625\n",
      "Batch: 48, Loss: 0.0258671622723341, Accuracy: 0.9931640625\n",
      "Batch: 49, Loss: 0.011340156197547913, Accuracy: 0.9990234375\n",
      "Batch: 50, Loss: 0.02488027885556221, Accuracy: 0.9931640625\n",
      "Batch: 51, Loss: 0.016121400520205498, Accuracy: 0.99609375\n",
      "Batch: 52, Loss: 0.020982716232538223, Accuracy: 0.9951171875\n",
      "Batch: 53, Loss: 0.018504517152905464, Accuracy: 0.9970703125\n",
      "Batch: 54, Loss: 0.01644526980817318, Accuracy: 0.9951171875\n",
      "Batch: 55, Loss: 0.014712141826748848, Accuracy: 0.9990234375\n",
      "Batch: 56, Loss: 0.021209867671132088, Accuracy: 0.99609375\n",
      "Batch: 57, Loss: 0.020330918952822685, Accuracy: 0.9931640625\n",
      "Batch: 58, Loss: 0.013819150626659393, Accuracy: 0.99609375\n",
      "Batch: 59, Loss: 0.02121943235397339, Accuracy: 0.9951171875\n",
      "Batch: 60, Loss: 0.018218856304883957, Accuracy: 0.9931640625\n",
      "Batch: 61, Loss: 0.013128732331097126, Accuracy: 0.9970703125\n",
      "Batch: 62, Loss: 0.02379315346479416, Accuracy: 0.9931640625\n",
      "Batch: 63, Loss: 0.014763079583644867, Accuracy: 0.9970703125\n",
      "Batch: 64, Loss: 0.022123320028185844, Accuracy: 0.99609375\n",
      "Batch: 65, Loss: 0.022496819496154785, Accuracy: 0.9931640625\n",
      "Batch: 66, Loss: 0.022575777024030685, Accuracy: 0.994140625\n",
      "Batch: 67, Loss: 0.025185059756040573, Accuracy: 0.99609375\n",
      "Batch: 68, Loss: 0.02399328164756298, Accuracy: 0.9951171875\n",
      "Batch: 69, Loss: 0.022690068930387497, Accuracy: 0.9951171875\n",
      "Batch: 70, Loss: 0.01375794317573309, Accuracy: 0.9951171875\n",
      "Batch: 71, Loss: 0.026418231427669525, Accuracy: 0.9931640625\n",
      "Batch: 72, Loss: 0.017616376280784607, Accuracy: 0.9951171875\n",
      "Batch: 73, Loss: 0.02155294641852379, Accuracy: 0.9951171875\n",
      "Batch: 74, Loss: 0.015919167548418045, Accuracy: 0.9951171875\n",
      "Batch: 75, Loss: 0.02147163264453411, Accuracy: 0.99609375\n",
      "Batch: 76, Loss: 0.02264709770679474, Accuracy: 0.9921875\n",
      "Batch: 77, Loss: 0.02053302340209484, Accuracy: 0.9931640625\n",
      "Batch: 78, Loss: 0.011352546513080597, Accuracy: 0.998046875\n",
      "Batch: 79, Loss: 0.014130725525319576, Accuracy: 0.99609375\n",
      "Batch: 80, Loss: 0.016706669703125954, Accuracy: 0.99609375\n",
      "Batch: 81, Loss: 0.010747513733804226, Accuracy: 0.9970703125\n",
      "Batch: 82, Loss: 0.02367366850376129, Accuracy: 0.9931640625\n",
      "Batch: 83, Loss: 0.018861612305045128, Accuracy: 0.99609375\n",
      "Batch: 84, Loss: 0.01671392098069191, Accuracy: 0.9970703125\n",
      "Batch: 85, Loss: 0.01827281340956688, Accuracy: 0.9970703125\n",
      "Batch: 86, Loss: 0.01696745678782463, Accuracy: 0.9970703125\n",
      "Batch: 87, Loss: 0.014193754643201828, Accuracy: 0.9970703125\n",
      "Batch: 88, Loss: 0.03054085560142994, Accuracy: 0.9921875\n",
      "Batch: 89, Loss: 0.020656101405620575, Accuracy: 0.994140625\n",
      "Batch: 90, Loss: 0.019342515617609024, Accuracy: 0.99609375\n",
      "Batch: 91, Loss: 0.01842271164059639, Accuracy: 0.9931640625\n",
      "Batch: 92, Loss: 0.01766929402947426, Accuracy: 0.9951171875\n",
      "Batch: 93, Loss: 0.015092941001057625, Accuracy: 0.9970703125\n",
      "Batch: 94, Loss: 0.042126890271902084, Accuracy: 0.9912109375\n",
      "Batch: 95, Loss: 0.012430447153747082, Accuracy: 0.9970703125\n",
      "Batch: 96, Loss: 0.025603389367461205, Accuracy: 0.99609375\n",
      "Batch: 97, Loss: 0.017674537375569344, Accuracy: 0.99609375\n",
      "Batch: 98, Loss: 0.020613744854927063, Accuracy: 0.994140625\n",
      "Batch: 99, Loss: 0.01583542302250862, Accuracy: 0.9951171875\n",
      "Batch: 100, Loss: 0.012202547863125801, Accuracy: 0.998046875\n",
      "Batch: 101, Loss: 0.01779109425842762, Accuracy: 0.9912109375\n",
      "Batch: 102, Loss: 0.016360778361558914, Accuracy: 0.99609375\n",
      "Batch: 103, Loss: 0.027075301855802536, Accuracy: 0.9931640625\n",
      "Batch: 104, Loss: 0.011303804814815521, Accuracy: 0.998046875\n",
      "Batch: 105, Loss: 0.023606980219483376, Accuracy: 0.99609375\n",
      "Batch: 106, Loss: 0.017734766006469727, Accuracy: 0.9970703125\n",
      "Batch: 107, Loss: 0.018719354644417763, Accuracy: 0.994140625\n",
      "Batch: 108, Loss: 0.022882450371980667, Accuracy: 0.994140625\n",
      "Batch: 109, Loss: 0.018110334873199463, Accuracy: 0.9970703125\n",
      "Batch: 110, Loss: 0.02085929922759533, Accuracy: 0.9921875\n",
      "Batch: 111, Loss: 0.014315132051706314, Accuracy: 0.994140625\n",
      "Batch: 112, Loss: 0.020530210807919502, Accuracy: 0.994140625\n",
      "Batch: 113, Loss: 0.013757197186350822, Accuracy: 0.9970703125\n",
      "Batch: 114, Loss: 0.019114473834633827, Accuracy: 0.9951171875\n",
      "Batch: 115, Loss: 0.02329374849796295, Accuracy: 0.99609375\n",
      "Batch: 116, Loss: 0.01711888611316681, Accuracy: 0.9970703125\n",
      "Batch: 117, Loss: 0.019318033009767532, Accuracy: 0.99609375\n",
      "Batch: 118, Loss: 0.018614068627357483, Accuracy: 0.9931640625\n",
      "Batch: 119, Loss: 0.012148908339440823, Accuracy: 0.998046875\n",
      "Batch: 120, Loss: 0.020881054922938347, Accuracy: 0.994140625\n",
      "Batch: 121, Loss: 0.017788143828511238, Accuracy: 0.9951171875\n",
      "Batch: 122, Loss: 0.010315440595149994, Accuracy: 0.998046875\n",
      "Batch: 123, Loss: 0.018646104261279106, Accuracy: 0.9970703125\n",
      "Batch: 124, Loss: 0.026802562177181244, Accuracy: 0.994140625\n",
      "Batch: 125, Loss: 0.026257535442709923, Accuracy: 0.9921875\n",
      "Batch: 126, Loss: 0.019269363954663277, Accuracy: 0.994140625\n",
      "Batch: 127, Loss: 0.024605892598628998, Accuracy: 0.99609375\n",
      "Batch: 128, Loss: 0.02767103724181652, Accuracy: 0.9921875\n",
      "Batch: 129, Loss: 0.013897493481636047, Accuracy: 0.9951171875\n",
      "Batch: 130, Loss: 0.0236380435526371, Accuracy: 0.994140625\n",
      "Batch: 131, Loss: 0.018571332097053528, Accuracy: 0.9970703125\n",
      "Batch: 132, Loss: 0.0201420821249485, Accuracy: 0.994140625\n",
      "Batch: 133, Loss: 0.027368424460291862, Accuracy: 0.994140625\n",
      "Batch: 134, Loss: 0.021973012015223503, Accuracy: 0.99609375\n",
      "Batch: 135, Loss: 0.014309629797935486, Accuracy: 0.9970703125\n",
      "Batch: 136, Loss: 0.0116885369643569, Accuracy: 0.9970703125\n",
      "Batch: 137, Loss: 0.022430943325161934, Accuracy: 0.99609375\n",
      "Batch: 138, Loss: 0.016216065734624863, Accuracy: 0.99609375\n",
      "Batch: 139, Loss: 0.027767444029450417, Accuracy: 0.9931640625\n",
      "Batch: 140, Loss: 0.022201575338840485, Accuracy: 0.9931640625\n",
      "Batch: 141, Loss: 0.016198700293898582, Accuracy: 0.99609375\n",
      "Batch: 142, Loss: 0.02893437072634697, Accuracy: 0.9912109375\n",
      "Batch: 143, Loss: 0.014765998348593712, Accuracy: 0.9951171875\n",
      "Batch: 144, Loss: 0.01806217059493065, Accuracy: 0.99609375\n",
      "Batch: 145, Loss: 0.01309870183467865, Accuracy: 0.99609375\n",
      "Batch: 146, Loss: 0.019667215645313263, Accuracy: 0.9951171875\n",
      "Batch: 147, Loss: 0.017384810373187065, Accuracy: 0.9951171875\n",
      "Batch: 148, Loss: 0.013350829482078552, Accuracy: 0.99609375\n",
      "Batch: 149, Loss: 0.014346325770020485, Accuracy: 0.9970703125\n",
      "Batch: 150, Loss: 0.011702900752425194, Accuracy: 0.9990234375\n",
      "Batch: 151, Loss: 0.012500974349677563, Accuracy: 0.998046875\n",
      "Epoch 12/90\n",
      "Batch: 1, Loss: 0.020499931648373604, Accuracy: 0.9951171875\n",
      "Batch: 2, Loss: 0.02187110111117363, Accuracy: 0.994140625\n",
      "Batch: 3, Loss: 0.013931970112025738, Accuracy: 0.9970703125\n",
      "Batch: 4, Loss: 0.0112409433349967, Accuracy: 0.998046875\n",
      "Batch: 5, Loss: 0.0134683633223176, Accuracy: 0.99609375\n",
      "Batch: 6, Loss: 0.02742674946784973, Accuracy: 0.994140625\n",
      "Batch: 7, Loss: 0.011485467664897442, Accuracy: 0.9970703125\n",
      "Batch: 8, Loss: 0.009843125939369202, Accuracy: 0.9990234375\n",
      "Batch: 9, Loss: 0.02441643364727497, Accuracy: 0.9951171875\n",
      "Batch: 10, Loss: 0.02463085763156414, Accuracy: 0.9951171875\n",
      "Batch: 11, Loss: 0.0182713083922863, Accuracy: 0.9951171875\n",
      "Batch: 12, Loss: 0.024524249136447906, Accuracy: 0.9931640625\n",
      "Batch: 13, Loss: 0.014526029117405415, Accuracy: 0.998046875\n",
      "Batch: 14, Loss: 0.02056441456079483, Accuracy: 0.994140625\n",
      "Batch: 15, Loss: 0.020804286003112793, Accuracy: 0.9951171875\n",
      "Batch: 16, Loss: 0.022840645164251328, Accuracy: 0.994140625\n",
      "Batch: 17, Loss: 0.017128806561231613, Accuracy: 0.9951171875\n",
      "Batch: 18, Loss: 0.022363297641277313, Accuracy: 0.994140625\n",
      "Batch: 19, Loss: 0.01942574605345726, Accuracy: 0.99609375\n",
      "Batch: 20, Loss: 0.023699814453721046, Accuracy: 0.99609375\n",
      "Batch: 21, Loss: 0.017956888303160667, Accuracy: 0.994140625\n",
      "Batch: 22, Loss: 0.02936428040266037, Accuracy: 0.9912109375\n",
      "Batch: 23, Loss: 0.015186036936938763, Accuracy: 0.998046875\n",
      "Batch: 24, Loss: 0.011128054931759834, Accuracy: 0.998046875\n",
      "Batch: 25, Loss: 0.012382619082927704, Accuracy: 0.99609375\n",
      "Batch: 26, Loss: 0.027452129870653152, Accuracy: 0.9912109375\n",
      "Batch: 27, Loss: 0.01911838911473751, Accuracy: 0.9951171875\n",
      "Batch: 28, Loss: 0.01962817832827568, Accuracy: 0.99609375\n",
      "Batch: 29, Loss: 0.015049465000629425, Accuracy: 0.99609375\n",
      "Batch: 30, Loss: 0.012907505966722965, Accuracy: 0.9970703125\n",
      "Batch: 31, Loss: 0.014430301263928413, Accuracy: 0.99609375\n",
      "Batch: 32, Loss: 0.00936367828398943, Accuracy: 0.9990234375\n",
      "Batch: 33, Loss: 0.020149199292063713, Accuracy: 0.99609375\n",
      "Batch: 34, Loss: 0.023558957502245903, Accuracy: 0.994140625\n",
      "Batch: 35, Loss: 0.011037838645279408, Accuracy: 0.998046875\n",
      "Batch: 36, Loss: 0.014166784472763538, Accuracy: 0.99609375\n",
      "Batch: 37, Loss: 0.025370385497808456, Accuracy: 0.9951171875\n",
      "Batch: 38, Loss: 0.013417993672192097, Accuracy: 0.99609375\n",
      "Batch: 39, Loss: 0.019395004957914352, Accuracy: 0.9951171875\n",
      "Batch: 40, Loss: 0.01099025271832943, Accuracy: 0.9970703125\n",
      "Batch: 41, Loss: 0.015197811648249626, Accuracy: 0.99609375\n",
      "Batch: 42, Loss: 0.013865333981812, Accuracy: 0.9951171875\n",
      "Batch: 43, Loss: 0.015612873248755932, Accuracy: 0.994140625\n",
      "Batch: 44, Loss: 0.014178475365042686, Accuracy: 0.99609375\n",
      "Batch: 45, Loss: 0.015524588525295258, Accuracy: 0.9951171875\n",
      "Batch: 46, Loss: 0.024031803011894226, Accuracy: 0.994140625\n",
      "Batch: 47, Loss: 0.025317607447504997, Accuracy: 0.994140625\n",
      "Batch: 48, Loss: 0.014234383590519428, Accuracy: 0.99609375\n",
      "Batch: 49, Loss: 0.013075637631118298, Accuracy: 0.9970703125\n",
      "Batch: 50, Loss: 0.02065999060869217, Accuracy: 0.994140625\n",
      "Batch: 51, Loss: 0.012685338966548443, Accuracy: 0.9951171875\n",
      "Batch: 52, Loss: 0.02108899876475334, Accuracy: 0.99609375\n",
      "Batch: 53, Loss: 0.022456509992480278, Accuracy: 0.9951171875\n",
      "Batch: 54, Loss: 0.017533816397190094, Accuracy: 0.9931640625\n",
      "Batch: 55, Loss: 0.015710117295384407, Accuracy: 0.99609375\n",
      "Batch: 56, Loss: 0.020214920863509178, Accuracy: 0.9931640625\n",
      "Batch: 57, Loss: 0.020812146365642548, Accuracy: 0.9951171875\n",
      "Batch: 58, Loss: 0.014455901458859444, Accuracy: 0.9970703125\n",
      "Batch: 59, Loss: 0.020045142620801926, Accuracy: 0.99609375\n",
      "Batch: 60, Loss: 0.017000539228320122, Accuracy: 0.9970703125\n",
      "Batch: 61, Loss: 0.010958921164274216, Accuracy: 0.998046875\n",
      "Batch: 62, Loss: 0.02023082971572876, Accuracy: 0.99609375\n",
      "Batch: 63, Loss: 0.014314645901322365, Accuracy: 0.9970703125\n",
      "Batch: 64, Loss: 0.02414509281516075, Accuracy: 0.994140625\n",
      "Batch: 65, Loss: 0.018566202372312546, Accuracy: 0.99609375\n",
      "Batch: 66, Loss: 0.01598203554749489, Accuracy: 0.99609375\n",
      "Batch: 67, Loss: 0.020945154130458832, Accuracy: 0.9951171875\n",
      "Batch: 68, Loss: 0.017622262239456177, Accuracy: 0.99609375\n",
      "Batch: 69, Loss: 0.01868591457605362, Accuracy: 0.9951171875\n",
      "Batch: 70, Loss: 0.015069421380758286, Accuracy: 0.9970703125\n",
      "Batch: 71, Loss: 0.018895288929343224, Accuracy: 0.9951171875\n",
      "Batch: 72, Loss: 0.011740053072571754, Accuracy: 0.99609375\n",
      "Batch: 73, Loss: 0.021188393235206604, Accuracy: 0.994140625\n",
      "Batch: 74, Loss: 0.010764162056148052, Accuracy: 0.9970703125\n",
      "Batch: 75, Loss: 0.013655321672558784, Accuracy: 0.99609375\n",
      "Batch: 76, Loss: 0.02788378857076168, Accuracy: 0.9912109375\n",
      "Batch: 77, Loss: 0.018714137375354767, Accuracy: 0.994140625\n",
      "Batch: 78, Loss: 0.009731441736221313, Accuracy: 0.9990234375\n",
      "Batch: 79, Loss: 0.013695980422198772, Accuracy: 0.9951171875\n",
      "Batch: 80, Loss: 0.01792297139763832, Accuracy: 0.9951171875\n",
      "Batch: 81, Loss: 0.010154110379517078, Accuracy: 0.998046875\n",
      "Batch: 82, Loss: 0.019289512187242508, Accuracy: 0.994140625\n",
      "Batch: 83, Loss: 0.01090356893837452, Accuracy: 0.99609375\n",
      "Batch: 84, Loss: 0.016626102849841118, Accuracy: 0.9931640625\n",
      "Batch: 85, Loss: 0.016643710434436798, Accuracy: 0.9970703125\n",
      "Batch: 86, Loss: 0.010278800502419472, Accuracy: 0.998046875\n",
      "Batch: 87, Loss: 0.012906900607049465, Accuracy: 0.99609375\n",
      "Batch: 88, Loss: 0.023018114268779755, Accuracy: 0.994140625\n",
      "Batch: 89, Loss: 0.017155863344669342, Accuracy: 0.9951171875\n",
      "Batch: 90, Loss: 0.014701569452881813, Accuracy: 0.9970703125\n",
      "Batch: 91, Loss: 0.012757726013660431, Accuracy: 0.9951171875\n",
      "Batch: 92, Loss: 0.010682680644094944, Accuracy: 0.9970703125\n",
      "Batch: 93, Loss: 0.011289721354842186, Accuracy: 0.998046875\n",
      "Batch: 94, Loss: 0.03019501455128193, Accuracy: 0.994140625\n",
      "Batch: 95, Loss: 0.010709834285080433, Accuracy: 0.9970703125\n",
      "Batch: 96, Loss: 0.02111966721713543, Accuracy: 0.99609375\n",
      "Batch: 97, Loss: 0.011658900417387486, Accuracy: 0.9970703125\n",
      "Batch: 98, Loss: 0.014520224183797836, Accuracy: 0.998046875\n",
      "Batch: 99, Loss: 0.013751035556197166, Accuracy: 0.9951171875\n",
      "Batch: 100, Loss: 0.011461890302598476, Accuracy: 0.9970703125\n",
      "Batch: 101, Loss: 0.014605294913053513, Accuracy: 0.99609375\n",
      "Batch: 102, Loss: 0.013357963413000107, Accuracy: 0.9970703125\n",
      "Batch: 103, Loss: 0.014729417860507965, Accuracy: 0.994140625\n",
      "Batch: 104, Loss: 0.010375762358307838, Accuracy: 0.9990234375\n",
      "Batch: 105, Loss: 0.016407685354351997, Accuracy: 0.9970703125\n",
      "Batch: 106, Loss: 0.018424173817038536, Accuracy: 0.99609375\n",
      "Batch: 107, Loss: 0.014520948752760887, Accuracy: 0.9951171875\n",
      "Batch: 108, Loss: 0.020896494388580322, Accuracy: 0.99609375\n",
      "Batch: 109, Loss: 0.011317940428853035, Accuracy: 0.998046875\n",
      "Batch: 110, Loss: 0.012774484232068062, Accuracy: 0.9951171875\n",
      "Batch: 111, Loss: 0.007191295735538006, Accuracy: 0.9970703125\n",
      "Batch: 112, Loss: 0.009691411629319191, Accuracy: 0.998046875\n",
      "Batch: 113, Loss: 0.011762481182813644, Accuracy: 0.99609375\n",
      "Batch: 114, Loss: 0.011875858530402184, Accuracy: 0.9970703125\n",
      "Batch: 115, Loss: 0.01291748508810997, Accuracy: 0.99609375\n",
      "Batch: 116, Loss: 0.016530973836779594, Accuracy: 0.994140625\n",
      "Batch: 117, Loss: 0.014554604887962341, Accuracy: 0.9970703125\n",
      "Batch: 118, Loss: 0.015233860351145267, Accuracy: 0.9970703125\n",
      "Batch: 119, Loss: 0.014464244246482849, Accuracy: 0.994140625\n",
      "Batch: 120, Loss: 0.017393000423908234, Accuracy: 0.9970703125\n",
      "Batch: 121, Loss: 0.01649324968457222, Accuracy: 0.9931640625\n",
      "Batch: 122, Loss: 0.009002652950584888, Accuracy: 0.9990234375\n",
      "Batch: 123, Loss: 0.021265972405672073, Accuracy: 0.9951171875\n",
      "Batch: 124, Loss: 0.022578787058591843, Accuracy: 0.9931640625\n",
      "Batch: 125, Loss: 0.02487681806087494, Accuracy: 0.994140625\n",
      "Batch: 126, Loss: 0.019743110984563828, Accuracy: 0.994140625\n",
      "Batch: 127, Loss: 0.022656893357634544, Accuracy: 0.9931640625\n",
      "Batch: 128, Loss: 0.01844623126089573, Accuracy: 0.994140625\n",
      "Batch: 129, Loss: 0.013545051217079163, Accuracy: 0.9970703125\n",
      "Batch: 130, Loss: 0.01653723232448101, Accuracy: 0.9951171875\n",
      "Batch: 131, Loss: 0.015857180580496788, Accuracy: 0.998046875\n",
      "Batch: 132, Loss: 0.017913896590471268, Accuracy: 0.9951171875\n",
      "Batch: 133, Loss: 0.015798956155776978, Accuracy: 0.9970703125\n",
      "Batch: 134, Loss: 0.02522469125688076, Accuracy: 0.9951171875\n",
      "Batch: 135, Loss: 0.009851702488958836, Accuracy: 0.9970703125\n",
      "Batch: 136, Loss: 0.010563621297478676, Accuracy: 1.0\n",
      "Batch: 137, Loss: 0.01517956331372261, Accuracy: 0.994140625\n",
      "Batch: 138, Loss: 0.013613197021186352, Accuracy: 0.9951171875\n",
      "Batch: 139, Loss: 0.02001361921429634, Accuracy: 0.9951171875\n",
      "Batch: 140, Loss: 0.013514172285795212, Accuracy: 0.9951171875\n",
      "Batch: 141, Loss: 0.013268309645354748, Accuracy: 0.99609375\n",
      "Batch: 142, Loss: 0.02620934322476387, Accuracy: 0.9912109375\n",
      "Batch: 143, Loss: 0.00922522135078907, Accuracy: 0.998046875\n",
      "Batch: 144, Loss: 0.01911182515323162, Accuracy: 0.9951171875\n",
      "Batch: 145, Loss: 0.010594939813017845, Accuracy: 0.99609375\n",
      "Batch: 146, Loss: 0.022715356200933456, Accuracy: 0.994140625\n",
      "Batch: 147, Loss: 0.01370309293270111, Accuracy: 0.99609375\n",
      "Batch: 148, Loss: 0.017082683742046356, Accuracy: 0.994140625\n",
      "Batch: 149, Loss: 0.01001559104770422, Accuracy: 0.9970703125\n",
      "Batch: 150, Loss: 0.008912628516554832, Accuracy: 0.9970703125\n",
      "Batch: 151, Loss: 0.009438678622245789, Accuracy: 0.9970703125\n",
      "Epoch 13/90\n",
      "Batch: 1, Loss: 0.014085352420806885, Accuracy: 0.99609375\n",
      "Batch: 2, Loss: 0.0167748611420393, Accuracy: 0.9951171875\n",
      "Batch: 3, Loss: 0.011278349906206131, Accuracy: 0.998046875\n",
      "Batch: 4, Loss: 0.012459011748433113, Accuracy: 0.9970703125\n",
      "Batch: 5, Loss: 0.012634003534913063, Accuracy: 0.9970703125\n",
      "Batch: 6, Loss: 0.01636391691863537, Accuracy: 0.9951171875\n",
      "Batch: 7, Loss: 0.007079568691551685, Accuracy: 0.998046875\n",
      "Batch: 8, Loss: 0.00818332377821207, Accuracy: 0.998046875\n",
      "Batch: 9, Loss: 0.01005230750888586, Accuracy: 0.9970703125\n",
      "Batch: 10, Loss: 0.019565332680940628, Accuracy: 0.99609375\n",
      "Batch: 11, Loss: 0.018262524157762527, Accuracy: 0.99609375\n",
      "Batch: 12, Loss: 0.017572438344359398, Accuracy: 0.9931640625\n",
      "Batch: 13, Loss: 0.012588758021593094, Accuracy: 0.9970703125\n",
      "Batch: 14, Loss: 0.018315434455871582, Accuracy: 0.9970703125\n",
      "Batch: 15, Loss: 0.015432865358889103, Accuracy: 0.9970703125\n",
      "Batch: 16, Loss: 0.017522402107715607, Accuracy: 0.994140625\n",
      "Batch: 17, Loss: 0.019201168790459633, Accuracy: 0.9951171875\n",
      "Batch: 18, Loss: 0.015005635097622871, Accuracy: 0.99609375\n",
      "Batch: 19, Loss: 0.011335373856127262, Accuracy: 0.998046875\n",
      "Batch: 20, Loss: 0.02615232579410076, Accuracy: 0.994140625\n",
      "Batch: 21, Loss: 0.014729062095284462, Accuracy: 0.994140625\n",
      "Batch: 22, Loss: 0.02292015589773655, Accuracy: 0.994140625\n",
      "Batch: 23, Loss: 0.017854100093245506, Accuracy: 0.99609375\n",
      "Batch: 24, Loss: 0.011692816391587257, Accuracy: 0.998046875\n",
      "Batch: 25, Loss: 0.007677506655454636, Accuracy: 1.0\n",
      "Batch: 26, Loss: 0.01759689673781395, Accuracy: 0.994140625\n",
      "Batch: 27, Loss: 0.019029883667826653, Accuracy: 0.9931640625\n",
      "Batch: 28, Loss: 0.01638120226562023, Accuracy: 0.994140625\n",
      "Batch: 29, Loss: 0.013192405924201012, Accuracy: 0.998046875\n",
      "Batch: 30, Loss: 0.011165670119225979, Accuracy: 0.9970703125\n",
      "Batch: 31, Loss: 0.012286923825740814, Accuracy: 0.9970703125\n",
      "Batch: 32, Loss: 0.007055184338241816, Accuracy: 0.9990234375\n",
      "Batch: 33, Loss: 0.01564798876643181, Accuracy: 0.9970703125\n",
      "Batch: 34, Loss: 0.019771169871091843, Accuracy: 0.994140625\n",
      "Batch: 35, Loss: 0.012448805384337902, Accuracy: 0.99609375\n",
      "Batch: 36, Loss: 0.010445029474794865, Accuracy: 0.998046875\n",
      "Batch: 37, Loss: 0.02341114543378353, Accuracy: 0.9951171875\n",
      "Batch: 38, Loss: 0.013868181966245174, Accuracy: 0.994140625\n",
      "Batch: 39, Loss: 0.014164548367261887, Accuracy: 0.99609375\n",
      "Batch: 40, Loss: 0.009707499295473099, Accuracy: 0.998046875\n",
      "Batch: 41, Loss: 0.01166689582169056, Accuracy: 0.9970703125\n",
      "Batch: 42, Loss: 0.014811374247074127, Accuracy: 0.9970703125\n",
      "Batch: 43, Loss: 0.01139476615935564, Accuracy: 0.9970703125\n",
      "Batch: 44, Loss: 0.01170593872666359, Accuracy: 0.9951171875\n",
      "Batch: 45, Loss: 0.012609077617526054, Accuracy: 0.99609375\n",
      "Batch: 46, Loss: 0.019433509558439255, Accuracy: 0.994140625\n",
      "Batch: 47, Loss: 0.018426772207021713, Accuracy: 0.9951171875\n",
      "Batch: 48, Loss: 0.014557790011167526, Accuracy: 0.9951171875\n",
      "Batch: 49, Loss: 0.008771897293627262, Accuracy: 0.998046875\n",
      "Batch: 50, Loss: 0.01529626827687025, Accuracy: 0.99609375\n",
      "Batch: 51, Loss: 0.009749229066073895, Accuracy: 0.998046875\n",
      "Batch: 52, Loss: 0.017433684319257736, Accuracy: 0.9951171875\n",
      "Batch: 53, Loss: 0.016279516741633415, Accuracy: 0.994140625\n",
      "Batch: 54, Loss: 0.008659403771162033, Accuracy: 0.9970703125\n",
      "Batch: 55, Loss: 0.014388114213943481, Accuracy: 0.9970703125\n",
      "Batch: 56, Loss: 0.01685059815645218, Accuracy: 0.994140625\n",
      "Batch: 57, Loss: 0.015282021835446358, Accuracy: 0.9970703125\n",
      "Batch: 58, Loss: 0.006437826901674271, Accuracy: 0.9990234375\n",
      "Batch: 59, Loss: 0.010433521121740341, Accuracy: 0.998046875\n",
      "Batch: 60, Loss: 0.01854175329208374, Accuracy: 0.994140625\n",
      "Batch: 61, Loss: 0.011831804178655148, Accuracy: 0.99609375\n",
      "Batch: 62, Loss: 0.014178446494042873, Accuracy: 0.9970703125\n",
      "Batch: 63, Loss: 0.01141846552491188, Accuracy: 0.998046875\n",
      "Batch: 64, Loss: 0.021530425176024437, Accuracy: 0.9951171875\n",
      "Batch: 65, Loss: 0.0132629768922925, Accuracy: 0.99609375\n",
      "Batch: 66, Loss: 0.010316089726984501, Accuracy: 0.998046875\n",
      "Batch: 67, Loss: 0.016416501253843307, Accuracy: 0.994140625\n",
      "Batch: 68, Loss: 0.012783138081431389, Accuracy: 0.9970703125\n",
      "Batch: 69, Loss: 0.016302553936839104, Accuracy: 0.99609375\n",
      "Batch: 70, Loss: 0.009342417120933533, Accuracy: 0.998046875\n",
      "Batch: 71, Loss: 0.013571782037615776, Accuracy: 0.998046875\n",
      "Batch: 72, Loss: 0.009254715405404568, Accuracy: 0.9970703125\n",
      "Batch: 73, Loss: 0.010855784639716148, Accuracy: 0.9970703125\n",
      "Batch: 74, Loss: 0.01011737808585167, Accuracy: 0.998046875\n",
      "Batch: 75, Loss: 0.014311457052826881, Accuracy: 0.994140625\n",
      "Batch: 76, Loss: 0.014691726304590702, Accuracy: 0.9931640625\n",
      "Batch: 77, Loss: 0.013864267617464066, Accuracy: 0.9970703125\n",
      "Batch: 78, Loss: 0.008277405053377151, Accuracy: 0.998046875\n",
      "Batch: 79, Loss: 0.015875812619924545, Accuracy: 0.9951171875\n",
      "Batch: 80, Loss: 0.014396151527762413, Accuracy: 0.9970703125\n",
      "Batch: 81, Loss: 0.008157795295119286, Accuracy: 0.9990234375\n",
      "Batch: 82, Loss: 0.01313187088817358, Accuracy: 0.9970703125\n",
      "Batch: 83, Loss: 0.008567010052502155, Accuracy: 0.998046875\n",
      "Batch: 84, Loss: 0.014765642583370209, Accuracy: 0.99609375\n",
      "Batch: 85, Loss: 0.013136067427694798, Accuracy: 0.9970703125\n",
      "Batch: 86, Loss: 0.010523198172450066, Accuracy: 0.9970703125\n",
      "Batch: 87, Loss: 0.01038261130452156, Accuracy: 0.998046875\n",
      "Batch: 88, Loss: 0.01678459905087948, Accuracy: 0.99609375\n",
      "Batch: 89, Loss: 0.009853674098849297, Accuracy: 0.998046875\n",
      "Batch: 90, Loss: 0.006726670078933239, Accuracy: 0.998046875\n",
      "Batch: 91, Loss: 0.011297699995338917, Accuracy: 0.9970703125\n",
      "Batch: 92, Loss: 0.009363748133182526, Accuracy: 0.9970703125\n",
      "Batch: 93, Loss: 0.013514282181859016, Accuracy: 0.99609375\n",
      "Batch: 94, Loss: 0.024973418563604355, Accuracy: 0.99609375\n",
      "Batch: 95, Loss: 0.005723854526877403, Accuracy: 1.0\n",
      "Batch: 96, Loss: 0.014175190590322018, Accuracy: 0.9970703125\n",
      "Batch: 97, Loss: 0.013702698983252048, Accuracy: 0.9970703125\n",
      "Batch: 98, Loss: 0.017390090972185135, Accuracy: 0.9951171875\n",
      "Batch: 99, Loss: 0.011953138746321201, Accuracy: 0.99609375\n",
      "Batch: 100, Loss: 0.009437238797545433, Accuracy: 0.998046875\n",
      "Batch: 101, Loss: 0.014275469817221165, Accuracy: 0.99609375\n",
      "Batch: 102, Loss: 0.014182353392243385, Accuracy: 0.99609375\n",
      "Batch: 103, Loss: 0.011190038174390793, Accuracy: 0.9970703125\n",
      "Batch: 104, Loss: 0.00959614384919405, Accuracy: 0.998046875\n",
      "Batch: 105, Loss: 0.015297340229153633, Accuracy: 0.998046875\n",
      "Batch: 106, Loss: 0.01799030788242817, Accuracy: 0.9951171875\n",
      "Batch: 107, Loss: 0.011444751173257828, Accuracy: 0.99609375\n",
      "Batch: 108, Loss: 0.016968782991170883, Accuracy: 0.9951171875\n",
      "Batch: 109, Loss: 0.009957684203982353, Accuracy: 0.998046875\n",
      "Batch: 110, Loss: 0.008653301745653152, Accuracy: 0.99609375\n",
      "Batch: 111, Loss: 0.00814296305179596, Accuracy: 1.0\n",
      "Batch: 112, Loss: 0.012252646498382092, Accuracy: 0.9970703125\n",
      "Batch: 113, Loss: 0.0133137758821249, Accuracy: 0.9951171875\n",
      "Batch: 114, Loss: 0.010547920130193233, Accuracy: 0.9970703125\n",
      "Batch: 115, Loss: 0.009021262638270855, Accuracy: 0.998046875\n",
      "Batch: 116, Loss: 0.0067568267695605755, Accuracy: 0.9990234375\n",
      "Batch: 117, Loss: 0.009172240272164345, Accuracy: 0.998046875\n",
      "Batch: 118, Loss: 0.014283350668847561, Accuracy: 0.9970703125\n",
      "Batch: 119, Loss: 0.010221097618341446, Accuracy: 0.998046875\n",
      "Batch: 120, Loss: 0.014213531278073788, Accuracy: 0.9970703125\n",
      "Batch: 121, Loss: 0.014451677910983562, Accuracy: 0.99609375\n",
      "Batch: 122, Loss: 0.008469922468066216, Accuracy: 0.9970703125\n",
      "Batch: 123, Loss: 0.01583881303668022, Accuracy: 0.99609375\n",
      "Batch: 124, Loss: 0.017019931226968765, Accuracy: 0.99609375\n",
      "Batch: 125, Loss: 0.015619201585650444, Accuracy: 0.9970703125\n",
      "Batch: 126, Loss: 0.008913754485547543, Accuracy: 0.99609375\n",
      "Batch: 127, Loss: 0.01439695619046688, Accuracy: 0.9970703125\n",
      "Batch: 128, Loss: 0.018531113862991333, Accuracy: 0.9951171875\n",
      "Batch: 129, Loss: 0.008560268208384514, Accuracy: 0.998046875\n",
      "Batch: 130, Loss: 0.012537759728729725, Accuracy: 0.9970703125\n",
      "Batch: 131, Loss: 0.015393623150885105, Accuracy: 0.9951171875\n",
      "Batch: 132, Loss: 0.012629058212041855, Accuracy: 0.998046875\n",
      "Batch: 133, Loss: 0.01555672474205494, Accuracy: 0.9951171875\n",
      "Batch: 134, Loss: 0.019571814686059952, Accuracy: 0.99609375\n",
      "Batch: 135, Loss: 0.009889040142297745, Accuracy: 0.998046875\n",
      "Batch: 136, Loss: 0.006783859338611364, Accuracy: 0.9990234375\n",
      "Batch: 137, Loss: 0.015678077936172485, Accuracy: 0.994140625\n",
      "Batch: 138, Loss: 0.011480811052024364, Accuracy: 0.9951171875\n",
      "Batch: 139, Loss: 0.016114765778183937, Accuracy: 0.994140625\n",
      "Batch: 140, Loss: 0.015581220388412476, Accuracy: 0.994140625\n",
      "Batch: 141, Loss: 0.013909555040299892, Accuracy: 0.9970703125\n",
      "Batch: 142, Loss: 0.013118283823132515, Accuracy: 0.99609375\n",
      "Batch: 143, Loss: 0.010991143062710762, Accuracy: 0.9970703125\n",
      "Batch: 144, Loss: 0.014261536300182343, Accuracy: 0.9951171875\n",
      "Batch: 145, Loss: 0.009931357577443123, Accuracy: 0.998046875\n",
      "Batch: 146, Loss: 0.011175334453582764, Accuracy: 0.998046875\n",
      "Batch: 147, Loss: 0.00963518861681223, Accuracy: 0.9990234375\n",
      "Batch: 148, Loss: 0.009302953258156776, Accuracy: 0.998046875\n",
      "Batch: 149, Loss: 0.009625227190554142, Accuracy: 0.998046875\n",
      "Batch: 150, Loss: 0.00697726896032691, Accuracy: 1.0\n",
      "Batch: 151, Loss: 0.008021531626582146, Accuracy: 0.998046875\n",
      "Epoch 14/90\n",
      "Batch: 1, Loss: 0.011731826700270176, Accuracy: 0.9990234375\n",
      "Batch: 2, Loss: 0.01891092024743557, Accuracy: 0.9951171875\n",
      "Batch: 3, Loss: 0.008251737803220749, Accuracy: 0.998046875\n",
      "Batch: 4, Loss: 0.007621420081704855, Accuracy: 0.9990234375\n",
      "Batch: 5, Loss: 0.010156247764825821, Accuracy: 0.998046875\n",
      "Batch: 6, Loss: 0.01682242751121521, Accuracy: 0.99609375\n",
      "Batch: 7, Loss: 0.00885537639260292, Accuracy: 0.998046875\n",
      "Batch: 8, Loss: 0.008535507135093212, Accuracy: 0.998046875\n",
      "Batch: 9, Loss: 0.015586082823574543, Accuracy: 0.9970703125\n",
      "Batch: 10, Loss: 0.02030453272163868, Accuracy: 0.9970703125\n",
      "Batch: 11, Loss: 0.009615005925297737, Accuracy: 0.998046875\n",
      "Batch: 12, Loss: 0.015707997605204582, Accuracy: 0.9951171875\n",
      "Batch: 13, Loss: 0.006918491329997778, Accuracy: 0.998046875\n",
      "Batch: 14, Loss: 0.012505311518907547, Accuracy: 0.998046875\n",
      "Batch: 15, Loss: 0.008070245385169983, Accuracy: 0.9990234375\n",
      "Batch: 16, Loss: 0.013189905323088169, Accuracy: 0.9970703125\n",
      "Batch: 17, Loss: 0.0132878627628088, Accuracy: 0.994140625\n",
      "Batch: 18, Loss: 0.017341099679470062, Accuracy: 0.9951171875\n",
      "Batch: 19, Loss: 0.010329297743737698, Accuracy: 0.998046875\n",
      "Batch: 20, Loss: 0.019233299419283867, Accuracy: 0.9970703125\n",
      "Batch: 21, Loss: 0.013026311062276363, Accuracy: 0.998046875\n",
      "Batch: 22, Loss: 0.01660808175802231, Accuracy: 0.9951171875\n",
      "Batch: 23, Loss: 0.009511233307421207, Accuracy: 0.9990234375\n",
      "Batch: 24, Loss: 0.008654588833451271, Accuracy: 0.9990234375\n",
      "Batch: 25, Loss: 0.006076807156205177, Accuracy: 1.0\n",
      "Batch: 26, Loss: 0.01365429162979126, Accuracy: 0.9951171875\n",
      "Batch: 27, Loss: 0.010495795868337154, Accuracy: 0.9970703125\n",
      "Batch: 28, Loss: 0.00962284579873085, Accuracy: 0.99609375\n",
      "Batch: 29, Loss: 0.010915009304881096, Accuracy: 0.99609375\n",
      "Batch: 30, Loss: 0.013139884918928146, Accuracy: 0.99609375\n",
      "Batch: 31, Loss: 0.009121988900005817, Accuracy: 0.998046875\n",
      "Batch: 32, Loss: 0.006596491206437349, Accuracy: 0.9990234375\n",
      "Batch: 33, Loss: 0.010999191552400589, Accuracy: 0.998046875\n",
      "Batch: 34, Loss: 0.015164641663432121, Accuracy: 0.9970703125\n",
      "Batch: 35, Loss: 0.00830891914665699, Accuracy: 0.998046875\n",
      "Batch: 36, Loss: 0.011417442932724953, Accuracy: 0.9970703125\n",
      "Batch: 37, Loss: 0.015536527149379253, Accuracy: 0.9951171875\n",
      "Batch: 38, Loss: 0.010025259107351303, Accuracy: 0.9970703125\n",
      "Batch: 39, Loss: 0.007351574022322893, Accuracy: 1.0\n",
      "Batch: 40, Loss: 0.00988366175442934, Accuracy: 0.9970703125\n",
      "Batch: 41, Loss: 0.01134758535772562, Accuracy: 0.9970703125\n",
      "Batch: 42, Loss: 0.011037304066121578, Accuracy: 0.9970703125\n",
      "Batch: 43, Loss: 0.008707915432751179, Accuracy: 0.998046875\n",
      "Batch: 44, Loss: 0.007842520251870155, Accuracy: 0.9990234375\n",
      "Batch: 45, Loss: 0.010092194192111492, Accuracy: 0.998046875\n",
      "Batch: 46, Loss: 0.011124894954264164, Accuracy: 0.998046875\n",
      "Batch: 47, Loss: 0.021483270451426506, Accuracy: 0.9931640625\n",
      "Batch: 48, Loss: 0.01015107985585928, Accuracy: 0.9970703125\n",
      "Batch: 49, Loss: 0.007769577205181122, Accuracy: 0.998046875\n",
      "Batch: 50, Loss: 0.015249732881784439, Accuracy: 0.9951171875\n",
      "Batch: 51, Loss: 0.009803634136915207, Accuracy: 0.9970703125\n",
      "Batch: 52, Loss: 0.014081125147640705, Accuracy: 0.99609375\n",
      "Batch: 53, Loss: 0.015084529295563698, Accuracy: 0.99609375\n",
      "Batch: 54, Loss: 0.00830734334886074, Accuracy: 0.998046875\n",
      "Batch: 55, Loss: 0.012434393167495728, Accuracy: 0.9970703125\n",
      "Batch: 56, Loss: 0.012714607641100883, Accuracy: 0.9970703125\n",
      "Batch: 57, Loss: 0.01100501511245966, Accuracy: 0.998046875\n",
      "Batch: 58, Loss: 0.008718893863260746, Accuracy: 0.998046875\n",
      "Batch: 59, Loss: 0.012096553109586239, Accuracy: 0.99609375\n",
      "Batch: 60, Loss: 0.010580447502434254, Accuracy: 0.9970703125\n",
      "Batch: 61, Loss: 0.006761445663869381, Accuracy: 1.0\n",
      "Batch: 62, Loss: 0.012184923514723778, Accuracy: 0.9970703125\n",
      "Batch: 63, Loss: 0.014005114324390888, Accuracy: 0.99609375\n",
      "Batch: 64, Loss: 0.012121707201004028, Accuracy: 0.998046875\n",
      "Batch: 65, Loss: 0.01429184153676033, Accuracy: 0.9970703125\n",
      "Batch: 66, Loss: 0.009570172987878323, Accuracy: 0.998046875\n",
      "Batch: 67, Loss: 0.015224877744913101, Accuracy: 0.9951171875\n",
      "Batch: 68, Loss: 0.01615651324391365, Accuracy: 0.99609375\n",
      "Batch: 69, Loss: 0.014196665957570076, Accuracy: 0.9970703125\n",
      "Batch: 70, Loss: 0.01002725213766098, Accuracy: 0.998046875\n",
      "Batch: 71, Loss: 0.009529399685561657, Accuracy: 0.998046875\n",
      "Batch: 72, Loss: 0.009074395522475243, Accuracy: 0.998046875\n",
      "Batch: 73, Loss: 0.010001135058701038, Accuracy: 0.9970703125\n",
      "Batch: 74, Loss: 0.009316672571003437, Accuracy: 0.9970703125\n",
      "Batch: 75, Loss: 0.012267890386283398, Accuracy: 0.994140625\n",
      "Batch: 76, Loss: 0.0069395191967487335, Accuracy: 0.9990234375\n",
      "Batch: 77, Loss: 0.013371752575039864, Accuracy: 0.9951171875\n",
      "Batch: 78, Loss: 0.011135868728160858, Accuracy: 0.998046875\n",
      "Batch: 79, Loss: 0.008014804683625698, Accuracy: 0.9990234375\n",
      "Batch: 80, Loss: 0.010847468860447407, Accuracy: 0.99609375\n",
      "Batch: 81, Loss: 0.009449528530240059, Accuracy: 0.9970703125\n",
      "Batch: 82, Loss: 0.014696933329105377, Accuracy: 0.99609375\n",
      "Batch: 83, Loss: 0.008171270601451397, Accuracy: 0.99609375\n",
      "Batch: 84, Loss: 0.010326160117983818, Accuracy: 0.9970703125\n",
      "Batch: 85, Loss: 0.011279460042715073, Accuracy: 0.99609375\n",
      "Batch: 86, Loss: 0.007759016007184982, Accuracy: 0.9990234375\n",
      "Batch: 87, Loss: 0.00832922849804163, Accuracy: 0.9970703125\n",
      "Batch: 88, Loss: 0.018714169040322304, Accuracy: 0.994140625\n",
      "Batch: 89, Loss: 0.005815489683300257, Accuracy: 1.0\n",
      "Batch: 90, Loss: 0.009232942946255207, Accuracy: 0.9990234375\n",
      "Batch: 91, Loss: 0.009906626306474209, Accuracy: 0.9970703125\n",
      "Batch: 92, Loss: 0.012796049937605858, Accuracy: 0.998046875\n",
      "Batch: 93, Loss: 0.006966416724026203, Accuracy: 0.9990234375\n",
      "Batch: 94, Loss: 0.021326739341020584, Accuracy: 0.994140625\n",
      "Batch: 95, Loss: 0.00779793132096529, Accuracy: 0.9990234375\n",
      "Batch: 96, Loss: 0.01304538082331419, Accuracy: 0.9970703125\n",
      "Batch: 97, Loss: 0.008319742977619171, Accuracy: 0.998046875\n",
      "Batch: 98, Loss: 0.012157542631030083, Accuracy: 0.9970703125\n",
      "Batch: 99, Loss: 0.006950924172997475, Accuracy: 0.9990234375\n",
      "Batch: 100, Loss: 0.007760387845337391, Accuracy: 0.9990234375\n",
      "Batch: 101, Loss: 0.0084847928956151, Accuracy: 0.9990234375\n",
      "Batch: 102, Loss: 0.004207585472613573, Accuracy: 1.0\n",
      "Batch: 103, Loss: 0.011494262143969536, Accuracy: 0.998046875\n",
      "Batch: 104, Loss: 0.006857338361442089, Accuracy: 0.998046875\n",
      "Batch: 105, Loss: 0.011645428836345673, Accuracy: 0.9990234375\n",
      "Batch: 106, Loss: 0.011692632921040058, Accuracy: 0.9970703125\n",
      "Batch: 107, Loss: 0.007187508046627045, Accuracy: 0.998046875\n",
      "Batch: 108, Loss: 0.0129293417558074, Accuracy: 0.9970703125\n",
      "Batch: 109, Loss: 0.00992265623062849, Accuracy: 0.9990234375\n",
      "Batch: 110, Loss: 0.0057451906614005566, Accuracy: 0.998046875\n",
      "Batch: 111, Loss: 0.005136077292263508, Accuracy: 1.0\n",
      "Batch: 112, Loss: 0.004941174760460854, Accuracy: 1.0\n",
      "Batch: 113, Loss: 0.005489666946232319, Accuracy: 1.0\n",
      "Batch: 114, Loss: 0.008552441373467445, Accuracy: 0.998046875\n",
      "Batch: 115, Loss: 0.007792182732373476, Accuracy: 0.9990234375\n",
      "Batch: 116, Loss: 0.009327149949967861, Accuracy: 0.998046875\n",
      "Batch: 117, Loss: 0.009105517528951168, Accuracy: 0.9990234375\n",
      "Batch: 118, Loss: 0.010623984038829803, Accuracy: 0.9970703125\n",
      "Batch: 119, Loss: 0.007728904485702515, Accuracy: 0.998046875\n",
      "Batch: 120, Loss: 0.009421443566679955, Accuracy: 0.99609375\n",
      "Batch: 121, Loss: 0.009960192255675793, Accuracy: 0.998046875\n",
      "Batch: 122, Loss: 0.006944759748876095, Accuracy: 0.9990234375\n",
      "Batch: 123, Loss: 0.013885104097425938, Accuracy: 0.9990234375\n",
      "Batch: 124, Loss: 0.013935303315520287, Accuracy: 0.9970703125\n",
      "Batch: 125, Loss: 0.01337882038205862, Accuracy: 0.99609375\n",
      "Batch: 126, Loss: 0.012238258495926857, Accuracy: 0.99609375\n",
      "Batch: 127, Loss: 0.011334583163261414, Accuracy: 0.9970703125\n",
      "Batch: 128, Loss: 0.01175997406244278, Accuracy: 0.9970703125\n",
      "Batch: 129, Loss: 0.005157277919352055, Accuracy: 0.9990234375\n",
      "Batch: 130, Loss: 0.007412892300635576, Accuracy: 0.9990234375\n",
      "Batch: 131, Loss: 0.009812243282794952, Accuracy: 0.998046875\n",
      "Batch: 132, Loss: 0.01142239198088646, Accuracy: 0.9970703125\n",
      "Batch: 133, Loss: 0.014230463653802872, Accuracy: 0.9970703125\n",
      "Batch: 134, Loss: 0.017038796097040176, Accuracy: 0.9951171875\n",
      "Batch: 135, Loss: 0.007407860830426216, Accuracy: 0.998046875\n",
      "Batch: 136, Loss: 0.005567216780036688, Accuracy: 0.9990234375\n",
      "Batch: 137, Loss: 0.0071588060818612576, Accuracy: 0.9970703125\n",
      "Batch: 138, Loss: 0.00785275548696518, Accuracy: 0.99609375\n",
      "Batch: 139, Loss: 0.016877437010407448, Accuracy: 0.994140625\n",
      "Batch: 140, Loss: 0.011916966177523136, Accuracy: 0.998046875\n",
      "Batch: 141, Loss: 0.009602203033864498, Accuracy: 0.9970703125\n",
      "Batch: 142, Loss: 0.011932490393519402, Accuracy: 0.9990234375\n",
      "Batch: 143, Loss: 0.0063382224179804325, Accuracy: 1.0\n",
      "Batch: 144, Loss: 0.008388616144657135, Accuracy: 0.9990234375\n",
      "Batch: 145, Loss: 0.0075565543957054615, Accuracy: 0.9970703125\n",
      "Batch: 146, Loss: 0.010826030746102333, Accuracy: 0.998046875\n",
      "Batch: 147, Loss: 0.006307216826826334, Accuracy: 1.0\n",
      "Batch: 148, Loss: 0.007615986745804548, Accuracy: 0.9990234375\n",
      "Batch: 149, Loss: 0.004845771007239819, Accuracy: 1.0\n",
      "Batch: 150, Loss: 0.006336043123155832, Accuracy: 1.0\n",
      "Batch: 151, Loss: 0.004220798145979643, Accuracy: 0.9990234375\n",
      "Epoch 15/90\n",
      "Batch: 1, Loss: 0.009511813521385193, Accuracy: 0.9970703125\n",
      "Batch: 2, Loss: 0.011589747853577137, Accuracy: 0.9951171875\n",
      "Batch: 3, Loss: 0.005643993150442839, Accuracy: 0.9990234375\n",
      "Batch: 4, Loss: 0.010726520791649818, Accuracy: 0.99609375\n",
      "Batch: 5, Loss: 0.007013154216110706, Accuracy: 0.9990234375\n",
      "Batch: 6, Loss: 0.013832906261086464, Accuracy: 0.9970703125\n",
      "Batch: 7, Loss: 0.0063904039561748505, Accuracy: 0.9990234375\n",
      "Batch: 8, Loss: 0.005986768286675215, Accuracy: 1.0\n",
      "Batch: 9, Loss: 0.013579284772276878, Accuracy: 0.9970703125\n",
      "Batch: 10, Loss: 0.013668430037796497, Accuracy: 0.9970703125\n",
      "Batch: 11, Loss: 0.011226369068026543, Accuracy: 0.998046875\n",
      "Batch: 12, Loss: 0.008387650363147259, Accuracy: 0.9990234375\n",
      "Batch: 13, Loss: 0.00860697589814663, Accuracy: 0.9970703125\n",
      "Batch: 14, Loss: 0.01288316585123539, Accuracy: 0.99609375\n",
      "Batch: 15, Loss: 0.01278244610875845, Accuracy: 0.99609375\n",
      "Batch: 16, Loss: 0.007634587120264769, Accuracy: 0.998046875\n",
      "Batch: 17, Loss: 0.016164658591151237, Accuracy: 0.994140625\n",
      "Batch: 18, Loss: 0.008984921500086784, Accuracy: 0.998046875\n",
      "Batch: 19, Loss: 0.008424710482358932, Accuracy: 0.9990234375\n",
      "Batch: 20, Loss: 0.015648862347006798, Accuracy: 0.99609375\n",
      "Batch: 21, Loss: 0.008973836898803711, Accuracy: 0.9970703125\n",
      "Batch: 22, Loss: 0.012884637340903282, Accuracy: 0.998046875\n",
      "Batch: 23, Loss: 0.010593848302960396, Accuracy: 0.9970703125\n",
      "Batch: 24, Loss: 0.0064140004105865955, Accuracy: 0.9990234375\n",
      "Batch: 25, Loss: 0.005367550998926163, Accuracy: 1.0\n",
      "Batch: 26, Loss: 0.01120680570602417, Accuracy: 0.998046875\n",
      "Batch: 27, Loss: 0.01091025024652481, Accuracy: 0.9970703125\n",
      "Batch: 28, Loss: 0.008204814046621323, Accuracy: 0.9970703125\n",
      "Batch: 29, Loss: 0.005354397930204868, Accuracy: 1.0\n",
      "Batch: 30, Loss: 0.004894955083727837, Accuracy: 1.0\n",
      "Batch: 31, Loss: 0.011915469542145729, Accuracy: 0.994140625\n",
      "Batch: 32, Loss: 0.0043647270649671555, Accuracy: 1.0\n",
      "Batch: 33, Loss: 0.011380890384316444, Accuracy: 0.9970703125\n",
      "Batch: 34, Loss: 0.015222037211060524, Accuracy: 0.9951171875\n",
      "Batch: 35, Loss: 0.007402376737445593, Accuracy: 0.9990234375\n",
      "Batch: 36, Loss: 0.007422723341733217, Accuracy: 0.9990234375\n",
      "Batch: 37, Loss: 0.010126018896698952, Accuracy: 0.9970703125\n",
      "Batch: 38, Loss: 0.009084144607186317, Accuracy: 0.9970703125\n",
      "Batch: 39, Loss: 0.007529676426202059, Accuracy: 0.998046875\n",
      "Batch: 40, Loss: 0.006520479451864958, Accuracy: 0.9990234375\n",
      "Batch: 41, Loss: 0.00840773805975914, Accuracy: 0.9990234375\n",
      "Batch: 42, Loss: 0.013378195464611053, Accuracy: 0.99609375\n",
      "Batch: 43, Loss: 0.007219814229756594, Accuracy: 0.998046875\n",
      "Batch: 44, Loss: 0.007101436611264944, Accuracy: 0.9990234375\n",
      "Batch: 45, Loss: 0.010914018377661705, Accuracy: 0.998046875\n",
      "Batch: 46, Loss: 0.012062150985002518, Accuracy: 0.99609375\n",
      "Batch: 47, Loss: 0.014149690978229046, Accuracy: 0.9951171875\n",
      "Batch: 48, Loss: 0.0056107123382389545, Accuracy: 0.9990234375\n",
      "Batch: 49, Loss: 0.008897793479263783, Accuracy: 0.99609375\n",
      "Batch: 50, Loss: 0.00799916684627533, Accuracy: 0.998046875\n",
      "Batch: 51, Loss: 0.007658042013645172, Accuracy: 0.998046875\n",
      "Batch: 52, Loss: 0.005096812266856432, Accuracy: 1.0\n",
      "Batch: 53, Loss: 0.006622168235480785, Accuracy: 0.998046875\n",
      "Batch: 54, Loss: 0.005588275846093893, Accuracy: 0.9990234375\n",
      "Batch: 55, Loss: 0.007050997111946344, Accuracy: 0.9990234375\n",
      "Batch: 56, Loss: 0.005961433053016663, Accuracy: 0.9990234375\n",
      "Batch: 57, Loss: 0.006136041134595871, Accuracy: 0.998046875\n",
      "Batch: 58, Loss: 0.004431263078004122, Accuracy: 1.0\n",
      "Batch: 59, Loss: 0.008443353697657585, Accuracy: 0.9970703125\n",
      "Batch: 60, Loss: 0.010536436922848225, Accuracy: 0.9970703125\n",
      "Batch: 61, Loss: 0.004620111081749201, Accuracy: 0.9990234375\n",
      "Batch: 62, Loss: 0.008664115332067013, Accuracy: 0.998046875\n",
      "Batch: 63, Loss: 0.0050516556948423386, Accuracy: 0.9990234375\n",
      "Batch: 64, Loss: 0.010369901545345783, Accuracy: 0.9990234375\n",
      "Batch: 65, Loss: 0.008548040874302387, Accuracy: 0.9990234375\n",
      "Batch: 66, Loss: 0.007519217673689127, Accuracy: 0.9990234375\n",
      "Batch: 67, Loss: 0.01107068732380867, Accuracy: 0.9970703125\n",
      "Batch: 68, Loss: 0.010356064885854721, Accuracy: 0.9970703125\n",
      "Batch: 69, Loss: 0.012206008657813072, Accuracy: 0.9970703125\n",
      "Batch: 70, Loss: 0.008448084816336632, Accuracy: 0.998046875\n",
      "Batch: 71, Loss: 0.006402746774256229, Accuracy: 0.9990234375\n",
      "Batch: 72, Loss: 0.004811640828847885, Accuracy: 0.9990234375\n",
      "Batch: 73, Loss: 0.010602322407066822, Accuracy: 0.9951171875\n",
      "Batch: 74, Loss: 0.005889517720788717, Accuracy: 0.998046875\n",
      "Batch: 75, Loss: 0.006624911911785603, Accuracy: 0.998046875\n",
      "Batch: 76, Loss: 0.00695949699729681, Accuracy: 0.9990234375\n",
      "Batch: 77, Loss: 0.007040089461952448, Accuracy: 0.9990234375\n",
      "Batch: 78, Loss: 0.003247832413762808, Accuracy: 1.0\n",
      "Batch: 79, Loss: 0.011766812764108181, Accuracy: 0.998046875\n",
      "Batch: 80, Loss: 0.008989313617348671, Accuracy: 0.9970703125\n",
      "Batch: 81, Loss: 0.0036348788999021053, Accuracy: 1.0\n",
      "Batch: 82, Loss: 0.009328236803412437, Accuracy: 0.9951171875\n",
      "Batch: 83, Loss: 0.005692912731319666, Accuracy: 0.9990234375\n",
      "Batch: 84, Loss: 0.00495239207521081, Accuracy: 0.9990234375\n",
      "Batch: 85, Loss: 0.00684404605999589, Accuracy: 0.998046875\n",
      "Batch: 86, Loss: 0.00698026642203331, Accuracy: 0.998046875\n",
      "Batch: 87, Loss: 0.005682077258825302, Accuracy: 1.0\n",
      "Batch: 88, Loss: 0.012711363844573498, Accuracy: 0.9970703125\n",
      "Batch: 89, Loss: 0.007969500496983528, Accuracy: 0.9970703125\n",
      "Batch: 90, Loss: 0.007675799075514078, Accuracy: 0.998046875\n",
      "Batch: 91, Loss: 0.005248323082923889, Accuracy: 1.0\n",
      "Batch: 92, Loss: 0.00744725251570344, Accuracy: 0.9970703125\n",
      "Batch: 93, Loss: 0.0062700919806957245, Accuracy: 0.998046875\n",
      "Batch: 94, Loss: 0.02028418891131878, Accuracy: 0.99609375\n",
      "Batch: 95, Loss: 0.0038600240368396044, Accuracy: 1.0\n",
      "Batch: 96, Loss: 0.010648094117641449, Accuracy: 0.9990234375\n",
      "Batch: 97, Loss: 0.005684846080839634, Accuracy: 0.998046875\n",
      "Batch: 98, Loss: 0.0049355411902070045, Accuracy: 0.9990234375\n",
      "Batch: 99, Loss: 0.006509596016258001, Accuracy: 0.998046875\n",
      "Batch: 100, Loss: 0.003953527193516493, Accuracy: 1.0\n",
      "Batch: 101, Loss: 0.0077890669927001, Accuracy: 0.9990234375\n",
      "Batch: 102, Loss: 0.005899485200643539, Accuracy: 0.9990234375\n",
      "Batch: 103, Loss: 0.006343059707432985, Accuracy: 0.9990234375\n",
      "Batch: 104, Loss: 0.004462422337383032, Accuracy: 0.9990234375\n",
      "Batch: 105, Loss: 0.007604212965816259, Accuracy: 0.9990234375\n",
      "Batch: 106, Loss: 0.005598238669335842, Accuracy: 0.9990234375\n",
      "Batch: 107, Loss: 0.004325306508690119, Accuracy: 1.0\n",
      "Batch: 108, Loss: 0.009983566589653492, Accuracy: 0.9970703125\n",
      "Batch: 109, Loss: 0.006288638338446617, Accuracy: 0.9990234375\n",
      "Batch: 110, Loss: 0.006283888127654791, Accuracy: 0.9990234375\n",
      "Batch: 111, Loss: 0.007784408517181873, Accuracy: 0.9990234375\n",
      "Batch: 112, Loss: 0.008194993250072002, Accuracy: 0.99609375\n",
      "Batch: 113, Loss: 0.0076072001829743385, Accuracy: 0.9990234375\n",
      "Batch: 114, Loss: 0.006792214699089527, Accuracy: 0.9990234375\n",
      "Batch: 115, Loss: 0.009907787665724754, Accuracy: 0.998046875\n",
      "Batch: 116, Loss: 0.0077165262773633, Accuracy: 0.998046875\n",
      "Batch: 117, Loss: 0.0055668968707323074, Accuracy: 0.9990234375\n",
      "Batch: 118, Loss: 0.007635726593434811, Accuracy: 0.998046875\n",
      "Batch: 119, Loss: 0.003284241072833538, Accuracy: 1.0\n",
      "Batch: 120, Loss: 0.005563346203416586, Accuracy: 0.9990234375\n",
      "Batch: 121, Loss: 0.014319316484034061, Accuracy: 0.99609375\n",
      "Batch: 122, Loss: 0.005457418970763683, Accuracy: 0.9990234375\n",
      "Batch: 123, Loss: 0.012986686080694199, Accuracy: 0.998046875\n",
      "Batch: 124, Loss: 0.013428272679448128, Accuracy: 0.9931640625\n",
      "Batch: 125, Loss: 0.009043007157742977, Accuracy: 0.998046875\n",
      "Batch: 126, Loss: 0.004229482263326645, Accuracy: 1.0\n",
      "Batch: 127, Loss: 0.01162404753267765, Accuracy: 0.9970703125\n",
      "Batch: 128, Loss: 0.008289340883493423, Accuracy: 0.998046875\n",
      "Batch: 129, Loss: 0.008186224848031998, Accuracy: 0.99609375\n",
      "Batch: 130, Loss: 0.006601365748792887, Accuracy: 0.9990234375\n",
      "Batch: 131, Loss: 0.00839785672724247, Accuracy: 0.998046875\n",
      "Batch: 132, Loss: 0.006383751519024372, Accuracy: 0.9990234375\n",
      "Batch: 133, Loss: 0.009891427122056484, Accuracy: 0.9990234375\n",
      "Batch: 134, Loss: 0.015716738998889923, Accuracy: 0.9970703125\n",
      "Batch: 135, Loss: 0.006168698891997337, Accuracy: 0.9990234375\n",
      "Batch: 136, Loss: 0.005747429560869932, Accuracy: 0.9990234375\n",
      "Batch: 137, Loss: 0.006844541523605585, Accuracy: 0.9990234375\n",
      "Batch: 138, Loss: 0.006834631785750389, Accuracy: 0.998046875\n",
      "Batch: 139, Loss: 0.011908354237675667, Accuracy: 0.998046875\n",
      "Batch: 140, Loss: 0.010386699810624123, Accuracy: 0.998046875\n",
      "Batch: 141, Loss: 0.007231178693473339, Accuracy: 0.9990234375\n",
      "Batch: 142, Loss: 0.012273571453988552, Accuracy: 0.9970703125\n",
      "Batch: 143, Loss: 0.006612284574657679, Accuracy: 0.9990234375\n",
      "Batch: 144, Loss: 0.011883530765771866, Accuracy: 0.9970703125\n",
      "Batch: 145, Loss: 0.006201493088155985, Accuracy: 0.998046875\n",
      "Batch: 146, Loss: 0.007159940432757139, Accuracy: 0.998046875\n",
      "Batch: 147, Loss: 0.005279503762722015, Accuracy: 0.9990234375\n",
      "Batch: 148, Loss: 0.007007014937698841, Accuracy: 0.998046875\n",
      "Batch: 149, Loss: 0.006323882844299078, Accuracy: 0.9990234375\n",
      "Batch: 150, Loss: 0.0035719028674066067, Accuracy: 1.0\n",
      "Batch: 151, Loss: 0.004956555552780628, Accuracy: 0.9990234375\n",
      "Epoch 16/90\n",
      "Batch: 1, Loss: 0.00811736099421978, Accuracy: 0.9990234375\n",
      "Batch: 2, Loss: 0.0051600877195596695, Accuracy: 0.9990234375\n",
      "Batch: 3, Loss: 0.002547627314925194, Accuracy: 1.0\n",
      "Batch: 4, Loss: 0.005961195565760136, Accuracy: 1.0\n",
      "Batch: 5, Loss: 0.0055791838094592094, Accuracy: 0.9990234375\n",
      "Batch: 6, Loss: 0.011277830228209496, Accuracy: 0.998046875\n",
      "Batch: 7, Loss: 0.003914759960025549, Accuracy: 1.0\n",
      "Batch: 8, Loss: 0.006893831305205822, Accuracy: 0.9990234375\n",
      "Batch: 9, Loss: 0.01493591908365488, Accuracy: 0.9970703125\n",
      "Batch: 10, Loss: 0.011304180137813091, Accuracy: 0.998046875\n",
      "Batch: 11, Loss: 0.006945764180272818, Accuracy: 0.9970703125\n",
      "Batch: 12, Loss: 0.009012427181005478, Accuracy: 0.998046875\n",
      "Batch: 13, Loss: 0.008191470988094807, Accuracy: 0.99609375\n",
      "Batch: 14, Loss: 0.00532321073114872, Accuracy: 0.9990234375\n",
      "Batch: 15, Loss: 0.0041861324571073055, Accuracy: 1.0\n",
      "Batch: 16, Loss: 0.010056281462311745, Accuracy: 0.9970703125\n",
      "Batch: 17, Loss: 0.008416558615863323, Accuracy: 0.9970703125\n",
      "Batch: 18, Loss: 0.007019496522843838, Accuracy: 0.9970703125\n",
      "Batch: 19, Loss: 0.004867644514888525, Accuracy: 0.9990234375\n",
      "Batch: 20, Loss: 0.009518426842987537, Accuracy: 0.998046875\n",
      "Batch: 21, Loss: 0.00876474380493164, Accuracy: 0.9951171875\n",
      "Batch: 22, Loss: 0.015214295126497746, Accuracy: 0.994140625\n",
      "Batch: 23, Loss: 0.004596508573740721, Accuracy: 1.0\n",
      "Batch: 24, Loss: 0.007861228659749031, Accuracy: 0.9970703125\n",
      "Batch: 25, Loss: 0.007600721903145313, Accuracy: 0.998046875\n",
      "Batch: 26, Loss: 0.011280524544417858, Accuracy: 0.99609375\n",
      "Batch: 27, Loss: 0.013694333843886852, Accuracy: 0.9970703125\n",
      "Batch: 28, Loss: 0.009063850156962872, Accuracy: 0.9970703125\n",
      "Batch: 29, Loss: 0.005261968821287155, Accuracy: 0.9990234375\n",
      "Batch: 30, Loss: 0.006806845776736736, Accuracy: 0.998046875\n",
      "Batch: 31, Loss: 0.004862464033067226, Accuracy: 1.0\n",
      "Batch: 32, Loss: 0.007414600811898708, Accuracy: 0.998046875\n",
      "Batch: 33, Loss: 0.00963306799530983, Accuracy: 0.998046875\n",
      "Batch: 34, Loss: 0.010991251096129417, Accuracy: 0.9970703125\n",
      "Batch: 35, Loss: 0.008249015547335148, Accuracy: 0.998046875\n",
      "Batch: 36, Loss: 0.004952754359692335, Accuracy: 0.9990234375\n",
      "Batch: 37, Loss: 0.008567714132368565, Accuracy: 0.9970703125\n",
      "Batch: 38, Loss: 0.008199864067137241, Accuracy: 0.9970703125\n",
      "Batch: 39, Loss: 0.0047263470478355885, Accuracy: 1.0\n",
      "Batch: 40, Loss: 0.005330182611942291, Accuracy: 0.998046875\n",
      "Batch: 41, Loss: 0.004371676594018936, Accuracy: 1.0\n",
      "Batch: 42, Loss: 0.006212114822119474, Accuracy: 0.9990234375\n",
      "Batch: 43, Loss: 0.00848278496414423, Accuracy: 0.998046875\n",
      "Batch: 44, Loss: 0.009534715674817562, Accuracy: 0.998046875\n",
      "Batch: 45, Loss: 0.008127320557832718, Accuracy: 0.998046875\n",
      "Batch: 46, Loss: 0.008725389838218689, Accuracy: 0.9970703125\n",
      "Batch: 47, Loss: 0.008995269425213337, Accuracy: 0.99609375\n",
      "Batch: 48, Loss: 0.005929860286414623, Accuracy: 1.0\n",
      "Batch: 49, Loss: 0.004575877916067839, Accuracy: 1.0\n",
      "Batch: 50, Loss: 0.01312030665576458, Accuracy: 0.99609375\n",
      "Batch: 51, Loss: 0.004252762999385595, Accuracy: 1.0\n",
      "Batch: 52, Loss: 0.007360723335295916, Accuracy: 0.998046875\n",
      "Batch: 53, Loss: 0.007669413927942514, Accuracy: 0.998046875\n",
      "Batch: 54, Loss: 0.010665591806173325, Accuracy: 0.9970703125\n",
      "Batch: 55, Loss: 0.004229682497680187, Accuracy: 1.0\n",
      "Batch: 56, Loss: 0.005181320011615753, Accuracy: 0.9990234375\n",
      "Batch: 57, Loss: 0.004645457491278648, Accuracy: 1.0\n",
      "Batch: 58, Loss: 0.005839120596647263, Accuracy: 0.9990234375\n",
      "Batch: 59, Loss: 0.006384860724210739, Accuracy: 0.9990234375\n",
      "Batch: 60, Loss: 0.005630345083773136, Accuracy: 0.998046875\n",
      "Batch: 61, Loss: 0.004281232133507729, Accuracy: 1.0\n",
      "Batch: 62, Loss: 0.010607456788420677, Accuracy: 0.998046875\n",
      "Batch: 63, Loss: 0.006905193440616131, Accuracy: 0.9970703125\n",
      "Batch: 64, Loss: 0.008181450888514519, Accuracy: 0.9990234375\n",
      "Batch: 65, Loss: 0.005190218798816204, Accuracy: 1.0\n",
      "Batch: 66, Loss: 0.005096653010696173, Accuracy: 0.9990234375\n",
      "Batch: 67, Loss: 0.01088112872093916, Accuracy: 0.9951171875\n",
      "Batch: 68, Loss: 0.008993208408355713, Accuracy: 0.998046875\n",
      "Batch: 69, Loss: 0.011745237745344639, Accuracy: 0.9951171875\n",
      "Batch: 70, Loss: 0.00788167119026184, Accuracy: 0.9970703125\n",
      "Batch: 71, Loss: 0.005254845134913921, Accuracy: 1.0\n",
      "Batch: 72, Loss: 0.00778625812381506, Accuracy: 0.998046875\n",
      "Batch: 73, Loss: 0.005303909070789814, Accuracy: 0.9990234375\n",
      "Batch: 74, Loss: 0.004758452996611595, Accuracy: 1.0\n",
      "Batch: 75, Loss: 0.006043837405741215, Accuracy: 0.9990234375\n",
      "Batch: 76, Loss: 0.0083237886428833, Accuracy: 0.998046875\n",
      "Batch: 77, Loss: 0.005139216780662537, Accuracy: 1.0\n",
      "Batch: 78, Loss: 0.003537164069712162, Accuracy: 1.0\n",
      "Batch: 79, Loss: 0.010506770573556423, Accuracy: 0.9970703125\n",
      "Batch: 80, Loss: 0.012209966778755188, Accuracy: 0.9951171875\n",
      "Batch: 81, Loss: 0.003880088683217764, Accuracy: 0.9990234375\n",
      "Batch: 82, Loss: 0.00807458907365799, Accuracy: 0.9970703125\n",
      "Batch: 83, Loss: 0.003804607316851616, Accuracy: 0.9990234375\n",
      "Batch: 84, Loss: 0.005186983849853277, Accuracy: 0.9990234375\n",
      "Batch: 85, Loss: 0.003700008150190115, Accuracy: 1.0\n",
      "Batch: 86, Loss: 0.00900103896856308, Accuracy: 0.9970703125\n",
      "Batch: 87, Loss: 0.004000191576778889, Accuracy: 1.0\n",
      "Batch: 88, Loss: 0.010080031119287014, Accuracy: 0.9970703125\n",
      "Batch: 89, Loss: 0.005776331294327974, Accuracy: 0.9990234375\n",
      "Batch: 90, Loss: 0.005016727838665247, Accuracy: 0.998046875\n",
      "Batch: 91, Loss: 0.006173775531351566, Accuracy: 0.9990234375\n",
      "Batch: 92, Loss: 0.005553302355110645, Accuracy: 0.9990234375\n",
      "Batch: 93, Loss: 0.0036910530179739, Accuracy: 0.9990234375\n",
      "Batch: 94, Loss: 0.015553642064332962, Accuracy: 0.9970703125\n",
      "Batch: 95, Loss: 0.006382667925208807, Accuracy: 0.9990234375\n",
      "Batch: 96, Loss: 0.005750548094511032, Accuracy: 0.9990234375\n",
      "Batch: 97, Loss: 0.005234415177255869, Accuracy: 0.998046875\n",
      "Batch: 98, Loss: 0.0054424782283604145, Accuracy: 0.998046875\n",
      "Batch: 99, Loss: 0.004200313705950975, Accuracy: 1.0\n",
      "Batch: 100, Loss: 0.008667539805173874, Accuracy: 0.998046875\n",
      "Batch: 101, Loss: 0.004051585681736469, Accuracy: 0.9990234375\n",
      "Batch: 102, Loss: 0.004457158036530018, Accuracy: 1.0\n",
      "Batch: 103, Loss: 0.008539767935872078, Accuracy: 0.998046875\n",
      "Batch: 104, Loss: 0.0036808112636208534, Accuracy: 1.0\n",
      "Batch: 105, Loss: 0.0076387301087379456, Accuracy: 0.998046875\n",
      "Batch: 106, Loss: 0.009881853125989437, Accuracy: 0.9970703125\n",
      "Batch: 107, Loss: 0.003966373857110739, Accuracy: 1.0\n",
      "Batch: 108, Loss: 0.008175166323781013, Accuracy: 0.9990234375\n",
      "Batch: 109, Loss: 0.010295412503182888, Accuracy: 0.9970703125\n",
      "Batch: 110, Loss: 0.0055069951340556145, Accuracy: 0.998046875\n",
      "Batch: 111, Loss: 0.0038677328266203403, Accuracy: 1.0\n",
      "Batch: 112, Loss: 0.0052305664867162704, Accuracy: 1.0\n",
      "Batch: 113, Loss: 0.006058545783162117, Accuracy: 0.9990234375\n",
      "Batch: 114, Loss: 0.007258156314492226, Accuracy: 0.998046875\n",
      "Batch: 115, Loss: 0.008515591733157635, Accuracy: 0.998046875\n",
      "Batch: 116, Loss: 0.0048566400073468685, Accuracy: 1.0\n",
      "Batch: 117, Loss: 0.005482141859829426, Accuracy: 1.0\n",
      "Batch: 118, Loss: 0.006368913222104311, Accuracy: 0.9990234375\n",
      "Batch: 119, Loss: 0.004590441472828388, Accuracy: 1.0\n",
      "Batch: 120, Loss: 0.0043003978207707405, Accuracy: 1.0\n",
      "Batch: 121, Loss: 0.005301202647387981, Accuracy: 0.9990234375\n",
      "Batch: 122, Loss: 0.0035588103346526623, Accuracy: 1.0\n",
      "Batch: 123, Loss: 0.009408623911440372, Accuracy: 0.9990234375\n",
      "Batch: 124, Loss: 0.009071700274944305, Accuracy: 0.998046875\n",
      "Batch: 125, Loss: 0.00818589050322771, Accuracy: 0.99609375\n",
      "Batch: 126, Loss: 0.004850571043789387, Accuracy: 0.9990234375\n",
      "Batch: 127, Loss: 0.009331442415714264, Accuracy: 0.998046875\n",
      "Batch: 128, Loss: 0.009900939650833607, Accuracy: 0.9970703125\n",
      "Batch: 129, Loss: 0.0032144852448254824, Accuracy: 1.0\n",
      "Batch: 130, Loss: 0.007998655550181866, Accuracy: 0.9970703125\n",
      "Batch: 131, Loss: 0.006162670440971851, Accuracy: 0.9970703125\n",
      "Batch: 132, Loss: 0.006620955187827349, Accuracy: 0.9990234375\n",
      "Batch: 133, Loss: 0.006947828456759453, Accuracy: 0.998046875\n",
      "Batch: 134, Loss: 0.009738566353917122, Accuracy: 0.9970703125\n",
      "Batch: 135, Loss: 0.003591332118958235, Accuracy: 1.0\n",
      "Batch: 136, Loss: 0.003841047640889883, Accuracy: 1.0\n",
      "Batch: 137, Loss: 0.005809164140373468, Accuracy: 0.998046875\n",
      "Batch: 138, Loss: 0.0062316651456058025, Accuracy: 0.998046875\n",
      "Batch: 139, Loss: 0.008810538798570633, Accuracy: 0.99609375\n",
      "Batch: 140, Loss: 0.005983905866742134, Accuracy: 0.9990234375\n",
      "Batch: 141, Loss: 0.005290603265166283, Accuracy: 1.0\n",
      "Batch: 142, Loss: 0.008964859880506992, Accuracy: 0.9970703125\n",
      "Batch: 143, Loss: 0.004073871299624443, Accuracy: 0.9990234375\n",
      "Batch: 144, Loss: 0.005650495644658804, Accuracy: 0.9990234375\n",
      "Batch: 145, Loss: 0.005099372938275337, Accuracy: 0.9990234375\n",
      "Batch: 146, Loss: 0.0066366358660161495, Accuracy: 0.9990234375\n",
      "Batch: 147, Loss: 0.00526084192097187, Accuracy: 0.9990234375\n",
      "Batch: 148, Loss: 0.006561662070453167, Accuracy: 1.0\n",
      "Batch: 149, Loss: 0.003892810083925724, Accuracy: 1.0\n",
      "Batch: 150, Loss: 0.0044823456555604935, Accuracy: 0.9990234375\n",
      "Batch: 151, Loss: 0.004745438229292631, Accuracy: 0.9990234375\n",
      "Epoch 17/90\n",
      "Batch: 1, Loss: 0.00858017336577177, Accuracy: 0.998046875\n",
      "Batch: 2, Loss: 0.011317271739244461, Accuracy: 0.99609375\n",
      "Batch: 3, Loss: 0.005621761083602905, Accuracy: 0.9990234375\n",
      "Batch: 4, Loss: 0.0055887107737362385, Accuracy: 0.9970703125\n",
      "Batch: 5, Loss: 0.0038920543156564236, Accuracy: 1.0\n",
      "Batch: 6, Loss: 0.01034502126276493, Accuracy: 0.9970703125\n",
      "Batch: 7, Loss: 0.007437399588525295, Accuracy: 0.998046875\n",
      "Batch: 8, Loss: 0.0025189125444740057, Accuracy: 1.0\n",
      "Batch: 9, Loss: 0.011739902198314667, Accuracy: 0.9970703125\n",
      "Batch: 10, Loss: 0.007172009442001581, Accuracy: 0.9990234375\n",
      "Batch: 11, Loss: 0.004954037256538868, Accuracy: 0.9990234375\n",
      "Batch: 12, Loss: 0.009933409281075, Accuracy: 0.9970703125\n",
      "Batch: 13, Loss: 0.003264669794589281, Accuracy: 0.9990234375\n",
      "Batch: 14, Loss: 0.005848964676260948, Accuracy: 0.9990234375\n",
      "Batch: 15, Loss: 0.005071539431810379, Accuracy: 1.0\n",
      "Batch: 16, Loss: 0.004947836510837078, Accuracy: 0.998046875\n",
      "Batch: 17, Loss: 0.005409544799476862, Accuracy: 0.998046875\n",
      "Batch: 18, Loss: 0.005784427747130394, Accuracy: 0.9990234375\n",
      "Batch: 19, Loss: 0.004772717598825693, Accuracy: 0.9990234375\n",
      "Batch: 20, Loss: 0.0066081685945391655, Accuracy: 0.998046875\n",
      "Batch: 21, Loss: 0.007794704753905535, Accuracy: 0.9970703125\n",
      "Batch: 22, Loss: 0.008630958385765553, Accuracy: 0.9970703125\n",
      "Batch: 23, Loss: 0.0027594557031989098, Accuracy: 1.0\n",
      "Batch: 24, Loss: 0.0033614360727369785, Accuracy: 1.0\n",
      "Batch: 25, Loss: 0.004214264452457428, Accuracy: 1.0\n",
      "Batch: 26, Loss: 0.00934365764260292, Accuracy: 0.9970703125\n",
      "Batch: 27, Loss: 0.006228544283658266, Accuracy: 0.998046875\n",
      "Batch: 28, Loss: 0.005408026278018951, Accuracy: 0.998046875\n",
      "Batch: 29, Loss: 0.005430273246020079, Accuracy: 0.9990234375\n",
      "Batch: 30, Loss: 0.005012650042772293, Accuracy: 0.9990234375\n",
      "Batch: 31, Loss: 0.004539706744253635, Accuracy: 1.0\n",
      "Batch: 32, Loss: 0.0034832367673516273, Accuracy: 1.0\n",
      "Batch: 33, Loss: 0.008720135316252708, Accuracy: 0.9970703125\n",
      "Batch: 34, Loss: 0.007040028460323811, Accuracy: 0.998046875\n",
      "Batch: 35, Loss: 0.0039643594063818455, Accuracy: 0.9990234375\n",
      "Batch: 36, Loss: 0.00597384525462985, Accuracy: 0.9990234375\n",
      "Batch: 37, Loss: 0.0072694867849349976, Accuracy: 0.9970703125\n",
      "Batch: 38, Loss: 0.003455578815191984, Accuracy: 1.0\n",
      "Batch: 39, Loss: 0.006841261871159077, Accuracy: 0.9990234375\n",
      "Batch: 40, Loss: 0.004180654883384705, Accuracy: 1.0\n",
      "Batch: 41, Loss: 0.0055922563187778, Accuracy: 0.998046875\n",
      "Batch: 42, Loss: 0.005479276180267334, Accuracy: 0.9990234375\n",
      "Batch: 43, Loss: 0.004912360105663538, Accuracy: 0.9990234375\n",
      "Batch: 44, Loss: 0.005736150778830051, Accuracy: 0.9990234375\n",
      "Batch: 45, Loss: 0.006249584257602692, Accuracy: 0.998046875\n",
      "Batch: 46, Loss: 0.007312895730137825, Accuracy: 0.998046875\n",
      "Batch: 47, Loss: 0.01124000083655119, Accuracy: 0.998046875\n",
      "Batch: 48, Loss: 0.007327401079237461, Accuracy: 0.998046875\n",
      "Batch: 49, Loss: 0.004699294455349445, Accuracy: 0.9990234375\n",
      "Batch: 50, Loss: 0.007581664714962244, Accuracy: 0.998046875\n",
      "Batch: 51, Loss: 0.004392862785607576, Accuracy: 1.0\n",
      "Batch: 52, Loss: 0.005417553707957268, Accuracy: 0.9990234375\n",
      "Batch: 53, Loss: 0.0069822873920202255, Accuracy: 0.9970703125\n",
      "Batch: 54, Loss: 0.0025171046145260334, Accuracy: 1.0\n",
      "Batch: 55, Loss: 0.004990343935787678, Accuracy: 0.9990234375\n",
      "Batch: 56, Loss: 0.005566910374909639, Accuracy: 0.9990234375\n",
      "Batch: 57, Loss: 0.00504172733053565, Accuracy: 0.998046875\n",
      "Batch: 58, Loss: 0.002507513388991356, Accuracy: 1.0\n",
      "Batch: 59, Loss: 0.005277949385344982, Accuracy: 0.9990234375\n",
      "Batch: 60, Loss: 0.002784255426377058, Accuracy: 1.0\n",
      "Batch: 61, Loss: 0.0036213253624737263, Accuracy: 0.9990234375\n",
      "Batch: 62, Loss: 0.008189013227820396, Accuracy: 0.998046875\n",
      "Batch: 63, Loss: 0.004501571413129568, Accuracy: 0.9990234375\n",
      "Batch: 64, Loss: 0.006481460761278868, Accuracy: 0.9990234375\n",
      "Batch: 65, Loss: 0.006520595867186785, Accuracy: 0.998046875\n",
      "Batch: 66, Loss: 0.005582052748650312, Accuracy: 0.9990234375\n",
      "Batch: 67, Loss: 0.006587275303900242, Accuracy: 0.9970703125\n",
      "Batch: 68, Loss: 0.0040097227320075035, Accuracy: 1.0\n",
      "Batch: 69, Loss: 0.0054169390350580215, Accuracy: 0.9990234375\n",
      "Batch: 70, Loss: 0.0045560733415186405, Accuracy: 1.0\n",
      "Batch: 71, Loss: 0.007622899487614632, Accuracy: 0.998046875\n",
      "Batch: 72, Loss: 0.005606207065284252, Accuracy: 0.998046875\n",
      "Batch: 73, Loss: 0.004272122867405415, Accuracy: 1.0\n",
      "Batch: 74, Loss: 0.0054671987891197205, Accuracy: 0.998046875\n",
      "Batch: 75, Loss: 0.006041634827852249, Accuracy: 0.9990234375\n",
      "Batch: 76, Loss: 0.007820634171366692, Accuracy: 0.99609375\n",
      "Batch: 77, Loss: 0.00571799511089921, Accuracy: 0.9990234375\n",
      "Batch: 78, Loss: 0.007055466063320637, Accuracy: 0.998046875\n",
      "Batch: 79, Loss: 0.0055221919901669025, Accuracy: 0.998046875\n",
      "Batch: 80, Loss: 0.007256350480020046, Accuracy: 0.9990234375\n",
      "Batch: 81, Loss: 0.0035477119963616133, Accuracy: 0.998046875\n",
      "Batch: 82, Loss: 0.007919376716017723, Accuracy: 0.9990234375\n",
      "Batch: 83, Loss: 0.005201572086662054, Accuracy: 0.9990234375\n",
      "Batch: 84, Loss: 0.003272980684414506, Accuracy: 0.9990234375\n",
      "Batch: 85, Loss: 0.0047113304026424885, Accuracy: 0.9990234375\n",
      "Batch: 86, Loss: 0.004498403053730726, Accuracy: 1.0\n",
      "Batch: 87, Loss: 0.0035367512609809637, Accuracy: 1.0\n",
      "Batch: 88, Loss: 0.004187809303402901, Accuracy: 1.0\n",
      "Batch: 89, Loss: 0.004253721795976162, Accuracy: 1.0\n",
      "Batch: 90, Loss: 0.003174665616825223, Accuracy: 1.0\n",
      "Batch: 91, Loss: 0.0051535977981984615, Accuracy: 0.9990234375\n",
      "Batch: 92, Loss: 0.005316165275871754, Accuracy: 0.998046875\n",
      "Batch: 93, Loss: 0.005593369249254465, Accuracy: 0.9990234375\n",
      "Batch: 94, Loss: 0.01312919333577156, Accuracy: 0.9970703125\n",
      "Batch: 95, Loss: 0.003465051995590329, Accuracy: 1.0\n",
      "Batch: 96, Loss: 0.007301459088921547, Accuracy: 0.9990234375\n",
      "Batch: 97, Loss: 0.0028554447926580906, Accuracy: 1.0\n",
      "Batch: 98, Loss: 0.004082215949892998, Accuracy: 0.9990234375\n",
      "Batch: 99, Loss: 0.004732280038297176, Accuracy: 0.9990234375\n",
      "Batch: 100, Loss: 0.0057601663284003735, Accuracy: 0.9990234375\n",
      "Batch: 101, Loss: 0.004407166037708521, Accuracy: 0.9990234375\n",
      "Batch: 102, Loss: 0.004951483104377985, Accuracy: 0.9990234375\n",
      "Batch: 103, Loss: 0.004817030392587185, Accuracy: 1.0\n",
      "Batch: 104, Loss: 0.0044699921272695065, Accuracy: 0.9990234375\n",
      "Batch: 105, Loss: 0.0044487640261650085, Accuracy: 0.998046875\n",
      "Batch: 106, Loss: 0.006027581170201302, Accuracy: 0.998046875\n",
      "Batch: 107, Loss: 0.00406105350703001, Accuracy: 1.0\n",
      "Batch: 108, Loss: 0.005025472026318312, Accuracy: 0.9990234375\n",
      "Batch: 109, Loss: 0.003972379025071859, Accuracy: 0.9990234375\n",
      "Batch: 110, Loss: 0.004418307915329933, Accuracy: 0.9990234375\n",
      "Batch: 111, Loss: 0.004801412113010883, Accuracy: 0.9990234375\n",
      "Batch: 112, Loss: 0.004262592643499374, Accuracy: 1.0\n",
      "Batch: 113, Loss: 0.007419392000883818, Accuracy: 0.9990234375\n",
      "Batch: 114, Loss: 0.006829850375652313, Accuracy: 0.998046875\n",
      "Batch: 115, Loss: 0.0061361161060631275, Accuracy: 0.998046875\n",
      "Batch: 116, Loss: 0.004789086524397135, Accuracy: 0.9990234375\n",
      "Batch: 117, Loss: 0.003722126130014658, Accuracy: 1.0\n",
      "Batch: 118, Loss: 0.006504515185952187, Accuracy: 0.9970703125\n",
      "Batch: 119, Loss: 0.0026187438052147627, Accuracy: 1.0\n",
      "Batch: 120, Loss: 0.003786179469898343, Accuracy: 1.0\n",
      "Batch: 121, Loss: 0.0032777399756014347, Accuracy: 1.0\n",
      "Batch: 122, Loss: 0.0026792341377586126, Accuracy: 1.0\n",
      "Batch: 123, Loss: 0.005950169172137976, Accuracy: 0.9990234375\n",
      "Batch: 124, Loss: 0.008515063673257828, Accuracy: 0.998046875\n",
      "Batch: 125, Loss: 0.007098086178302765, Accuracy: 0.9990234375\n",
      "Batch: 126, Loss: 0.00879338476806879, Accuracy: 0.9970703125\n",
      "Batch: 127, Loss: 0.006027826573699713, Accuracy: 0.9990234375\n",
      "Batch: 128, Loss: 0.004544595256447792, Accuracy: 1.0\n",
      "Batch: 129, Loss: 0.004499852657318115, Accuracy: 0.9990234375\n",
      "Batch: 130, Loss: 0.0054867686703801155, Accuracy: 0.9990234375\n",
      "Batch: 131, Loss: 0.0052228509448468685, Accuracy: 0.9990234375\n",
      "Batch: 132, Loss: 0.0031081344932317734, Accuracy: 1.0\n",
      "Batch: 133, Loss: 0.008030837401747704, Accuracy: 0.998046875\n",
      "Batch: 134, Loss: 0.004224271047860384, Accuracy: 1.0\n",
      "Batch: 135, Loss: 0.003760307328775525, Accuracy: 1.0\n",
      "Batch: 136, Loss: 0.004973856266587973, Accuracy: 0.9990234375\n",
      "Batch: 137, Loss: 0.0026988915633410215, Accuracy: 1.0\n",
      "Batch: 138, Loss: 0.003155634505674243, Accuracy: 1.0\n",
      "Batch: 139, Loss: 0.007155692670494318, Accuracy: 0.998046875\n",
      "Batch: 140, Loss: 0.005819621961563826, Accuracy: 1.0\n",
      "Batch: 141, Loss: 0.00449155131354928, Accuracy: 1.0\n",
      "Batch: 142, Loss: 0.007419298402965069, Accuracy: 0.998046875\n",
      "Batch: 143, Loss: 0.003223010106012225, Accuracy: 1.0\n",
      "Batch: 144, Loss: 0.01117503922432661, Accuracy: 0.9970703125\n",
      "Batch: 145, Loss: 0.007380827330052853, Accuracy: 0.998046875\n",
      "Batch: 146, Loss: 0.007033884525299072, Accuracy: 0.9990234375\n",
      "Batch: 147, Loss: 0.0044810157269239426, Accuracy: 0.9990234375\n",
      "Batch: 148, Loss: 0.0044109029695391655, Accuracy: 1.0\n",
      "Batch: 149, Loss: 0.004842745140194893, Accuracy: 0.9970703125\n",
      "Batch: 150, Loss: 0.0030357579234987497, Accuracy: 1.0\n",
      "Batch: 151, Loss: 0.0035579854156821966, Accuracy: 0.9990234375\n",
      "Epoch 18/90\n",
      "Batch: 1, Loss: 0.009865976870059967, Accuracy: 0.998046875\n",
      "Batch: 2, Loss: 0.004927875008434057, Accuracy: 0.9990234375\n",
      "Batch: 3, Loss: 0.0036339550279080868, Accuracy: 0.998046875\n",
      "Batch: 4, Loss: 0.0029994137585163116, Accuracy: 1.0\n",
      "Batch: 5, Loss: 0.003241403726860881, Accuracy: 1.0\n",
      "Batch: 6, Loss: 0.0083285728469491, Accuracy: 0.9970703125\n",
      "Batch: 7, Loss: 0.0019027498783543706, Accuracy: 1.0\n",
      "Batch: 8, Loss: 0.005263022147119045, Accuracy: 0.9990234375\n",
      "Batch: 9, Loss: 0.006868606433272362, Accuracy: 0.9970703125\n",
      "Batch: 10, Loss: 0.008752327412366867, Accuracy: 0.9970703125\n",
      "Batch: 11, Loss: 0.0048323944211006165, Accuracy: 1.0\n",
      "Batch: 12, Loss: 0.004671880975365639, Accuracy: 0.9990234375\n",
      "Batch: 13, Loss: 0.007279525510966778, Accuracy: 0.9970703125\n",
      "Batch: 14, Loss: 0.004784283693879843, Accuracy: 0.9990234375\n",
      "Batch: 15, Loss: 0.0038172630593180656, Accuracy: 1.0\n",
      "Batch: 16, Loss: 0.008504781872034073, Accuracy: 0.99609375\n",
      "Batch: 17, Loss: 0.004818415269255638, Accuracy: 1.0\n",
      "Batch: 18, Loss: 0.006631780881434679, Accuracy: 0.998046875\n",
      "Batch: 19, Loss: 0.003841725178062916, Accuracy: 1.0\n",
      "Batch: 20, Loss: 0.005844595842063427, Accuracy: 0.998046875\n",
      "Batch: 21, Loss: 0.005617935210466385, Accuracy: 0.998046875\n",
      "Batch: 22, Loss: 0.008348546922206879, Accuracy: 0.9970703125\n",
      "Batch: 23, Loss: 0.004240941256284714, Accuracy: 0.9990234375\n",
      "Batch: 24, Loss: 0.005702366586774588, Accuracy: 0.998046875\n",
      "Batch: 25, Loss: 0.00634817173704505, Accuracy: 0.9970703125\n",
      "Batch: 26, Loss: 0.006423627492040396, Accuracy: 0.9970703125\n",
      "Batch: 27, Loss: 0.004105357453227043, Accuracy: 1.0\n",
      "Batch: 28, Loss: 0.002586653456091881, Accuracy: 1.0\n",
      "Batch: 29, Loss: 0.00667463568970561, Accuracy: 0.998046875\n",
      "Batch: 30, Loss: 0.003902674652636051, Accuracy: 1.0\n",
      "Batch: 31, Loss: 0.004604028537869453, Accuracy: 0.9990234375\n",
      "Batch: 32, Loss: 0.002885103691369295, Accuracy: 1.0\n",
      "Batch: 33, Loss: 0.004759918432682753, Accuracy: 0.9990234375\n",
      "Batch: 34, Loss: 0.008179175667464733, Accuracy: 0.9970703125\n",
      "Batch: 35, Loss: 0.0055137863382697105, Accuracy: 0.9990234375\n",
      "Batch: 36, Loss: 0.006184138357639313, Accuracy: 0.9990234375\n",
      "Batch: 37, Loss: 0.004785400815308094, Accuracy: 0.998046875\n",
      "Batch: 38, Loss: 0.004645327106118202, Accuracy: 0.9990234375\n",
      "Batch: 39, Loss: 0.006092131603509188, Accuracy: 0.9990234375\n",
      "Batch: 40, Loss: 0.004521184600889683, Accuracy: 0.9990234375\n",
      "Batch: 41, Loss: 0.0025325738824903965, Accuracy: 1.0\n",
      "Batch: 42, Loss: 0.002188020385801792, Accuracy: 1.0\n",
      "Batch: 43, Loss: 0.0037238774821162224, Accuracy: 1.0\n",
      "Batch: 44, Loss: 0.004021312575787306, Accuracy: 0.9990234375\n",
      "Batch: 45, Loss: 0.0021303524263203144, Accuracy: 1.0\n",
      "Batch: 46, Loss: 0.007550905458629131, Accuracy: 0.998046875\n",
      "Batch: 47, Loss: 0.007274502422660589, Accuracy: 0.9990234375\n",
      "Batch: 48, Loss: 0.005111671984195709, Accuracy: 0.998046875\n",
      "Batch: 49, Loss: 0.003518804209306836, Accuracy: 1.0\n",
      "Batch: 50, Loss: 0.004851016215980053, Accuracy: 0.9990234375\n",
      "Batch: 51, Loss: 0.003397970926016569, Accuracy: 0.9990234375\n",
      "Batch: 52, Loss: 0.00598013773560524, Accuracy: 0.998046875\n",
      "Batch: 53, Loss: 0.004145127721130848, Accuracy: 0.9990234375\n",
      "Batch: 54, Loss: 0.0026326263323426247, Accuracy: 1.0\n",
      "Batch: 55, Loss: 0.00435367226600647, Accuracy: 0.9990234375\n",
      "Batch: 56, Loss: 0.004603258799761534, Accuracy: 0.9990234375\n",
      "Batch: 57, Loss: 0.0042517767287790775, Accuracy: 0.9990234375\n",
      "Batch: 58, Loss: 0.004025671165436506, Accuracy: 0.9990234375\n",
      "Batch: 59, Loss: 0.005032864864915609, Accuracy: 0.998046875\n",
      "Batch: 60, Loss: 0.005021318793296814, Accuracy: 0.998046875\n",
      "Batch: 61, Loss: 0.004574425984174013, Accuracy: 0.9990234375\n",
      "Batch: 62, Loss: 0.004202587995678186, Accuracy: 1.0\n",
      "Batch: 63, Loss: 0.0031943200156092644, Accuracy: 1.0\n",
      "Batch: 64, Loss: 0.0064000580459833145, Accuracy: 0.9970703125\n",
      "Batch: 65, Loss: 0.005307510960847139, Accuracy: 0.9990234375\n",
      "Batch: 66, Loss: 0.005893947556614876, Accuracy: 0.9990234375\n",
      "Batch: 67, Loss: 0.002897328231483698, Accuracy: 1.0\n",
      "Batch: 68, Loss: 0.004380948841571808, Accuracy: 0.9990234375\n",
      "Batch: 69, Loss: 0.007232129108160734, Accuracy: 0.9970703125\n",
      "Batch: 70, Loss: 0.005196125712245703, Accuracy: 0.9990234375\n",
      "Batch: 71, Loss: 0.003058352041989565, Accuracy: 1.0\n",
      "Batch: 72, Loss: 0.0023282882757484913, Accuracy: 1.0\n",
      "Batch: 73, Loss: 0.0044822851195931435, Accuracy: 0.9990234375\n",
      "Batch: 74, Loss: 0.003587075276300311, Accuracy: 1.0\n",
      "Batch: 75, Loss: 0.004665087908506393, Accuracy: 0.9990234375\n",
      "Batch: 76, Loss: 0.003941308706998825, Accuracy: 1.0\n",
      "Batch: 77, Loss: 0.006783477962017059, Accuracy: 0.9990234375\n",
      "Batch: 78, Loss: 0.005108133424073458, Accuracy: 0.9990234375\n",
      "Batch: 79, Loss: 0.0034953549038618803, Accuracy: 1.0\n",
      "Batch: 80, Loss: 0.00785855669528246, Accuracy: 0.99609375\n",
      "Batch: 81, Loss: 0.0039580632001161575, Accuracy: 0.9990234375\n",
      "Batch: 82, Loss: 0.003379341447725892, Accuracy: 0.9990234375\n",
      "Batch: 83, Loss: 0.0035018576309084892, Accuracy: 0.9990234375\n",
      "Batch: 84, Loss: 0.00535358302295208, Accuracy: 0.9970703125\n",
      "Batch: 85, Loss: 0.0036702349316328764, Accuracy: 0.9990234375\n",
      "Batch: 86, Loss: 0.002575690858066082, Accuracy: 0.9990234375\n",
      "Batch: 87, Loss: 0.003791793715208769, Accuracy: 0.9990234375\n",
      "Batch: 88, Loss: 0.006839613430202007, Accuracy: 0.998046875\n",
      "Batch: 89, Loss: 0.003731407690793276, Accuracy: 0.9990234375\n",
      "Batch: 90, Loss: 0.007140735164284706, Accuracy: 0.998046875\n",
      "Batch: 91, Loss: 0.004951076582074165, Accuracy: 0.9990234375\n",
      "Batch: 92, Loss: 0.004417428281158209, Accuracy: 0.9990234375\n",
      "Batch: 93, Loss: 0.004534182138741016, Accuracy: 0.9990234375\n",
      "Batch: 94, Loss: 0.006684956140816212, Accuracy: 0.9990234375\n",
      "Batch: 95, Loss: 0.0030183210037648678, Accuracy: 0.9990234375\n",
      "Batch: 96, Loss: 0.006155509501695633, Accuracy: 0.998046875\n",
      "Batch: 97, Loss: 0.002002950292080641, Accuracy: 1.0\n",
      "Batch: 98, Loss: 0.002750490326434374, Accuracy: 1.0\n",
      "Batch: 99, Loss: 0.005335788708180189, Accuracy: 0.998046875\n",
      "Batch: 100, Loss: 0.004284987226128578, Accuracy: 1.0\n",
      "Batch: 101, Loss: 0.002444049809128046, Accuracy: 1.0\n",
      "Batch: 102, Loss: 0.002538188360631466, Accuracy: 0.9990234375\n",
      "Batch: 103, Loss: 0.004219381604343653, Accuracy: 1.0\n",
      "Batch: 104, Loss: 0.0022131968289613724, Accuracy: 1.0\n",
      "Batch: 105, Loss: 0.004128225147724152, Accuracy: 0.9990234375\n",
      "Batch: 106, Loss: 0.004366871900856495, Accuracy: 0.9990234375\n",
      "Batch: 107, Loss: 0.0037106559611856937, Accuracy: 1.0\n",
      "Batch: 108, Loss: 0.004720274358987808, Accuracy: 0.9990234375\n",
      "Batch: 109, Loss: 0.0030426522716879845, Accuracy: 1.0\n",
      "Batch: 110, Loss: 0.006411817856132984, Accuracy: 0.998046875\n",
      "Batch: 111, Loss: 0.0024604666978120804, Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "file = open(os.path.join(data_directory, data_file), mode = 'r')\n",
    "data = file.read()\n",
    "file.close()\n",
    "if __name__ == \"__main__\":\n",
    "    training_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.570057</td>\n",
       "      <td>0.293945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.850464</td>\n",
       "      <td>0.488281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.504380</td>\n",
       "      <td>0.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.353270</td>\n",
       "      <td>0.593750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.247315</td>\n",
       "      <td>0.617188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1.169375</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1.088979</td>\n",
       "      <td>0.658203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1.049507</td>\n",
       "      <td>0.677734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.988916</td>\n",
       "      <td>0.684570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.946073</td>\n",
       "      <td>0.682617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.922529</td>\n",
       "      <td>0.703125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.904022</td>\n",
       "      <td>0.722656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.890658</td>\n",
       "      <td>0.714844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.844449</td>\n",
       "      <td>0.726562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.815944</td>\n",
       "      <td>0.741211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.829617</td>\n",
       "      <td>0.728516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.775039</td>\n",
       "      <td>0.749023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.766915</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.767771</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.733762</td>\n",
       "      <td>0.756836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0.705088</td>\n",
       "      <td>0.777344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0.708641</td>\n",
       "      <td>0.775391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>0.675398</td>\n",
       "      <td>0.776367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>0.719725</td>\n",
       "      <td>0.765625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0.662180</td>\n",
       "      <td>0.779297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>0.635798</td>\n",
       "      <td>0.789062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0.614068</td>\n",
       "      <td>0.794922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0.621199</td>\n",
       "      <td>0.795898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>0.608465</td>\n",
       "      <td>0.804688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0.592249</td>\n",
       "      <td>0.793945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>61</td>\n",
       "      <td>0.385737</td>\n",
       "      <td>0.867188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>62</td>\n",
       "      <td>0.356167</td>\n",
       "      <td>0.883789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>63</td>\n",
       "      <td>0.371307</td>\n",
       "      <td>0.878906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>0.357482</td>\n",
       "      <td>0.884766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>65</td>\n",
       "      <td>0.340871</td>\n",
       "      <td>0.877930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>66</td>\n",
       "      <td>0.372424</td>\n",
       "      <td>0.870117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>67</td>\n",
       "      <td>0.359206</td>\n",
       "      <td>0.881836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>68</td>\n",
       "      <td>0.323794</td>\n",
       "      <td>0.891602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>69</td>\n",
       "      <td>0.349235</td>\n",
       "      <td>0.883789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>70</td>\n",
       "      <td>0.341775</td>\n",
       "      <td>0.885742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>71</td>\n",
       "      <td>0.328699</td>\n",
       "      <td>0.879883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>72</td>\n",
       "      <td>0.302101</td>\n",
       "      <td>0.902344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>73</td>\n",
       "      <td>0.348871</td>\n",
       "      <td>0.882812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>74</td>\n",
       "      <td>0.324025</td>\n",
       "      <td>0.900391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>75</td>\n",
       "      <td>0.297615</td>\n",
       "      <td>0.895508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>76</td>\n",
       "      <td>0.331783</td>\n",
       "      <td>0.886719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>77</td>\n",
       "      <td>0.315978</td>\n",
       "      <td>0.900391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>78</td>\n",
       "      <td>0.301240</td>\n",
       "      <td>0.900391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>79</td>\n",
       "      <td>0.314003</td>\n",
       "      <td>0.913086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>80</td>\n",
       "      <td>0.330850</td>\n",
       "      <td>0.891602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>81</td>\n",
       "      <td>0.307386</td>\n",
       "      <td>0.898438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>82</td>\n",
       "      <td>0.312513</td>\n",
       "      <td>0.896484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>83</td>\n",
       "      <td>0.303039</td>\n",
       "      <td>0.888672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>84</td>\n",
       "      <td>0.293686</td>\n",
       "      <td>0.911133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>85</td>\n",
       "      <td>0.325840</td>\n",
       "      <td>0.899414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>86</td>\n",
       "      <td>0.295506</td>\n",
       "      <td>0.904297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>87</td>\n",
       "      <td>0.295797</td>\n",
       "      <td>0.903320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>88</td>\n",
       "      <td>0.292568</td>\n",
       "      <td>0.893555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>89</td>\n",
       "      <td>0.276495</td>\n",
       "      <td>0.912109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>90</td>\n",
       "      <td>0.268679</td>\n",
       "      <td>0.916016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Epoch      Loss  Accuracy\n",
       "0       1  2.570057  0.293945\n",
       "1       2  1.850464  0.488281\n",
       "2       3  1.504380  0.562500\n",
       "3       4  1.353270  0.593750\n",
       "4       5  1.247315  0.617188\n",
       "5       6  1.169375  0.625000\n",
       "6       7  1.088979  0.658203\n",
       "7       8  1.049507  0.677734\n",
       "8       9  0.988916  0.684570\n",
       "9      10  0.946073  0.682617\n",
       "10     11  0.922529  0.703125\n",
       "11     12  0.904022  0.722656\n",
       "12     13  0.890658  0.714844\n",
       "13     14  0.844449  0.726562\n",
       "14     15  0.815944  0.741211\n",
       "15     16  0.829617  0.728516\n",
       "16     17  0.775039  0.749023\n",
       "17     18  0.766915  0.750000\n",
       "18     19  0.767771  0.750000\n",
       "19     20  0.733762  0.756836\n",
       "20     21  0.705088  0.777344\n",
       "21     22  0.708641  0.775391\n",
       "22     23  0.675398  0.776367\n",
       "23     24  0.719725  0.765625\n",
       "24     25  0.662180  0.779297\n",
       "25     26  0.635798  0.789062\n",
       "26     27  0.614068  0.794922\n",
       "27     28  0.621199  0.795898\n",
       "28     29  0.608465  0.804688\n",
       "29     30  0.592249  0.793945\n",
       "..    ...       ...       ...\n",
       "60     61  0.385737  0.867188\n",
       "61     62  0.356167  0.883789\n",
       "62     63  0.371307  0.878906\n",
       "63     64  0.357482  0.884766\n",
       "64     65  0.340871  0.877930\n",
       "65     66  0.372424  0.870117\n",
       "66     67  0.359206  0.881836\n",
       "67     68  0.323794  0.891602\n",
       "68     69  0.349235  0.883789\n",
       "69     70  0.341775  0.885742\n",
       "70     71  0.328699  0.879883\n",
       "71     72  0.302101  0.902344\n",
       "72     73  0.348871  0.882812\n",
       "73     74  0.324025  0.900391\n",
       "74     75  0.297615  0.895508\n",
       "75     76  0.331783  0.886719\n",
       "76     77  0.315978  0.900391\n",
       "77     78  0.301240  0.900391\n",
       "78     79  0.314003  0.913086\n",
       "79     80  0.330850  0.891602\n",
       "80     81  0.307386  0.898438\n",
       "81     82  0.312513  0.896484\n",
       "82     83  0.303039  0.888672\n",
       "83     84  0.293686  0.911133\n",
       "84     85  0.325840  0.899414\n",
       "85     86  0.295506  0.904297\n",
       "86     87  0.295797  0.903320\n",
       "87     88  0.292568  0.893555\n",
       "88     89  0.276495  0.912109\n",
       "89     90  0.268679  0.916016\n",
       "\n",
       "[90 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = pd.read_csv(os.path.join(data_directory, \"log.csv\"))\n",
    "log"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "af89a60ed4cc6cf4ebfd41881fc995abc48882d69c5f9a2abef426668f1a5c12"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}